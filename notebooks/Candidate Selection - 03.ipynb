{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from functools import lru_cache\n",
    "from ipdb import set_trace\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "from allennlp.data import Instance, Token\n",
    "from allennlp.data.fields import TextField, ListField, MetadataField, ArrayField, IndexField, Field, AdjacencyField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.token_indexers import PretrainedBertIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.word_splitter import BertBasicWordSplitter\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.iterators import BasicIterator\n",
    "from allennlp.models import Model, SimpleSeq2Seq\n",
    "from allennlp.modules.token_embedders import PretrainedBertEmbedder\n",
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper\n",
    "from allennlp.training import Trainer\n",
    "from allennlp.training.moving_average import ExponentialMovingAverage\n",
    "from allennlp.training.metrics import CategoricalAccuracy, BooleanAccuracy\n",
    "from allennlp.nn.util import get_text_field_mask, move_to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Schema(object):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        with open(filepath) as f:\n",
    "            self.index = {}\n",
    "            for schema in json.load(f):\n",
    "                service_name = schema[\"service_name\"]\n",
    "                self.index[service_name] = schema\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get(self, service):\n",
    "        result = dict(\n",
    "            # service\n",
    "            name=service,\n",
    "            desc=self.index[service][\"description\"],\n",
    "            \n",
    "            # slots\n",
    "            slot_name=[],\n",
    "            slot_desc=[],\n",
    "            slot_iscat=[], \n",
    "            slot_vals=[], # collected only for cat slots.. not sure if that makes sense\n",
    "\n",
    "            # intents\n",
    "            intent_name=[],\n",
    "            intent_desc=[],\n",
    "            intent_istrans=[],\n",
    "            intent_reqslots=[],\n",
    "            intent_optslots=[],\n",
    "            intent_optvals=[],\n",
    "        )\n",
    "\n",
    "        for slot in self.index[service][\"slots\"]:\n",
    "            result[\"slot_name\"].append(slot[\"name\"])\n",
    "            result[\"slot_desc\"].append(slot[\"description\"])\n",
    "            result[\"slot_iscat\"].append(slot[\"is_categorical\"])\n",
    "            result[\"slot_vals\"].append(slot[\"possible_values\"])\n",
    "        \n",
    "        for intent in self.index[service][\"intents\"]:\n",
    "            result[\"intent_name\"].append(intent[\"name\"])\n",
    "            result[\"intent_desc\"].append(intent[\"description\"])\n",
    "            result[\"intent_istrans\"].append(intent[\"is_transactional\"])\n",
    "            result[\"intent_reqslots\"].append(intent[\"required_slots\"])\n",
    "            result[\"intent_optslots\"].append(list(intent[\"optional_slots\"].keys()))\n",
    "            result[\"intent_optvals\"].append(list(intent[\"optional_slots\"].values()))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    \n",
    "    def __init__(self, schema, services):\n",
    "        self.schema = schema\n",
    "        \n",
    "        # memory for cat slots: serv,slot=>[] or for noncat slots: noncat => []\n",
    "        self.memory = defaultdict(list)\n",
    "        self.index = defaultdict(set) # serv,slot->val, noncat->val\n",
    "\n",
    "        for serv in services:\n",
    "            # add possible values from slot\n",
    "            sch = schema.get(serv)\n",
    "            for slot, iscat, slotvals in zip(sch[\"slot_name\"], sch[\"slot_iscat\"], sch[\"slot_vals\"]):\n",
    "                key = (serv, slot) if iscat else \"noncat\"\n",
    "                for val in [\"NONE\", \"dontcare\"] + slotvals:\n",
    "                    if val not in self.index[key]:\n",
    "                        self.index[key].add(val)\n",
    "                        self.memory[key].append(val)\n",
    "\n",
    "            # add optional slot vals\n",
    "            for optslots, optvals in zip(sch[\"intent_optslots\"], sch[\"intent_optvals\"]):\n",
    "                for slot, val in zip(optslots, optvals):\n",
    "                    slotid = sch[\"slot_name\"].index(slot)\n",
    "                    iscat = sch[\"slot_iscat\"][slotid]\n",
    "                    assert slotid != -1\n",
    "                    key = (serv, slot) if iscat else \"noncat\"\n",
    "                    if val not in self.index[key]:\n",
    "                        self.index[key].add(val)\n",
    "                        self.memory[key].append(val)\n",
    "                        \n",
    "    def update(self, dial_turn):\n",
    "        # update only noncat values..\n",
    "        utter = dial_turn[\"utterance\"]\n",
    "        for frame in dial_turn[\"frames\"]:\n",
    "            sch = self.schema.get(frame[\"service\"])\n",
    "            slot_names = sch[\"slot_name\"]\n",
    "            slot_iscat = sch[\"slot_iscat\"]\n",
    "\n",
    "            for tag in frame[\"slots\"]:\n",
    "                slot, st, en = tag[\"slot\"], tag[\"start\"], tag[\"exclusive_end\"]\n",
    "                slotid = slot_names.index(slot)\n",
    "                iscat = slot_iscat[slotid]\n",
    "                assert slotid != -1\n",
    "\n",
    "                if not iscat:\n",
    "                    value = utter[st:en]\n",
    "                    key = \"noncat\"\n",
    "                    if value not in self.index[key]:\n",
    "                        value = re.sub(\"\\u2013\", \"-\", value) # dial 59_00125 turn 14\n",
    "                        self.index[key].add(value)\n",
    "                        self.memory[key].append(value)\n",
    "                        \n",
    "    def get(self, key=\"noncat\"):\n",
    "        return self.memory[key]\n",
    "    \n",
    "    \n",
    "class DialogReader(DatasetReader):\n",
    "\n",
    "    def __init__(self, schema, limit, lazy=False):\n",
    "        super().__init__(lazy)\n",
    "        self.token_indexers = {\"tokens\": PretrainedBertIndexer(\"bert-base-uncased\")}\n",
    "        self.tokenizer = BertBasicWordSplitter()\n",
    "        self.schema = schema\n",
    "        self.limit = limit\n",
    "\n",
    "    def _read(self, path):\n",
    "        # get a set of dialogs\n",
    "        count = 0\n",
    "        dialogs = []\n",
    "        for filename in sorted(glob.glob(path)):\n",
    "            if count > self.limit:\n",
    "                break\n",
    "            with open(filename) as f:\n",
    "                for d in json.load(f):\n",
    "                    dialogs.append(d)\n",
    "                    count += 1\n",
    "                    if count > self.limit:\n",
    "                        break\n",
    "        \n",
    "        # prepare instances\n",
    "        for dial in dialogs:\n",
    "            memory = Memory(self.schema, dial[\"services\"])\n",
    "            for turnid, turn in enumerate(dial[\"turns\"]):\n",
    "                memory.update(turn)\n",
    "                if turn[\"speaker\"] == \"USER\":\n",
    "                    usr_utter = turn[\"utterance\"]\n",
    "                    sys_utter = dial[\"turns\"][turnid-1][\"utterance\"] if turnid > 0 else \"dialog started\"\n",
    "                    num_none_questions  = 0\n",
    "                    \n",
    "                    for frame in turn[\"frames\"]:\n",
    "                        # get schema info\n",
    "                        serv = frame[\"service\"]\n",
    "                        sch = self.schema.get(serv)\n",
    "                        \n",
    "                        # intent\n",
    "                        intent = frame[\"state\"][\"active_intent\"]\n",
    "                        all_intents = {s: i for i, s in enumerate(sch[\"intent_name\"])}\n",
    "                        intent_istrans = False\n",
    "                        intent_desc = \"No intent\"\n",
    "                        if intent != \"NONE\":\n",
    "                            intentid = all_intents[intent]\n",
    "                            assert intentid != -1\n",
    "                            intent_desc = sch[\"intent_desc\"][intentid]\n",
    "                            intent_istrans = sch[\"intent_istrans\"][intentid]\n",
    "                        \n",
    "                        # slots\n",
    "                        all_slots = {s: i for i, s in enumerate(sch[\"slot_name\"])}\n",
    "                        all_slots_iscat = sch[\"slot_iscat\"]\n",
    "                        all_slots_desc = sch[\"slot_desc\"]\n",
    "                        active_slots = frame[\"state\"][\"slot_values\"]\n",
    "                        none_slots = set(all_slots) - set(active_slots)\n",
    "                        \n",
    "                        # active slots\n",
    "                        for slot, values in active_slots.items():\n",
    "                            slotid = all_slots[slot]\n",
    "                            assert slotid != -1\n",
    "                            key = (serv, slot) if all_slots_iscat[slotid] else \"noncat\"\n",
    "                            target_value = re.sub(\"\\u2013\", \"-\", values[0])\n",
    "                            \n",
    "                            item = dict(\n",
    "                                dialid=dial[\"dialogue_id\"],\n",
    "                                turnid=turnid,\n",
    "                                usr_utter=usr_utter,\n",
    "                                sys_utter=sys_utter,\n",
    "                                serv=serv,\n",
    "                                serv_desc=sch[\"desc\"],\n",
    "                                slot=slot,\n",
    "                                slot_desc=all_slots_desc[slotid],\n",
    "                                slot_iscat=all_slots_iscat[slotid],\n",
    "                                slot_val=target_value,\n",
    "                                intent=intent,\n",
    "                                intent_desc=intent_desc,\n",
    "                                intent_istrans=intent_istrans,\n",
    "                                memory=memory.get(key),\n",
    "                            )\n",
    "                            yield self.text_to_instance(item)\n",
    "                            \n",
    "                        # none valued slots\n",
    "                        for slot in none_slots:\n",
    "                            if np.random.randn() > 0.5 and num_none_questions < 3:\n",
    "                                num_none_questions += 1\n",
    "                                slotid = all_slots[slot]\n",
    "                                assert slotid != -1\n",
    "                                key = (serv, slot) if all_slots_iscat[slotid] else \"noncat\"\n",
    "                                target_value = \"NONE\"\n",
    "                                item = dict(\n",
    "                                    dialid=dial[\"dialogue_id\"],\n",
    "                                    turnid=turnid,\n",
    "                                    usr_utter=usr_utter,\n",
    "                                    sys_utter=sys_utter,\n",
    "                                    serv=serv,\n",
    "                                    serv_desc=sch[\"desc\"],\n",
    "                                    slot=slot,\n",
    "                                    slot_desc=all_slots_desc[slotid],\n",
    "                                    slot_iscat=all_slots_iscat[slotid],\n",
    "                                    slot_val=target_value,\n",
    "                                    intent=intent,\n",
    "                                    intent_desc=intent_desc,\n",
    "                                    intent_istrans=intent_istrans,\n",
    "                                    memory=memory.get(key),\n",
    "                                )\n",
    "                                yield self.text_to_instance(item)\n",
    "                        \n",
    "            \n",
    "    def text_to_instance(self, item):\n",
    "        fields = {}\n",
    "        \n",
    "        # featurize query\n",
    "        query_tokens = []\n",
    "        query_type = []\n",
    "        \n",
    "        for index, field in enumerate((\"sys_utter\", \"usr_utter\", \"serv_desc\", \"slot_desc\")):\n",
    "            tokens = self.tokenizer.split_words(item[field])\n",
    "            query_tokens.extend(tokens)\n",
    "            query_type.extend([index + 1] * len(tokens))\n",
    "        \n",
    "        query_pos = list(range(1, len(query_tokens) + 1))\n",
    "        \n",
    "        fields[\"query\"] = TextField(query_tokens, self.token_indexers)\n",
    "        fields[\"query_type\"] = ArrayField(np.array(query_type))\n",
    "        fields[\"query_pos\"] = ArrayField(np.array(query_pos))\n",
    "        \n",
    "        # featurize memory\n",
    "        mem_values = item[\"memory\"]\n",
    "        mem_tokens = []\n",
    "        mem_loc = []\n",
    "        mem_type = []\n",
    "        mem_pos = []\n",
    "        \n",
    "        for index, mem_val in enumerate(mem_values):\n",
    "            tokens = self.tokenizer.split_words(mem_val)\n",
    "            loc = int(mem_val == item[\"slot_val\"])\n",
    "            for i, tok in enumerate(tokens):\n",
    "                mem_tokens.append(tok)\n",
    "                mem_loc.append(loc * (i == len(tokens)-1))\n",
    "                mem_type.append(index + 1)\n",
    "            \n",
    "        mem_pos = list(range(1, len(mem_tokens) + 1))\n",
    "        \n",
    "        fields[\"memory\"] = TextField(mem_tokens, self.token_indexers)\n",
    "        fields[\"memory_loc\"] = ArrayField(np.array(mem_loc), padding_value=-1)\n",
    "        fields[\"memory_type\"] = ArrayField(np.array(mem_type))\n",
    "        fields[\"memory_pos\"] = ArrayField(np.array(mem_pos))\n",
    "        \n",
    "        # positional fields\n",
    "        fields[\"turnid\"] =  ArrayField(np.array(item[\"turnid\"]))\n",
    "        \n",
    "        # meta fields\n",
    "        fields[\"id\"] = MetadataField(\"{}/{}/{}/{}\".format(item[\"dialid\"], item[\"turnid\"], item[\"serv\"], item[\"slot\"]))\n",
    "        fields[\"slot\"] = MetadataField(item[\"slot\"])\n",
    "        fields[\"serv\"] = MetadataField(item[\"serv\"])\n",
    "        fields[\"intent\"] = MetadataField(item[\"intent\"])\n",
    "        fields[\"dialid\"] = MetadataField(item[\"dialid\"])\n",
    "        fields[\"memory_values\"] = MetadataField(item[\"memory\"])\n",
    "        \n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_schema = Schema(\"../data/train/schema.json\")\n",
    "dev_schema = Schema(\"../data/dev/schema.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b755e91d87f43ae8bde648f360980fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e210f6fbeb54c9d86d71d0d41dbe5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c3f15995794fcc985bb864c088a656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6016), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'query_type', 'query_pos', 'memory', 'memory_loc', 'memory_type', 'memory_pos', 'turnid', 'id', 'slot', 'serv', 'intent', 'dialid', 'memory_values'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read full dataset\n",
    "reader = DialogReader(train_schema, limit=100)\n",
    "train_ds = reader.read(\"../data/train/dialogues*.json\")\n",
    "\n",
    "reader = DialogReader(dev_schema, limit=5)\n",
    "dev_ds = reader.read(\"../data/dev/dialogues*.json\")\n",
    "\n",
    "vocab = Vocabulary.from_instances(train_ds + dev_ds)\n",
    "\n",
    "\n",
    "it = BasicIterator(batch_size=32)\n",
    "it.index_with(vocab)\n",
    "batch = next(iter(it(train_ds)))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"memory_loc\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateSelector(Model):\n",
    "    \n",
    "    def __init__(self, vocab):\n",
    "        super().__init__(vocab)\n",
    "        self.emb = PretrainedBertEmbedder(\"bert-base-uncased\", requires_grad=True)\n",
    "        emb_dim = self.emb.get_output_dim()\n",
    "        \n",
    "        # query encoder\n",
    "        self.register_buffer(\"query_state_history\", None)\n",
    "        self.register_buffer(\"query_state\", None)\n",
    "        self.query_enc = nn.GRU(3 * emb_dim, emb_dim, batch_first=True, bidirectional=True)\n",
    "        self.query_type_emb = nn.Embedding(10, emb_dim) # max query fields\n",
    "        self.query_pos_emb = nn.Embedding(500, emb_dim) # max query length\n",
    "        \n",
    "        # candidate values decoder\n",
    "        self.memory_dec = nn.GRU(4 * emb_dim + 1, emb_dim, batch_first=True, num_layers=2, dropout=0.2)\n",
    "        self.memory_type_emb = nn.Embedding(100, emb_dim) # max candidate values\n",
    "        self.memory_pos_emb = nn.Embedding(500, emb_dim) # max total length of candidates\n",
    "        \n",
    "        # query attention\n",
    "        self.attn_w = nn.Linear(4 * emb_dim, emb_dim)\n",
    "        self.attn_v = nn.Linear(emb_dim, 1, bias=False)\n",
    "        \n",
    "        # final state\n",
    "        self.final = nn.Linear(emb_dim, 1)\n",
    "        \n",
    "        self.accuracy = BooleanAccuracy()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        #self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for n, p in self.named_parameters():\n",
    "            if not n.startswith((\"emb\",)):\n",
    "                if \"weight\" in n:\n",
    "                    p.data.normal_(mean=0, std=1)\n",
    "                else:\n",
    "                    p.data.zero_()\n",
    "        \n",
    "    def get_metrics(self, reset=False):\n",
    "        return {\"acc\": self.accuracy.get_metric(reset)}\n",
    "    \n",
    "    def encoder(self, inputs, reset=False):\n",
    "        hidden = self.query_state\n",
    "        if reset:\n",
    "            hidden = None\n",
    "        \n",
    "        # if hidden size is uneven\n",
    "        if hidden is not None:\n",
    "            hidden_bs = hidden.shape[1]\n",
    "            inputs_bs = inputs.shape[0]\n",
    "            if hidden_bs > inputs_bs:\n",
    "                hidden = hidden[:,:inputs_bs,:]\n",
    "            elif hidden_bs < inputs_bs:\n",
    "                padding = torch.zeros(\n",
    "                    hidden.shape[0], inputs_bs-hidden_bs, hidden.shape[2],\n",
    "                    device=hidden.device, dtype=hidden.dtype)\n",
    "                hidden = torch.cat([hidden, padding], dim=1)\n",
    "            hidden = hidden.contiguous()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs, hidden = self.query_enc(inputs, hidden)\n",
    "        \n",
    "        # retain query state\n",
    "        self.query_state = hidden.detach()\n",
    "        \n",
    "        return outputs, hidden\n",
    "    \n",
    "    def query_state_attention(self, mem_h):\n",
    "        # mem_h -- [layers * dir, batch, emb]\n",
    "        # query_o -- [batch, seq, dir * emb]\n",
    "        sh = mem_h.shape\n",
    "        \n",
    "        energies = []\n",
    "        \n",
    "        queries_o = self.query_state_history\n",
    "        for x in range(3 - len(queries_o)):\n",
    "            empty_query = torch.zeros()\n",
    "        \n",
    "        sh = mem_h.shape\n",
    "        mem_h = mem_h.view(sh[1], 1, -1) # b,1,lde\n",
    "        mem_h = mem_h.repeat(1, query_o.shape[1], 1) # b,s,lde\n",
    "        \n",
    "        x = torch.cat((query_o, mem_h), -1) # b,s, l*d*e + d*e\n",
    "        energy = torch.tanh(self.attn_w(x)) # bse\n",
    "        energy = self.attn_v(energy).squeeze(-1) # bs1\n",
    "        \n",
    "        attn = F.softmax(energy, -1) # bs\n",
    "        \n",
    "        # context\n",
    "        if self.query_enc.bidirectional:\n",
    "            sh = query_o.shape[-1] // 2\n",
    "            query_o = query_o[...,:sh] + query_o[...,sh:]\n",
    "            \n",
    "        context = torch.bmm(attn.unsqueeze(1), query_o) # b1e\n",
    "        \n",
    "        return context # b1e\n",
    "    \n",
    "    def query_attention(self, mem_h, query_o):\n",
    "        # mem_h -- [layers * dir, batch, emb]\n",
    "        # query_o -- [batch, seq, dir * emb]\n",
    "        energies = []\n",
    "        \n",
    "        sh = mem_h.shape\n",
    "        mem_h = mem_h.view(sh[1], 1, -1) # b,1,lde\n",
    "        mem_h = mem_h.repeat(1, query_o.shape[1], 1) # b,s,lde\n",
    "        \n",
    "        x = torch.cat((query_o, mem_h), -1) # b,s, l*d*e + d*e\n",
    "        energy = torch.tanh(self.attn_w(x)) # bse\n",
    "        energy = self.attn_v(energy).squeeze(-1) # bs1\n",
    "        \n",
    "        attn = F.softmax(energy, -1) # bs\n",
    "        \n",
    "        # context\n",
    "        if self.query_enc.bidirectional:\n",
    "            sh = query_o.shape[-1] // 2\n",
    "            query_o = query_o[...,:sh] + query_o[...,sh:]\n",
    "            \n",
    "        context = torch.bmm(attn.unsqueeze(1), query_o) # b1e\n",
    "        \n",
    "        return context # b1e\n",
    "    \n",
    "    def decoder(self, query_o, query_h, mem_inp, mem_out):\n",
    "        # query_o -- [batch, seq, dir*emb]\n",
    "        # query_h -- [layers * dir, batch, emb]\n",
    "        # mem_inp -- [batch, mem, emb]\n",
    "        # mem_out -- [batch, mem]\n",
    "        predicted = []\n",
    "        \n",
    "        # init prev final out\n",
    "        bs = mem_inp.shape[0]\n",
    "        prev_out = torch.zeros(bs, 1, 1, device=mem_inp.device, dtype=mem_inp.dtype) # b11\n",
    "        \n",
    "        # init decoder hidden state\n",
    "        layers = self.query_enc.num_layers \n",
    "        if self.query_enc.bidirectional:\n",
    "            dec_h = query_h[:layers,...] + query_h[layers:,...]\n",
    "        if layers > 1:\n",
    "            dec_h = query_h.sum(0, keepdim=True)\n",
    "            \n",
    "        dim = self.memory_dec.num_layers * (1 + int(self.memory_dec.bidirectional))\n",
    "        dec_h = dec_h.repeat(dim, 1, 1) # [layers * dir, batch, emb]\n",
    "        \n",
    "        # predict at each candidate value\n",
    "        for m in range(mem_inp.shape[1]):\n",
    "            inp = mem_inp[:,m:m+1,:] # b,1,3e\n",
    "            context = self.query_attention(dec_h, query_o) # b1,e\n",
    "            combined_inp = torch.cat((inp, context, prev_out), dim=-1) # b,1,4e+1\n",
    "            \n",
    "            dec_o, dec_h = self.memory_dec(combined_inp, dec_h)\n",
    "            \n",
    "            predicted.append(dec_o)\n",
    "            prev_out = mem_out[:,m:m+1,None] # teacher forcing\n",
    "        \n",
    "        predicted = torch.cat(predicted, dim=1) # bme\n",
    "        \n",
    "        return predicted\n",
    "    \n",
    "    def forward(self, **batch):\n",
    "        query = self.emb(batch[\"query\"][\"tokens\"], batch[\"query\"][\"tokens-offsets\"]) # [batch, seq, emb]\n",
    "        query_type = self.query_type_emb(batch[\"query_type\"].long()) # [batch, seq, emb]\n",
    "        query_pos = self.query_pos_emb(batch[\"query_pos\"].long()) # [batch, seq, emb]\n",
    "        \n",
    "        memory = self.emb(batch[\"memory\"][\"tokens\"], batch[\"memory\"][\"tokens-offsets\"]) # [batch, mem, emb]\n",
    "        memory_type = self.memory_type_emb(batch[\"memory_type\"].long()) # [batch, mem, emb]\n",
    "        memory_pos = self.memory_pos_emb(batch[\"memory_pos\"].long())\n",
    "        memory_loc_oh = batch[\"memory_loc\"] # [batch, mem]\n",
    "        \n",
    "        is_new_dial = bool((batch[\"turnid\"] == 0).all())\n",
    "        query_i = torch.cat((query, query_type, query_pos), -1) # [batch, seq, 3*emb]\n",
    "        query_o, query_h = self.encoder(query_i, reset=is_new_dial) # [batch, seq, dir * emb], [layers * dir, batch, emb]\n",
    "        \n",
    "        # decode values\n",
    "        memory_i = torch.cat((memory, memory_type, memory_pos), dim=-1) # [batch, seq, 3*emb]\n",
    "        mem_o = self.decoder(query_o, query_h, memory_i, memory_loc_oh) # [batch, mem, emb]\n",
    "        predicted = F.softmax(self.final(mem_o).squeeze(-1), -1) # [batch, mem]\n",
    "        \n",
    "        # set NANs\n",
    "        if (predicted != predicted).any():\n",
    "            predicted[predicted != predicted] = 0\n",
    "            print(\"Warning: found NaN\")\n",
    "\n",
    "        # loss\n",
    "        target_loc = memory_loc_oh.argmax(-1)\n",
    "        loss = F.cross_entropy(predicted, target_loc, ignore_index=-1).unsqueeze(0)\n",
    "            \n",
    "        # metric\n",
    "        predicted_loc = predicted.argmax(-1)\n",
    "        target_loc = memory_loc_oh.argmax(-1)\n",
    "\n",
    "        mask = batch[\"memory\"][\"mask\"]\n",
    "        mask = mask[torch.arange(mask.shape[0]), target_loc]\n",
    "\n",
    "        self.accuracy(predicted_loc, target_loc, mask)\n",
    "\n",
    "        output = dict(\n",
    "            logits=predicted,\n",
    "            loss=loss,\n",
    "            pred=predicted_loc,\n",
    "            target=target_loc,\n",
    "        )\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# litmus test on CPU\n",
    "model = CandidateSelector(vocab).to(\"cpu\")\n",
    "batch=move_to_device(batch, -1)\n",
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to check gpu_memory_mb(), continuing\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/site-packages/allennlp/common/util.py\", line 378, in gpu_memory_mb\n",
      "    encoding='utf-8')\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 395, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 472, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 775, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 1453, in _execute_child\n",
      "    restore_signals, start_new_session, preexec_fn)\n",
      "OSError: [Errno 12] Cannot allocate memory\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ce74003e25410eb194c0ef74fb797a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=182), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to check gpu_memory_mb(), continuing\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/site-packages/allennlp/common/util.py\", line 378, in gpu_memory_mb\n",
      "    encoding='utf-8')\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 395, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 472, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 775, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/home/suryak/anaconda3/lib/python3.7/subprocess.py\", line 1453, in _execute_child\n",
      "    restore_signals, start_new_session, preexec_fn)\n",
      "OSError: [Errno 12] Cannot allocate memory\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36e357562674dc7b21afaafb76c4783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=182), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 1,\n",
       " 'peak_cpu_memory_MB': 125591.588,\n",
       " 'training_duration': '0:06:13.965647',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 1,\n",
       " 'epoch': 1,\n",
       " 'training_acc': 0.487263339070568,\n",
       " 'training_loss': 3.4144281096510833,\n",
       " 'training_cpu_memory_MB': 125591.588}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allen_device=1\n",
    "torch_device=1\n",
    "\n",
    "model = CandidateSelector(vocab).to(torch_device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "\n",
    "iterator = BasicIterator(batch_size=32)\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    num_epochs=2,\n",
    "    cuda_device=allen_device,\n",
    "    serialization_dir=\"../results/4\",\n",
    "    should_log_learning_rate=True,\n",
    "    histogram_interval=50,\n",
    "    num_serialized_models_to_keep=1,\n",
    "    grad_norm=1,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2', 'NONE')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference\n",
    "results = {}\n",
    "test_iterator = BasicIterator(batch_size=1)\n",
    "test_iterator.index_with(vocab)\n",
    "\n",
    "sample = next(iter(test_iterator(dev_ds, shuffle=False)))\n",
    "sample = move_to_device(sample, allen_device)\n",
    "\n",
    "key = sample[\"id\"][0]\n",
    "output = model(**sample)\n",
    "\n",
    "t_loc = int(output[\"target\"].item())\n",
    "p_loc = int(output[\"pred\"].item())\n",
    "\n",
    "target_val = sample[\"memory_values\"][0][t_loc]\n",
    "pred_val = sample[\"memory_values\"][0][p_loc]\n",
    "\n",
    "target_val, pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(model, test_ds, device):\n",
    "    results = defaultdict(OrderedDict)\n",
    "    test_iterator = BasicIterator(batch_size=32)\n",
    "    test_iterator.index_with(vocab)\n",
    "    \n",
    "    model = move_to_device(model, device)\n",
    "    model = model.eval()\n",
    "    \n",
    "    for sample in tqdm(test_iterator(test_ds, shuffle=False, num_epochs=1)):\n",
    "        sample = move_to_device(sample, device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**sample)\n",
    "        \n",
    "        num_samples = output[\"target\"].shape[0]\n",
    "        for i in range(num_samples):\n",
    "            key = sample[\"id\"][i]\n",
    "            t_loc = int(output[\"target\"][i].item())\n",
    "            p_loc = int(output[\"pred\"][i].item())\n",
    "\n",
    "            t_val = \"UNK\"\n",
    "            p_val = \"UNK\"\n",
    "            if t_loc < len(sample[\"memory_values\"][i]):\n",
    "                t_val = sample[\"memory_values\"][i][t_loc]\n",
    "            if p_loc < len(sample[\"memory_values\"][i]):\n",
    "                p_val = sample[\"memory_values\"][i][p_loc]\n",
    "        \n",
    "            results[key] = (t_val, p_val, t_loc == p_loc)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f110a4ffd1ae463fb909a32a29c706cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = predictor(model, dev_ds, allen_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_00000/0/Restaurants_2/number_of_seats</th>\n",
       "      <td>2</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/0/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/0/Restaurants_2/has_vegetarian_options</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/0/Restaurants_2/date</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/0/Restaurants_2/phone_number</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/2/Restaurants_2/number_of_seats</th>\n",
       "      <td>2</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/2/Restaurants_2/restaurant_name</th>\n",
       "      <td>UNK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/2/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/2/Restaurants_2/location</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/2/Restaurants_2/price_range</th>\n",
       "      <td>NONE</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/4/Restaurants_2/date</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/4/Restaurants_2/number_of_seats</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/4/Restaurants_2/restaurant_name</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/4/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/4/Restaurants_2/location</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/4/Restaurants_2/has_vegetarian_options</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/4/Restaurants_2/has_seating_outdoors</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/6/Restaurants_2/date</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/6/Restaurants_2/number_of_seats</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/6/Restaurants_2/restaurant_name</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/6/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/6/Restaurants_2/location</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/6/Restaurants_2/price_range</th>\n",
       "      <td>NONE</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/8/Restaurants_2/date</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/8/Restaurants_2/number_of_seats</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/8/Restaurants_2/restaurant_name</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/8/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/8/Restaurants_2/location</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/8/Restaurants_2/category</th>\n",
       "      <td>NONE</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00000/8/Restaurants_2/rating</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/4/Restaurants_2/has_vegetarian_options</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/4/Restaurants_2/address</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/6/Restaurants_2/number_of_seats</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/6/Restaurants_2/restaurant_name</th>\n",
       "      <td>The Big 4</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/6/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/6/Restaurants_2/location</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/6/Restaurants_2/has_vegetarian_options</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/6/Restaurants_2/phone_number</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/8/Restaurants_2/number_of_seats</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/8/Restaurants_2/restaurant_name</th>\n",
       "      <td>UNK</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/8/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/8/Restaurants_2/location</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/8/Restaurants_2/has_vegetarian_options</th>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/8/Restaurants_2/category</th>\n",
       "      <td>NONE</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/8/Restaurants_2/address</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/10/Restaurants_2/date</th>\n",
       "      <td>UNK</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/10/Restaurants_2/number_of_seats</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/10/Restaurants_2/restaurant_name</th>\n",
       "      <td>UNK</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/10/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/10/Restaurants_2/location</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/10/Restaurants_2/has_vegetarian_options</th>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/10/Restaurants_2/rating</th>\n",
       "      <td>NONE</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/date</th>\n",
       "      <td>UNK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/number_of_seats</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/restaurant_name</th>\n",
       "      <td>UNK</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/time</th>\n",
       "      <td>UNK</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/location</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/has_vegetarian_options</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/price_range</th>\n",
       "      <td>NONE</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_00005/12/Restaurants_2/category</th>\n",
       "      <td>NONE</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1      2\n",
       "1_00000/0/Restaurants_2/number_of_seats                  2      NONE  False\n",
       "1_00000/0/Restaurants_2/time                           UNK      NONE  False\n",
       "1_00000/0/Restaurants_2/has_vegetarian_options        NONE      NONE   True\n",
       "1_00000/0/Restaurants_2/date                          NONE      NONE   True\n",
       "1_00000/0/Restaurants_2/phone_number                  NONE      NONE   True\n",
       "1_00000/2/Restaurants_2/number_of_seats                  2      NONE  False\n",
       "1_00000/2/Restaurants_2/restaurant_name                UNK      NONE  False\n",
       "1_00000/2/Restaurants_2/time                           UNK      NONE  False\n",
       "1_00000/2/Restaurants_2/location                       UNK       UNK   True\n",
       "1_00000/2/Restaurants_2/price_range                   NONE  moderate  False\n",
       "1_00000/4/Restaurants_2/date                           UNK       UNK  False\n",
       "1_00000/4/Restaurants_2/number_of_seats                  2         2   True\n",
       "1_00000/4/Restaurants_2/restaurant_name                UNK       UNK  False\n",
       "1_00000/4/Restaurants_2/time                           UNK       UNK  False\n",
       "1_00000/4/Restaurants_2/location                       UNK       UNK   True\n",
       "1_00000/4/Restaurants_2/has_vegetarian_options        NONE      NONE   True\n",
       "1_00000/4/Restaurants_2/has_seating_outdoors          NONE      NONE   True\n",
       "1_00000/6/Restaurants_2/date                           UNK       UNK  False\n",
       "1_00000/6/Restaurants_2/number_of_seats                  2         2   True\n",
       "1_00000/6/Restaurants_2/restaurant_name                UNK       UNK  False\n",
       "1_00000/6/Restaurants_2/time                           UNK       UNK  False\n",
       "1_00000/6/Restaurants_2/location                       UNK       UNK   True\n",
       "1_00000/6/Restaurants_2/price_range                   NONE  moderate  False\n",
       "1_00000/8/Restaurants_2/date                           UNK       UNK  False\n",
       "1_00000/8/Restaurants_2/number_of_seats                  2         2   True\n",
       "1_00000/8/Restaurants_2/restaurant_name                UNK       UNK  False\n",
       "1_00000/8/Restaurants_2/time                           UNK       UNK  False\n",
       "1_00000/8/Restaurants_2/location                       UNK       UNK   True\n",
       "1_00000/8/Restaurants_2/category                      NONE       UNK  False\n",
       "1_00000/8/Restaurants_2/rating                        NONE      NONE   True\n",
       "...                                                    ...       ...    ...\n",
       "1_00005/4/Restaurants_2/has_vegetarian_options        NONE      NONE   True\n",
       "1_00005/4/Restaurants_2/address                       NONE      NONE   True\n",
       "1_00005/6/Restaurants_2/number_of_seats                  4         2  False\n",
       "1_00005/6/Restaurants_2/restaurant_name          The Big 4     today  False\n",
       "1_00005/6/Restaurants_2/time                           UNK      NONE  False\n",
       "1_00005/6/Restaurants_2/location                     today     today   True\n",
       "1_00005/6/Restaurants_2/has_vegetarian_options        NONE      NONE   True\n",
       "1_00005/6/Restaurants_2/phone_number                  NONE      NONE   True\n",
       "1_00005/8/Restaurants_2/number_of_seats                  4         2  False\n",
       "1_00005/8/Restaurants_2/restaurant_name                UNK     today  False\n",
       "1_00005/8/Restaurants_2/time                           UNK     today  False\n",
       "1_00005/8/Restaurants_2/location                     today     today   True\n",
       "1_00005/8/Restaurants_2/has_vegetarian_options        NONE      True  False\n",
       "1_00005/8/Restaurants_2/category                      NONE     today  False\n",
       "1_00005/8/Restaurants_2/address                       NONE      NONE   True\n",
       "1_00005/10/Restaurants_2/date                          UNK     today  False\n",
       "1_00005/10/Restaurants_2/number_of_seats                 4         2  False\n",
       "1_00005/10/Restaurants_2/restaurant_name               UNK     today  False\n",
       "1_00005/10/Restaurants_2/time                          UNK     today  False\n",
       "1_00005/10/Restaurants_2/location                    today     today   True\n",
       "1_00005/10/Restaurants_2/has_vegetarian_options       NONE      True  False\n",
       "1_00005/10/Restaurants_2/rating                       NONE     today  False\n",
       "1_00005/12/Restaurants_2/date                          UNK      NONE  False\n",
       "1_00005/12/Restaurants_2/number_of_seats                 4         2  False\n",
       "1_00005/12/Restaurants_2/restaurant_name               UNK     today  False\n",
       "1_00005/12/Restaurants_2/time                          UNK     today  False\n",
       "1_00005/12/Restaurants_2/location                    today     today   True\n",
       "1_00005/12/Restaurants_2/has_vegetarian_options       NONE      NONE   True\n",
       "1_00005/12/Restaurants_2/price_range                  NONE  moderate  False\n",
       "1_00005/12/Restaurants_2/category                     NONE     today  False\n",
       "\n",
       "[206 rows x 3 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results.values(), index=results.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from functools import lru_cache\n",
    "from ipdb import set_trace\n",
    "\n",
    "from allennlp.data import Instance, Token\n",
    "from allennlp.data.fields import TextField, ListField, MetadataField, ArrayField, IndexField, Field, AdjacencyField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.token_indexers import PretrainedBertIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.word_splitter import BertBasicWordSplitter\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.iterators import BasicIterator\n",
    "from allennlp.models import Model, SimpleSeq2Seq\n",
    "from allennlp.modules.token_embedders import PretrainedBertEmbedder\n",
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper\n",
    "from allennlp.training import Trainer\n",
    "from allennlp.training.moving_average import ExponentialMovingAverage\n",
    "from allennlp.training.metrics import CategoricalAccuracy, BooleanAccuracy\n",
    "from allennlp.nn.util import get_text_field_mask, move_to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Schema(object):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        with open(filepath) as f:\n",
    "            self.index = {}\n",
    "            for schema in json.load(f):\n",
    "                service_name = schema[\"service_name\"]\n",
    "                self.index[service_name] = schema\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get(self, service):\n",
    "        result = dict(\n",
    "            # service\n",
    "            name=service,\n",
    "            desc=self.index[service][\"description\"],\n",
    "            \n",
    "            # slots\n",
    "            slot_name=[],\n",
    "            slot_desc=[],\n",
    "            slot_iscat=[], \n",
    "            slot_vals=[], # collected only for cat slots.. not sure if that makes sense\n",
    "\n",
    "            # intents\n",
    "            intent_name=[],\n",
    "            intent_desc=[],\n",
    "            intent_istrans=[],\n",
    "            intent_reqslots=[],\n",
    "            intent_optslots=[],\n",
    "            intent_optvals=[],\n",
    "        )\n",
    "\n",
    "        for slot in self.index[service][\"slots\"]:\n",
    "            result[\"slot_name\"].append(slot[\"name\"])\n",
    "            result[\"slot_desc\"].append(slot[\"description\"])\n",
    "            result[\"slot_iscat\"].append(slot[\"is_categorical\"])\n",
    "            result[\"slot_vals\"].append(slot[\"possible_values\"])\n",
    "        \n",
    "        for intent in self.index[service][\"intents\"]:\n",
    "            result[\"intent_name\"].append(intent[\"name\"])\n",
    "            result[\"intent_desc\"].append(intent[\"description\"])\n",
    "            result[\"intent_istrans\"].append(intent[\"is_transactional\"])\n",
    "            result[\"intent_reqslots\"].append(intent[\"required_slots\"])\n",
    "            result[\"intent_optslots\"].append(list(intent[\"optional_slots\"].keys()))\n",
    "            result[\"intent_optvals\"].append(list(intent[\"optional_slots\"].values()))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    \n",
    "    def __init__(self, schema, services):\n",
    "        self.schema = schema\n",
    "        \n",
    "        # memory for cat slots: serv,slot=>[] or for noncat slots: noncat => []\n",
    "        self.memory = defaultdict(list)\n",
    "        self.index = defaultdict(set) # serv,slot->val, noncat->val\n",
    "\n",
    "        for serv in services:\n",
    "            # add possible values from slot\n",
    "            sch = schema.get(serv)\n",
    "            for slot, iscat, slotvals in zip(sch[\"slot_name\"], sch[\"slot_iscat\"], sch[\"slot_vals\"]):\n",
    "                key = (serv, slot) if iscat else \"noncat\"\n",
    "                for val in [\"NONE\", \"dontcare\"] + slotvals:\n",
    "                    if val not in self.index[key]:\n",
    "                        self.index[key].add(val)\n",
    "                        self.memory[key].append(val)\n",
    "\n",
    "            # add optional slot vals\n",
    "            for optslots, optvals in zip(sch[\"intent_optslots\"], sch[\"intent_optvals\"]):\n",
    "                for slot, val in zip(optslots, optvals):\n",
    "                    slotid = sch[\"slot_name\"].index(slot)\n",
    "                    iscat = sch[\"slot_iscat\"][slotid]\n",
    "                    assert slotid != -1\n",
    "                    key = (serv, slot) if iscat else \"noncat\"\n",
    "                    if val not in self.index[key]:\n",
    "                        self.index[key].add(val)\n",
    "                        self.memory[key].append(val)\n",
    "                        \n",
    "    def update(self, dial_turn):\n",
    "        # update only noncat values..\n",
    "        utter = dial_turn[\"utterance\"]\n",
    "        for frame in dial_turn[\"frames\"]:\n",
    "            sch = self.schema.get(frame[\"service\"])\n",
    "            slot_names = sch[\"slot_name\"]\n",
    "            slot_iscat = sch[\"slot_iscat\"]\n",
    "\n",
    "            for tag in frame[\"slots\"]:\n",
    "                slot, st, en = tag[\"slot\"], tag[\"start\"], tag[\"exclusive_end\"]\n",
    "                slotid = slot_names.index(slot)\n",
    "                iscat = slot_iscat[slotid]\n",
    "                assert slotid != -1\n",
    "\n",
    "                if not iscat:\n",
    "                    value = utter[st:en]\n",
    "                    key = \"noncat\"\n",
    "                    if value not in self.index[key]:\n",
    "                        value = re.sub(\"\\u2013\", \"-\", value) # dial 59_00125 turn 14\n",
    "                        self.index[key].add(value)\n",
    "                        self.memory[key].append(value)\n",
    "                        \n",
    "    def get(self, key=\"noncat\"):\n",
    "        return self.memory[key]\n",
    "    \n",
    "    \n",
    "class DialogReader(DatasetReader):\n",
    "\n",
    "    def __init__(self, schema, limit, lazy=False):\n",
    "        super().__init__(lazy)\n",
    "        self.token_indexers = {\"tokens\": PretrainedBertIndexer(\"bert-base-uncased\")}\n",
    "        self.tokenizer = BertBasicWordSplitter()\n",
    "        self.schema = schema\n",
    "        self.limit = limit\n",
    "\n",
    "    def _read(self, path):\n",
    "        # get a set of dialogs\n",
    "        count = 0\n",
    "        dialogs = []\n",
    "        for filename in glob.glob(path):\n",
    "            if count > self.limit:\n",
    "                break\n",
    "            with open(filename) as f:\n",
    "                for d in json.load(f):\n",
    "                    dialogs.append(d)\n",
    "                    count += 1\n",
    "                    if count > self.limit:\n",
    "                        break\n",
    "        \n",
    "        # prepare instances\n",
    "        for dial in dialogs:\n",
    "            memory = Memory(self.schema, dial[\"services\"])\n",
    "            for turnid, turn in enumerate(dial[\"turns\"]):\n",
    "                memory.update(turn)\n",
    "                if turn[\"speaker\"] == \"USER\":\n",
    "                    usr_utter = turn[\"utterance\"]\n",
    "                    sys_utter = dial[\"turns\"][turnid-1][\"utterance\"] if turnid > 0 else \"dialog started\"\n",
    "                    num_none_questions  = 0\n",
    "                    \n",
    "                    for frame in turn[\"frames\"]:\n",
    "                        # get schema info\n",
    "                        serv = frame[\"service\"]\n",
    "                        sch = self.schema.get(serv)\n",
    "                        \n",
    "                        # intent\n",
    "                        intent = frame[\"state\"][\"active_intent\"]\n",
    "                        all_intents = {s: i for i, s in enumerate(sch[\"intent_name\"])}\n",
    "                        intent_istrans = False\n",
    "                        intent_desc = \"No intent\"\n",
    "                        if intent != \"NONE\":\n",
    "                            intentid = all_intents[intent]\n",
    "                            assert intentid != -1\n",
    "                            intent_desc = sch[\"intent_desc\"][intentid]\n",
    "                            intent_istrans = sch[\"intent_istrans\"][intentid]\n",
    "                        \n",
    "                        # slots\n",
    "                        all_slots = {s: i for i, s in enumerate(sch[\"slot_name\"])}\n",
    "                        all_slots_iscat = sch[\"slot_iscat\"]\n",
    "                        all_slots_desc = sch[\"slot_desc\"]\n",
    "                        active_slots = frame[\"state\"][\"slot_values\"]\n",
    "                        none_slots = set(all_slots) - set(active_slots)\n",
    "                        \n",
    "                        # active slots\n",
    "                        for slot, values in active_slots.items():\n",
    "                            slotid = all_slots[slot]\n",
    "                            assert slotid != -1\n",
    "                            key = (serv, slot) if all_slots_iscat[slotid] else \"noncat\"\n",
    "                            target_value = re.sub(\"\\u2013\", \"-\", values[0])\n",
    "                            \n",
    "                            item = dict(\n",
    "                                dialid=dial[\"dialogue_id\"],\n",
    "                                turnid=turnid,\n",
    "                                usr_utter=usr_utter,\n",
    "                                sys_utter=sys_utter,\n",
    "                                serv=serv,\n",
    "                                serv_desc=sch[\"desc\"],\n",
    "                                slot=slot,\n",
    "                                slot_desc=all_slots_desc[slotid],\n",
    "                                slot_iscat=all_slots_iscat[slotid],\n",
    "                                slot_val=target_value,\n",
    "                                intent=intent,\n",
    "                                intent_desc=intent_desc,\n",
    "                                intent_istrans=intent_istrans,\n",
    "                                memory=memory.get(key),\n",
    "                            )\n",
    "                            yield self.text_to_instance(item)\n",
    "                            \n",
    "                        # none valued slots\n",
    "                        for slot in none_slots:\n",
    "                            if np.random.randn() > 0.5 and num_none_questions < 3:\n",
    "                                num_none_questions += 1\n",
    "                                slotid = all_slots[slot]\n",
    "                                assert slotid != -1\n",
    "                                key = (serv, slot) if all_slots_iscat[slotid] else \"noncat\"\n",
    "                                target_value = \"NONE\"\n",
    "                                item = dict(\n",
    "                                    dialid=dial[\"dialogue_id\"],\n",
    "                                    turnid=turnid,\n",
    "                                    usr_utter=usr_utter,\n",
    "                                    sys_utter=sys_utter,\n",
    "                                    serv=serv,\n",
    "                                    serv_desc=sch[\"desc\"],\n",
    "                                    slot=slot,\n",
    "                                    slot_desc=all_slots_desc[slotid],\n",
    "                                    slot_iscat=all_slots_iscat[slotid],\n",
    "                                    slot_val=target_value,\n",
    "                                    intent=intent,\n",
    "                                    intent_desc=intent_desc,\n",
    "                                    intent_istrans=intent_istrans,\n",
    "                                    memory=memory.get(key),\n",
    "                                )\n",
    "                                yield self.text_to_instance(item)\n",
    "                        \n",
    "            \n",
    "    def text_to_instance(self, item):\n",
    "        fields = {}\n",
    "        \n",
    "        # featurize query\n",
    "        q_fields = (\"sys_utter\", \"usr_utter\", \"serv_desc\", \"slot_desc\", \"intent_desc\")\n",
    "        query = \" . \".join(item[f] for f in q_fields)\n",
    "        query_tokens = self.tokenizer.split_words(query)\n",
    "        fields[\"query\"] = TextField(query_tokens, self.token_indexers)\n",
    "        \n",
    "        # featurize memory\n",
    "        mem_values = item[\"memory\"]\n",
    "        mem_tokens = []\n",
    "        mem_target = []\n",
    "        for mem_val in mem_values:\n",
    "            tokens = self.tokenizer.split_words(mem_val)\n",
    "            target = int(mem_val == item[\"slot_val\"])\n",
    "            for t in tokens:\n",
    "                mem_tokens.append(t)\n",
    "                mem_target.append(target)\n",
    "        \n",
    "        fields[\"memory\"] = TextField(mem_tokens, self.token_indexers)\n",
    "        fields[\"memory_target\"] = ArrayField(np.array(mem_target))\n",
    "        \n",
    "        # positional fields\n",
    "        fields[\"turnid\"] =  ArrayField(np.array(item[\"turnid\"]))\n",
    "        \n",
    "        # meta fields\n",
    "        fields[\"id\"] = MetadataField(\"{}/{}/{}/{}\".format(item[\"dialid\"], item[\"turnid\"], item[\"serv\"], item[\"slot\"]))\n",
    "        fields[\"slot\"] = MetadataField(item[\"slot\"])\n",
    "        fields[\"serv\"] = MetadataField(item[\"serv\"])\n",
    "        fields[\"intent\"] = MetadataField(item[\"intent\"])\n",
    "        fields[\"dialid\"] = MetadataField(item[\"dialid\"])\n",
    "        \n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_schema = Schema(\"../data/train/schema.json\")\n",
    "dev_schema = Schema(\"../data/dev/schema.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81169f8532d46ab9ff69db305bb5fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841aed317f594171bd12a2e066d3962b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684c5aa320d34ab1aa242a5e71e2d5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1966), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'memory', 'memory_target', 'turnid', 'id', 'slot', 'serv', 'intent', 'dialid'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = DialogReader(train_schema, limit=10)\n",
    "train_ds = reader.read(\"../data/train/dialogues*.json\")\n",
    "\n",
    "reader = DialogReader(dev_schema, limit=10)\n",
    "dev_ds = reader.read(\"../data/dev/dialogues*.json\")\n",
    "\n",
    "vocab = Vocabulary.from_instances(train_ds + dev_ds)\n",
    "\n",
    "\n",
    "it = BasicIterator(batch_size=32)\n",
    "it.index_with(vocab)\n",
    "batch = next(iter(it(train_ds)))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateSelector(Model):\n",
    "    \n",
    "    def __init__(self, vocab):\n",
    "        super().__init__(vocab)\n",
    "        self.emb = PretrainedBertEmbedder(\"bert-base-uncased\", requires_grad=True)\n",
    "        emb_dim = self.emb.get_output_dim()\n",
    "        \n",
    "        self.register_buffer(\"query_state\", None)\n",
    "        self.query_enc = nn.GRU(emb_dim, emb_dim, batch_first=True)\n",
    "        \n",
    "        self.memory_dec = nn.GRU(2 * emb_dim + 1, emb_dim, batch_first=True)\n",
    "        \n",
    "        self.attn_w = nn.Linear(emb_dim * 2, emb_dim)\n",
    "        self.attn_v = nn.Linear(emb_dim, 1, bias=False)\n",
    "        \n",
    "        self.final = nn.Linear(emb_dim, 1)\n",
    "        \n",
    "        self.accuracy = BooleanAccuracy()\n",
    "        \n",
    "    def get_metrics(self, reset=False):\n",
    "        return {\"acc\": self.accuracy.get_metric(reset)}\n",
    "    \n",
    "    def encoder(self, inputs, reset=False):\n",
    "        hidden = self.query_state\n",
    "        if reset:\n",
    "            hidden = None\n",
    "        \n",
    "        # if hidden size is uneven\n",
    "        if hidden is not None:\n",
    "            hidden_bs = hidden.shape[1]\n",
    "            inputs_bs = inputs.shape[0]\n",
    "            if hidden_bs > inputs_bs:\n",
    "                hidden = hidden[:,:inputs_bs,:]\n",
    "            elif hidden_bs < inputs_bs:\n",
    "                padding = torch.zeros(\n",
    "                    hidden.shape[0], inputs_bs-hidden_bs, hidden.shape[2],\n",
    "                    device=hidden.device, dtype=hidden.dtype)\n",
    "                hidden = torch.cat([hidden, padding], dim=1)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs, hidden = self.query_enc(inputs, hidden)\n",
    "        self.query_state = hidden.detach()\n",
    "        return outputs, hidden\n",
    "    \n",
    "    def attention(self, mem_h, query_o):\n",
    "        # mem_h: l*d,b,e  query_o: bse\n",
    "        energies = []\n",
    "        \n",
    "        sh = mem_h.shape\n",
    "        mem_h = mem_h.view(sh[1], 1, -1) # b,1, l*d*e\n",
    "        mem_h = mem_h.repeat(1, query_o.shape[1], 1) # b,s,lde\n",
    "        \n",
    "        x = torch.cat((query_o, mem_h), -1) # b,s,e+lde\n",
    "        energy = torch.tanh(self.attn_w(x)) # bse\n",
    "        energy = self.attn_v(energy).squeeze(-1) # bs1\n",
    "        \n",
    "        attn = F.softmax(energy, -1) # bs\n",
    "        \n",
    "        # context\n",
    "        context = torch.bmm(attn.unsqueeze(1), query_o) # b1e\n",
    "        \n",
    "        return context # b1e\n",
    "    \n",
    "    def decoder(self, query_o, query_h, mem_inp, mem_out):\n",
    "        bs = mem_inp.shape[0]\n",
    "\n",
    "        predicted = []\n",
    "        prev_out = torch.zeros(bs, 1, 1, device=mem_inp.device, dtype=mem_inp.dtype) # b11\n",
    "        dec_h = query_h\n",
    "        \n",
    "        for m in range(mem_inp.shape[1]):\n",
    "            inp = mem_inp[:,m:m+1,:] # b1e\n",
    "            context = self.attention(dec_h, query_o) # bwe\n",
    "            \n",
    "            combined_inp = torch.cat((inp, context, prev_out), dim=-1) # b,1,e2+1\n",
    "            dec_o, dec_h = self.memory_dec(combined_inp, dec_h)\n",
    "            \n",
    "            predicted.append(dec_o)\n",
    "            prev_loc = mem_out[:,m:m+1,None] # teacher forcing\n",
    "        \n",
    "        predicted = torch.cat(predicted, dim=1) # bme\n",
    "        \n",
    "        return predicted\n",
    "    \n",
    "    def forward(self, **batch):\n",
    "        query = self.emb(batch[\"query\"][\"tokens\"], batch[\"query\"][\"tokens-offsets\"]) # bse\n",
    "        memory = self.emb(batch[\"memory\"][\"tokens\"], batch[\"memory\"][\"tokens-offsets\"]) # bme\n",
    "        memory_loc_oh = batch[\"memory_target\"] # bm\n",
    "        \n",
    "        # encode query\n",
    "        is_new_dial = bool((batch[\"turnid\"] == 0).all())\n",
    "        query_o, query_h = self.encoder(query, reset=is_new_dial) # be\n",
    "        \n",
    "        # decode values\n",
    "        mem_o = self.decoder(query_o, query_h, memory, memory_loc_oh) # bme\n",
    "        \n",
    "        # final logits\n",
    "        predicted = self.final(mem_o).squeeze(-1) # bm\n",
    "        \n",
    "        # loss\n",
    "        mask = batch[\"memory\"][\"mask\"].float()\n",
    "        loss = F.binary_cross_entropy_with_logits(predicted, memory_loc_oh, mask).unsqueeze(0)\n",
    "        \n",
    "        # metric\n",
    "        predicted_loc = predicted.argmax(-1) # b\n",
    "        memory_loc = memory_loc_oh.argmax(-1) # b\n",
    "        mask = batch[\"memory\"][\"mask\"][torch.arange(memory.shape[0]), memory_loc] # b\n",
    "        self.accuracy(predicted_loc, memory_loc, mask)\n",
    "        \n",
    "        output = dict(\n",
    "            logits=predicted,\n",
    "            loss=loss,\n",
    "            pred=predicted_loc,\n",
    "            target=memory_loc,\n",
    "        )\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ec019f814048a7874101204be30996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95a2309d6e3488eb7aff2eb54f4b2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81903cb7a0ad4828925a243b2be78ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a8b3c25b0b469bb04cd6e1a840087c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcef225ad31244fca224c962077f911d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648385c6323e4e61ae63757dc7d93330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -rf ../results/4\n",
    "\n",
    "allen_device=1\n",
    "torch_device=1\n",
    "\n",
    "model = CandidateSelector(vocab).to(torch_device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "ema = ExponentialMovingAverage(model.named_parameters())\n",
    "\n",
    "iterator = BasicIterator(batch_size=32)\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    num_epochs=10,\n",
    "    cuda_device=allen_device,\n",
    "    #serialization_dir=\"../results/4\",\n",
    "    #should_log_learning_rate=True,\n",
    "    #histogram_interval=30,\n",
    "    num_serialized_models_to_keep=1,\n",
    "    #moving_average=ema,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

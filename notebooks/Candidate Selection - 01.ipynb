{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as D\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import lru_cache\n",
    "from collections import OrderedDict\n",
    "from types import SimpleNamespace\n",
    "from collections.abc import Iterable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from ipdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        self.bert = bert\n",
    "    \n",
    "    def __call__(self, text, include_sep=True):\n",
    "        tokens = self.bert.tokenize(text)\n",
    "        if include_sep:\n",
    "            tokens.insert(0, \"[CLS]\")\n",
    "            tokens.append(\"[SEP]\")\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "class TokenIndexer:\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        self.bert = bert\n",
    "        \n",
    "    def inv(self, *args, **kw):\n",
    "        # tokens MUST be list, tensor doesn't work.\n",
    "        return self.bert.convert_ids_to_tokens(*args, **kw)\n",
    "        \n",
    "    def __call__(self, *args, **kw):\n",
    "        return self.bert.convert_tokens_to_ids(*args, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def label_binarize(labels, classes):\n",
    "    # labels: np.array or tensor [batch, 1]\n",
    "    # classes: [..] list of classes\n",
    "    # weirdly,`sklearn.preprocessing.label_binarize` returns [1] or [0]\n",
    "    # instead of onehot ONLY when executing in this script!\n",
    "    vectors = [np.zeros(len(classes)) for _ in labels]\n",
    "    for i, label in enumerate(labels):\n",
    "        for j, c in enumerate(classes):\n",
    "            if c == label:\n",
    "                vectors[i][j] = 1\n",
    "    return np.array(vectors)\n",
    "    \n",
    "\n",
    "def label_inv_binarize(vectors, classes):\n",
    "    # labels: np.array or tensor [batch, classes]\n",
    "    # classes: [..] list of classes\n",
    "    # follows sklearn LabelBinarizer.inverse_transform()\n",
    "    # given all zeros, predicts label at index 0, instead of returning none!\n",
    "    # sklearn doesn't have functional API of inverse transform\n",
    "    labels = []\n",
    "    for each in vectors:\n",
    "        index = np.argmax(each)\n",
    "        labels.append(classes[index])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def padded_array(array, value=0):\n",
    "    # TODO: this does not do type checking; and wow it can be slow on strings.\n",
    "    # expects array to have fixed _number_ of dimensions\n",
    "    \n",
    "    # resolve the shape of padded array\n",
    "    shape_index = {}\n",
    "    queue = [(array, 0)]\n",
    "    while queue:\n",
    "        subarr, dim = queue.pop(0)\n",
    "        shape_index[dim] = max(shape_index.get(dim, -1), len(subarr))\n",
    "        for x in subarr:\n",
    "            if isinstance(x, Iterable) and not isinstance(x, str):\n",
    "                queue.append((x, dim+1))\n",
    "    shape = [shape_index[k] for k in range(max(shape_index) + 1)]\n",
    "    \n",
    "    # fill the values \n",
    "    padded = np.ones(shape) * value\n",
    "    queue = [(array, [])]\n",
    "    while queue:\n",
    "        subarr, index = queue.pop(0)\n",
    "        for j, x in enumerate(subarr):\n",
    "            if isinstance(x, Iterable):\n",
    "                queue.append((x, index + [j]))\n",
    "            else:\n",
    "                padded[tuple(index + [j])] = x\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "class Schemas(object):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        with open(filepath) as f:\n",
    "            self.index = {}\n",
    "            for schema in json.load(f):\n",
    "                service_name = schema[\"service_name\"]\n",
    "                self.index[service_name] = schema\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get(self, service):\n",
    "        result = dict(\n",
    "            # service\n",
    "            name=service,\n",
    "            desc=self.index[service][\"description\"],\n",
    "            \n",
    "            # slots\n",
    "            slot_name=[],\n",
    "            slot_desc=[],\n",
    "            slot_iscat=[], \n",
    "            slot_vals=[], # collected only for cat slots.. not sure if that makes sense\n",
    "\n",
    "            # intents\n",
    "            intent_name=[],\n",
    "            intent_desc=[],\n",
    "            intent_istrans=[],\n",
    "            intent_reqslots=[],\n",
    "            intent_optslots=[],\n",
    "            intent_optvals=[],\n",
    "        )\n",
    "\n",
    "        for slot in self.index[service][\"slots\"]:\n",
    "            result[\"slot_name\"].append(slot[\"name\"])\n",
    "            result[\"slot_desc\"].append(slot[\"description\"])\n",
    "            result[\"slot_iscat\"].append(slot[\"is_categorical\"])\n",
    "            result[\"slot_vals\"].append(slot[\"possible_values\"])\n",
    "        \n",
    "        for intent in self.index[service][\"intents\"]:\n",
    "            result[\"intent_name\"].append(intent[\"name\"])\n",
    "            result[\"intent_desc\"].append(intent[\"description\"])\n",
    "            result[\"intent_istrans\"].append(intent[\"is_transactional\"])\n",
    "            result[\"intent_reqslots\"].append(intent[\"required_slots\"])\n",
    "            result[\"intent_optslots\"].append(list(intent[\"optional_slots\"].keys()))\n",
    "            result[\"intent_optvals\"].append(list(intent[\"optional_slots\"].values()))\n",
    "\n",
    "        return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueDataset(D.Dataset):\n",
    "    def __init__(self, filename, schemas, tokenizer, token_indexer):\n",
    "        with open(filename) as f:\n",
    "            self.ds = json.load(f)\n",
    "        self.schemas = schemas\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexer = token_indexer\n",
    "        self.dialogues = []\n",
    "        for dial in self.ds:\n",
    "            fields = self.dial_to_fields(dial)\n",
    "            self.dialogues.append(fields)\n",
    "        self.schemas = None\n",
    "        self.tokenizer = None\n",
    "        self.token_indexer = None\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dialogues[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dialogues)\n",
    "    \n",
    "    # Turn,Service,Value\n",
    "    def fd_serv_name(self, dial, fields):\n",
    "        resp = dict(value=[])\n",
    "        for service in dial[\"services\"]:\n",
    "            resp[\"value\"].append(service)\n",
    "        return resp\n",
    "    \n",
    "    # Turn,Service,Tokens\n",
    "    def fd_serv_desc(self, dial, fields):\n",
    "        resp = dict(value=[], tokens=[], ids=[], ids_pos=[], mask=[])\n",
    "        for service in dial[\"services\"]:\n",
    "            desc = self.schemas.get(service)[\"desc\"]\n",
    "            tokens = self.tokenizer(desc)\n",
    "            ids = self.token_indexer(tokens)\n",
    "            resp[\"value\"].append(desc)\n",
    "            resp[\"tokens\"].append(tokens)\n",
    "            resp[\"ids\"].append(ids)\n",
    "            resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "            resp[\"mask\"].append([1] * len(ids))\n",
    "        return resp\n",
    "    \n",
    "    # Turn,Service,Slots,Value\n",
    "    def fd_slot_name(self, dial, fields):\n",
    "        resp = {\"value\": []}\n",
    "        for serv in dial[\"services\"]:\n",
    "            schema = self.schemas.get(serv)\n",
    "            resp[\"value\"].append(schema[\"slot_name\"])\n",
    "        return resp\n",
    "    \n",
    "    # Turn,Service,Slots,Tokens\n",
    "    def fd_slot_desc(self, dial, fields):\n",
    "        resp = dict(value=[], tokens=[], ids=[], ids_pos=[], mask=[])\n",
    "        for serv in dial[\"services\"]:\n",
    "            s_desc = self.schemas.get(serv)[\"slot_desc\"]\n",
    "            s_tokens = [self.tokenizer(d) for d in s_desc]\n",
    "            s_ids = [self.token_indexer(d) for d in s_tokens]\n",
    "            s_mask = [[1] * len(d) for d in s_tokens]\n",
    "            resp[\"value\"].append(s_desc)\n",
    "            resp[\"tokens\"].append(s_tokens)\n",
    "            resp[\"ids\"].append(s_ids)\n",
    "            resp[\"ids_pos\"].append([list(range(1, len(i) + 1)) for i in s_ids])\n",
    "            resp[\"mask\"].append(s_mask)\n",
    "        return resp\n",
    "    \n",
    "    # Turn,Service,Slot,1\n",
    "    def fd_slot_iscat(self, dial, fields):\n",
    "        resp = dict(value=[], ids=[], mask=[])\n",
    "        for serv in dial[\"services\"]:\n",
    "            schema = self.schemas.get(serv)\n",
    "            resp[\"value\"].append(schema[\"slot_iscat\"])\n",
    "            resp[\"ids\"].append([int(i) for i in schema[\"slot_iscat\"]])\n",
    "            resp[\"mask\"].append([1] * len(schema[\"slot_iscat\"]))\n",
    "        return resp\n",
    "\n",
    "    # Turn,Memory,Tokens\n",
    "    def fd_slot_memory(self, dial, fields):\n",
    "        # TODO: iscat feature..\n",
    "        # memory is a sequence of slot tagger values across all frames in a dial.. that grows per turn\n",
    "        # maintain snapshot at each turn\n",
    "        resp = dict(\n",
    "            value=[], # unfeaturized memory\n",
    "            value_desc = [],\n",
    "            value_slot = [], # slots that use this value\n",
    "            tokens=[], # [turn, memory, tokens]\n",
    "            tokens_desc = [],\n",
    "            ids=[], # [turn, memory, tokens]\n",
    "            ids_desc = [], # [turn, memory, tokens]\n",
    "            ids_iscat = [],  # [turn, memory, 2] 0/1 onehot\n",
    "            ids_pos=[], # [turn, memory, 1] positional info for memory cells\n",
    "            #ids_tokens_pos = [], # [turn, memory, tokens] position info for memory values\n",
    "            #ids_tokens_desc_pos = [], # [turn, memory, tokens] positional info for memory desc values\n",
    "            ids_memsize=[], # mem sizes [turn, 1]\n",
    "            mask=[], # mask on memory [turn, mem-size, tokens]\n",
    "            mask_desc = [], # mask on mem desc [turn, mem, tokens]\n",
    "        )\n",
    "        \n",
    "        # memory is sequential, initialized by vals from schema, only has values\n",
    "        memory = [\"NONE\", \"dontcare\"] # keep these at index 0, 1\n",
    "        memory_slot = [[\"*\"], [\"*\"]]\n",
    "        memory_desc = [\"NONE\", \"DONTCARE\"]\n",
    "        memory_iscat = [[1,1], [1,1]] # [not used by cat slot, used by cat slot]\n",
    "        memory_index = {}\n",
    "        for serv in dial[\"services\"]:\n",
    "            schema = self.schemas.get(serv)\n",
    "            servdesc = schema[\"desc\"]\n",
    "            for slotname, slotdesc, iscat, values in zip(schema[\"slot_name\"], schema[\"slot_desc\"], schema[\"slot_iscat\"], schema[\"slot_vals\"]):\n",
    "                for val in values:\n",
    "                    if val not in memory_index:\n",
    "                        memory.append(val)\n",
    "                        memory_slot.append([slotname])\n",
    "                        memory_desc.append(slotdesc + \"[SEP]\" + servdesc)\n",
    "                        memory_iscat.append([int(iscat==False), int(iscat==True)]) # LOL; I just can't believe I am not using label_binarize!!\n",
    "                        memory_index[val] = len(memory)\n",
    "                    else:\n",
    "                        idx = memory_index[val] - 1\n",
    "                        if slotname not in memory_slot[idx]:\n",
    "                            memory_desc[idx] = memory_desc[idx] + \"[SEP]\" + slotdesc + \"[SEP]\" + servdesc\n",
    "                            memory_slot[idx].append(slotname)\n",
    "                            memory_iscat[idx][int(iscat)] = 1\n",
    "        \n",
    "        # at each user turn create a memory snapshot..\n",
    "        for turn in dial[\"turns\"]:\n",
    "            memory = deepcopy(memory)\n",
    "            memory_desc = deepcopy(memory_desc)\n",
    "            memory_slot = deepcopy(memory_slot)\n",
    "            memory_iscat = deepcopy(memory_iscat)\n",
    "            \n",
    "            # pick slot tagger's ground truth ; categorical slot vals are already initialized!\n",
    "            utter = turn[\"utterance\"]\n",
    "            for frame in turn[\"frames\"]:\n",
    "                schema = self.schemas.get(frame[\"service\"])\n",
    "                servdesc = schema[\"desc\"]\n",
    "                for tag in frame[\"slots\"]:\n",
    "                    slotname = tag[\"slot\"]\n",
    "                    iscat = schema[\"slot_iscat\"][schema[\"slot_name\"].index(slotname)]\n",
    "                    slotdesc = schema[\"slot_desc\"][schema[\"slot_name\"].index(slotname)] # shit! O(N*2)\n",
    "                    st, en = tag[\"start\"], tag[\"exclusive_end\"]\n",
    "                    value = utter[st:en]\n",
    "                    if value not in memory_index:\n",
    "                        memory.append(value)\n",
    "                        memory_slot.append([slotname])\n",
    "                        memory_desc.append(slotdesc)\n",
    "                        memory_iscat.append([int(iscat==False), int(iscat==True)])\n",
    "                        memory_index[value] = len(memory)\n",
    "                    else:\n",
    "                        idx = memory_index[value] - 1\n",
    "                        if slotname not in memory_slot[idx]:\n",
    "                            memory_slot[idx].append(slotname)\n",
    "                            memory_desc[idx] = memory_desc[idx] + \"[SEP]\" + slotdesc + \"[SEP]\" + servdesc\n",
    "                            memory_iscat[idx][int(iscat)] = 1\n",
    "                        \n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                resp[\"value\"].append(memory)\n",
    "                resp[\"value_desc\"].append(memory_desc)\n",
    "                resp[\"value_slot\"].append(memory_slot)\n",
    "                resp[\"ids_iscat\"].append(memory_iscat)\n",
    "                resp[\"ids_memsize\"].append(len(memory))\n",
    "\n",
    "        # tokenize and index the memory values\n",
    "        # value: [turn, values], ids/tokens: [turn, values, tokens]\n",
    "        for mem_desc_snapshot, mem_snapshot in zip(resp[\"value_desc\"], resp[\"value\"]):\n",
    "            mem_tokens = []\n",
    "            mem_tokens_desc = []\n",
    "            mem_ids = []\n",
    "            mem_ids_desc = []\n",
    "            mem_pos = list(range(1, len(mem_snapshot) + 1))\n",
    "            mem_mask = []\n",
    "            mem_mask_desc = []\n",
    "            for desc, val in zip(mem_desc_snapshot, mem_snapshot):\n",
    "                # featurize memory\n",
    "                tokens = self.tokenizer(val)\n",
    "                mem_tokens.append(tokens)\n",
    "                mem_ids.append(self.token_indexer(tokens))\n",
    "                mem_mask.append([1] * len(tokens))\n",
    "                \n",
    "                # featurize memory desc\n",
    "                tokens_desc = self.tokenizer(desc)\n",
    "                mem_tokens_desc.append(tokens_desc)\n",
    "                mem_ids_desc.append(self.token_indexer(tokens_desc))\n",
    "                mem_mask_desc.append([1] * len(tokens_desc))\n",
    "                \n",
    "            resp[\"tokens\"].append(mem_tokens)\n",
    "            resp[\"tokens_desc\"].append(mem_tokens_desc)\n",
    "            resp[\"ids\"].append(mem_ids)\n",
    "            resp[\"ids_desc\"].append(mem_ids_desc)\n",
    "            resp[\"ids_pos\"].append(mem_pos)\n",
    "            resp[\"mask\"].append(mem_mask)\n",
    "            resp[\"mask_desc\"].append(mem_mask_desc)\n",
    "        \n",
    "        return resp\n",
    "    \n",
    "    def fd_slot_memory_loc(self, dial, fields):\n",
    "        resp = dict(\n",
    "            value=[],  # string value\n",
    "            ids=[], # memory loc\n",
    "            ids_onehot=[], # onehot of memory loc\n",
    "            mask=[],\n",
    "            mask_onehot=[],\n",
    "            mask_none=[], # 1 -> non NONE values\n",
    "            mask_none_onehot=[],\n",
    "        )\n",
    "        \n",
    "        # query dialog memory snapshots per turn. NOTE: fd_slot_memory should exec first.\n",
    "        memory = fields[\"slot_memory\"][\"value\"]\n",
    "        \n",
    "        # init snapshot: service, slot -> memory loc, val\n",
    "        memory_loc = []\n",
    "        memory_val = []\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                loc = OrderedDict()\n",
    "                val = OrderedDict()\n",
    "                for serv in dial[\"services\"]:\n",
    "                    loc[serv] = OrderedDict()\n",
    "                    val[serv] = OrderedDict()\n",
    "                    for slot in self.schemas.get(serv)[\"slot_name\"]:\n",
    "                        loc[serv][slot] = None\n",
    "                        val[serv][slot] = None\n",
    "                memory_loc.append(loc)\n",
    "                memory_val.append(val)\n",
    "        \n",
    "        # fill the memory locations \n",
    "        snapshot_id = 0\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                turn_memory = memory[snapshot_id]\n",
    "                turn_memory_loc = memory_loc[snapshot_id]\n",
    "                turn_memory_val = memory_val[snapshot_id]\n",
    "                for frame in turn[\"frames\"]:\n",
    "                    service = frame[\"service\"]\n",
    "                    for slot, values in frame[\"state\"][\"slot_values\"].items():\n",
    "                        val = re.sub(\"\\u2013\", \"-\", values[0]) # dial 59_00125 turn 14\n",
    "                        turn_memory_loc[service][slot] = turn_memory.index(val)\n",
    "                        turn_memory_val[service][slot] = val\n",
    "                    # add locations to UNKNOWN slots\n",
    "                    for slot, val in turn_memory_loc[service].items():\n",
    "                        if val is None:\n",
    "                            turn_memory_loc[service][slot] = turn_memory.index(\"NONE\")\n",
    "                            turn_memory_val[service][slot] = \"NONE\"\n",
    "                snapshot_id += 1\n",
    "        \n",
    "        # featurize\n",
    "        snapshot_id = 0\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                turn_memory = memory[snapshot_id]\n",
    "                turn_memory_loc = memory_loc[snapshot_id]\n",
    "                turn_memory_val = memory_val[snapshot_id]\n",
    "                none_loc = memory[snapshot_id].index(\"NONE\")\n",
    "                turn_fields = dict(\n",
    "                    value=[], ids=[], ids_onehot=[], mask=[], mask_onehot=[],\n",
    "                    mask_none=[], mask_none_onehot=[],\n",
    "                )\n",
    "\n",
    "                for serv in turn_memory_loc:\n",
    "                    mem_size = len(turn_memory)\n",
    "                    vals = list(turn_memory_val[serv].values())\n",
    "                    ids = list(turn_memory_loc[serv].values())\n",
    "                    ids_onehots = label_binarize(ids, list(range(mem_size)))\n",
    "                    mask = [1] * len(ids)\n",
    "                    mask_onehots = [[1] * mem_size for _ in ids]\n",
    "\n",
    "                    mask_none = [int(v!=\"NONE\") for v in vals]\n",
    "                    mask_none_onehot = [[1] * mem_size for _ in ids]\n",
    "                    for v, loc, onehot in zip(vals, ids, mask_none_onehot):\n",
    "                        if v == \"NONE\":\n",
    "                            onehot[loc] = 0\n",
    "                                \n",
    "                    turn_fields[\"value\"].append(vals)\n",
    "                    turn_fields[\"ids\"].append(ids)\n",
    "                    turn_fields[\"ids_onehot\"].append(ids_onehots)\n",
    "                    turn_fields[\"mask\"].append(mask)\n",
    "                    turn_fields[\"mask_onehot\"].append(mask_onehots)\n",
    "                    turn_fields[\"mask_none\"].append(mask_none)\n",
    "                    turn_fields[\"mask_none_onehot\"].append(mask_none_onehot)\n",
    "\n",
    "                # update turn\n",
    "                for k, v in turn_fields.items():\n",
    "                    resp[k].append(v)\n",
    "                \n",
    "                snapshot_id += 1\n",
    "            \n",
    "        return resp\n",
    "    \n",
    "    def fd_num_turns(self, dial, fields):\n",
    "        return {\"ids\": len(dial[\"turns\"])}\n",
    "    \n",
    "    def fd_num_frames(self, dial, fields):\n",
    "        return {\"ids\": [len(t[\"frames\"]) for t in dial[\"turns\"]]}\n",
    "    \n",
    "    def fd_usr_utter(self, dial, fields):\n",
    "        resp = dict(value=[], ids=[], ids_pos=[], mask=[], tokens=[])\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                utter = turn[\"utterance\"]\n",
    "                tokens = self.tokenizer(utter)\n",
    "                ids = self.token_indexer(tokens)\n",
    "                resp[\"value\"].append(utter)\n",
    "                resp[\"ids\"].append(ids)\n",
    "                resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "                resp[\"tokens\"].append(tokens)\n",
    "                resp[\"mask\"].append([1] * len(tokens))\n",
    "        return resp\n",
    "    \n",
    "    def fd_sys_utter(self, dial, fields):\n",
    "        resp = dict(value=[], ids=[], ids_pos=[], mask=[], tokens=[])\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"SYSTEM\":\n",
    "                utter = turn[\"utterance\"]\n",
    "                tokens = self.tokenizer(utter)\n",
    "                ids = self.token_indexer(tokens)\n",
    "                resp[\"value\"].append(utter)\n",
    "                resp[\"ids\"].append(ids)\n",
    "                resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "                resp[\"tokens\"].append(tokens)\n",
    "                resp[\"mask\"].append([1] * len(tokens))\n",
    "        return resp\n",
    "    \n",
    "    def fd_dial_id(self, dial, fields):\n",
    "        return {\"value\": dial[\"dialogue_id\"]}\n",
    "    \n",
    "    def dial_to_fields(self, dial):\n",
    "        fields = {}\n",
    "        ordered_funcs = [\n",
    "            \"fd_dial_id\",\n",
    "            \"fd_num_turns\", \"fd_num_frames\",\n",
    "            \"fd_serv_name\", \"fd_serv_desc\", \n",
    "            \"fd_slot_name\", \"fd_slot_desc\", \"fd_slot_iscat\",\n",
    "            \"fd_slot_memory\", \"fd_slot_memory_loc\",\n",
    "            \"fd_usr_utter\", \"fd_sys_utter\"]\n",
    "        for func in ordered_funcs:\n",
    "            name = func.split(\"fd_\", maxsplit=1)[-1]\n",
    "            value = getattr(self, func)(dial, fields)\n",
    "            if value is not None:\n",
    "                fields[name] = value\n",
    "        return fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "bert_ = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = Tokenizer(bert_)\n",
    "token_indexer = TokenIndexer(bert_)\n",
    "\n",
    "train_schemas = Schemas(\"../data/train/schema.json\")\n",
    "test_schemas = Schemas(\"../data/dev/schema.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DialogueDataset(\"../data/train/dialogues_001.json\", train_schemas, tokenizer, token_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb564346eb549fb8c3d7e8a66b64591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=127), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "train_dial_sets = []\n",
    "train_dial_files = sorted(glob.glob(\"../data/train/dialogues*.json\"))\n",
    "num_workers = min(20, len(train_dial_files))\n",
    "\n",
    "def worker(filename):\n",
    "    return DialogueDataset(filename, train_schemas, tokenizer, token_indexer)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    for ds in tqdm(executor.map(worker, train_dial_files), total=len(train_dial_files)):\n",
    "        train_dial_sets.append(ds)\n",
    "\n",
    "train_ds = D.ConcatDataset(train_dial_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b847186fda3406dbb904437bb27787c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "test_dial_sets = []\n",
    "test_dial_files = sorted(glob.glob(\"../data/dev/dialogues*.json\"))\n",
    "num_workers = min(20, len(train_dial_files))\n",
    "\n",
    "def worker(filename):\n",
    "    return DialogueDataset(filename, test_schemas, tokenizer, token_indexer)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    for ds in tqdm(executor.map(worker, test_dial_files), total=len(test_dial_files)):\n",
    "        test_dial_sets.append(ds)\n",
    "\n",
    "test_ds = D.ConcatDataset(test_dial_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['restaurant_name',\n",
       "  'date',\n",
       "  'time',\n",
       "  'serves_alcohol',\n",
       "  'has_live_music',\n",
       "  'phone_number',\n",
       "  'street_address',\n",
       "  'party_size',\n",
       "  'price_range',\n",
       "  'city',\n",
       "  'cuisine']]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][\"slot_name\"][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def move_to_device(obj, device):\n",
    "    if type(obj) is list:\n",
    "        return [move_to_device(o, device) for o in obj]\n",
    "    elif type(obj) is dict:\n",
    "        return {k: move_to_device(v, device) for k, v in obj.items()}\n",
    "    elif type(obj) is torch.Tensor or isinstance(obj, nn.Module):\n",
    "        return obj.to(device)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dialogue_mini_batcher(dialogues):\n",
    "    default_padding = 0\n",
    "    batch = {}\n",
    "    for dial in dialogues:\n",
    "        # populate the batch\n",
    "        for field, data in dial.items():\n",
    "            if field not in batch:\n",
    "                batch[field] = {}\n",
    "            for attr, val in data.items():\n",
    "                if attr == \"padding\":\n",
    "                    batch[field][attr] = val\n",
    "                else:\n",
    "                    batch[field][attr] = batch[field].get(attr, [])\n",
    "                    batch[field][attr].append(val)\n",
    "\n",
    "    # padding on field attributes\n",
    "    for field_name, data in batch.items():\n",
    "        for attr in data:\n",
    "            if attr.startswith((\"ids\", \"mask\")):\n",
    "                data[attr] = padded_array(data[attr], default_padding)\n",
    "                data[attr] = torch.tensor(data[attr], device=\"cpu\") # whatif its in device0 in epoch0, then at epoch1, sent to device1\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "class DialogIterator(object):\n",
    "    \"\"\"A simple wrapper on DataLoader\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, *args, **kw):\n",
    "        self.length = None\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.iterator = D.DataLoader(dataset, batch_size, *args, **kw)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.length is None:\n",
    "            self.length = 0\n",
    "            for dial in self.dataset:\n",
    "                num_turns = dial[\"num_turns\"][\"ids\"] # num slo\n",
    "                num_services = len(dial[\"serv_name\"][\"value\"])\n",
    "                num_slots = sum([len(x) for x in dial[\"slot_name\"][\"value\"]])\n",
    "                self.length += num_turns * num_services * num_slots\n",
    "            self.length = int(self.length / self.batch_size)\n",
    "        return self.length\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.iterator:\n",
    "            num_turns = batch[\"usr_utter\"][\"ids\"].shape[1]\n",
    "            num_services = batch[\"serv_desc\"][\"ids\"].shape[1]\n",
    "            num_slots = batch[\"slot_desc\"][\"ids\"].shape[2]\n",
    "            for turnid in range(num_turns):\n",
    "                for serviceid in range(num_services):\n",
    "                    for slotid in range(num_slots):\n",
    "                        inputs = dict(turnid=turnid, serviceid=serviceid, slotid=slotid)\n",
    "                        inputs.update(batch)\n",
    "                        yield inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_turns ids --> torch.Size([1])\n",
      "num_frames ids --> torch.Size([1, 24])\n",
      "serv_desc ids --> torch.Size([1, 1, 10])\n",
      "serv_desc ids_pos --> torch.Size([1, 1, 10])\n",
      "serv_desc mask --> torch.Size([1, 1, 10])\n",
      "slot_desc ids --> torch.Size([1, 1, 11, 12])\n",
      "slot_desc ids_pos --> torch.Size([1, 1, 11, 12])\n",
      "slot_desc mask --> torch.Size([1, 1, 11, 12])\n",
      "slot_iscat ids --> torch.Size([1, 1, 11])\n",
      "slot_iscat mask --> torch.Size([1, 1, 11])\n",
      "slot_memory ids --> torch.Size([1, 12, 29, 10])\n",
      "slot_memory ids_desc --> torch.Size([1, 12, 29, 40])\n",
      "slot_memory ids_iscat --> torch.Size([1, 12, 29, 2])\n",
      "slot_memory ids_pos --> torch.Size([1, 12, 29])\n",
      "slot_memory ids_memsize --> torch.Size([1, 12])\n",
      "slot_memory mask --> torch.Size([1, 12, 29, 10])\n",
      "slot_memory mask_desc --> torch.Size([1, 12, 29, 40])\n",
      "slot_memory_loc ids --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc ids_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "slot_memory_loc mask --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc mask_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "slot_memory_loc mask_none --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc mask_none_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "usr_utter ids --> torch.Size([1, 12, 25])\n",
      "usr_utter ids_pos --> torch.Size([1, 12, 25])\n",
      "usr_utter mask --> torch.Size([1, 12, 25])\n",
      "sys_utter ids --> torch.Size([1, 12, 31])\n",
      "sys_utter ids_pos --> torch.Size([1, 12, 31])\n",
      "sys_utter mask --> torch.Size([1, 12, 31])\n"
     ]
    }
   ],
   "source": [
    "def get_sample(ds, size=1):\n",
    "    return next(iter(DialogIterator(ds, size, collate_fn=dialogue_mini_batcher)))\n",
    "\n",
    "def print_shapes(ds):\n",
    "    it = get_sample(ds, size=1)\n",
    "    for field, val in it.items():\n",
    "        if type(val) is dict:\n",
    "            for attr in val:\n",
    "                if attr.startswith(\"ids\") or attr.startswith(\"mask\"):\n",
    "                    print(field, attr, \"-->\", val[attr].shape)\n",
    "                    \n",
    "\n",
    "# TODO: why mem ids, and mem loc size is diff by 1?\n",
    "print_shapes(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertModel, BertConfig\n",
    "from allennlp.training.metrics import BooleanAccuracy, CategoricalAccuracy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDownstream(nn.Module):\n",
    "    # https://huggingface.co/pytorch-transformers/model_doc/bert.html\n",
    "    # https://github.com/hanxiao/bert-as-service/blob/master/docs/section/faq.rst#id6\n",
    "    \n",
    "    def __init__(self, btype, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.emb = BertModel.from_pretrained(btype, output_hidden_states=True)\n",
    "        for name, param in self.emb.named_parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return 768\n",
    "    \n",
    "    def forward(self, input_ids, position_ids=None, attention_mask=None, flat=(1,-1)):\n",
    "        sh = list(input_ids.shape)\n",
    "        \n",
    "        input_ids = input_ids.flatten(*flat).long()\n",
    "        if position_ids is not None:\n",
    "            position_ids = position_ids.flatten(*flat).long()\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.flatten(*flat).long()\n",
    "        outputs = self.emb(input_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # average of hidden layers: bs->bse\n",
    "        pooled = torch.mean(torch.stack([outputs[2][i] for i in range(2, 11)]), dim=0)\n",
    "        \n",
    "        # unflatten\n",
    "        pooled = pooled.view(sh + [-1])\n",
    "        \n",
    "        return pooled # (..., e)\n",
    "\n",
    "\n",
    "class CandidateSelector(nn.Module):\n",
    "    \"\"\"\n",
    "    memory -- represents temporal hash table of text values, that monotonically grows\n",
    "    memory_desc -- represents sequential description to every value in hash table\n",
    "    slot, utter -- represent query/key descriptions\n",
    "    \n",
    "    The idea is that we model a hash function \n",
    "        F: slot, utter, time -> memory_location\n",
    "    \n",
    "    This is a mix of ideas from\n",
    "        - Memory Networks by Jason Weston, FAIR\n",
    "        - E2E Memory Networks by Sukhbaatar, NYU/FAIR\n",
    "        - Pointer Networks by Oriol Vinayls, Google Brain\n",
    "        - Alignment and Translation by Bahdanau, MILA\n",
    "    \n",
    "        - Weston and Sukhbaatar demonstrate memory models on Facebook bAbI tasks. that capture some temporal challenges.\n",
    "            while Vinayls tweaks the idea of Bahdanau's attention, to classification/regress targets represented in latent space.\n",
    "            (NOTE: their motivation is subtly different, but this explanation still stands valid)\n",
    "    \n",
    "    Unique contribution:\n",
    "        - Explore the problem where memory grows and has temporal information.\n",
    "        - Model a hash function that understands temporal (just like Vinayls) but but \n",
    "            new challenges are:\n",
    "            - applied to dialog state (no one else did before), where the hash function has additional challenges of dealing with \n",
    "                guessing user behavior dist. and language subtlities (eg: coreference and ellipsis resolutions.)\n",
    "            - the hash function is learning from real world data, unlike previous works where toy data are used. \n",
    "                the hash key is can change just because user explicitly/implicitly says something..\n",
    "            - the model is setup in a way it supports growth, and scale across domains. Sukhbaatar's approach is fixed (verify again!)\n",
    "            \n",
    "    Viewpoints/Quesitons\n",
    "        - Where does meta data belong. such as attr -- iscatategorical. should Hash function figure out everything..\n",
    "            or the memory may cache this information too as they appear in the history (at inference time, this will have cumulative error)?\n",
    "        - one way to think is that, the memory representation remains static.. and the hash function figures it out\n",
    "            then should the slot descriptions/serv desc for resp. memory values be tagged to the representation?\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = BertDownstream(\"bert-base-uncased\")\n",
    "        emb_dim = self.emb.output_dim\n",
    "        \n",
    "        self.l0 = nn.LSTM(emb_dim, emb_dim, batch_first=True, num_layers=2) # encode utter\n",
    "        self.l1 = nn.LSTM(emb_dim, emb_dim, batch_first=True, num_layers=2) # encode memory\n",
    "        self.l2 = nn.LSTM(emb_dim, emb_dim, batch_first=True, num_layers=2) # encode query slot\n",
    "        \n",
    "        self.turn_pos = nn.Linear(1, emb_dim)\n",
    "        self.mem_pos = nn.Linear(1, emb_dim)\n",
    "        \n",
    "        # attentions\n",
    "        self.l3 = nn.Linear(2*emb_dim, emb_dim)\n",
    "        self.l4 = nn.Linear(emb_dim, 1)\n",
    "        self.l5 = nn.Linear(emb_dim, 1)\n",
    "         \n",
    "        # metrics\n",
    "        self.acc = CategoricalAccuracy()\n",
    "        self.goal_acc = CategoricalAccuracy()\n",
    "        \n",
    "        #self.register_buffer(\"utter_state\", None)\n",
    "\n",
    "        # init weights: classifier's performance changes heavily on these\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.startswith((\"l0.\", \"11.\", \"l2.\")):\n",
    "                print(\"Initializing bias/weights of \", name)\n",
    "                if \"weight\" in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    param.data.fill_(0.01)\n",
    "\n",
    "    def get_metrics(self, reset=False, goal_reset=False):\n",
    "        return dict(\n",
    "            acc=self.acc.get_metric(reset), # avg per slot\n",
    "            goal_acc=self.goal_acc.get_metric(goal_reset), # avg per turn\n",
    "        )\n",
    "    \n",
    "    def encode_utter(self, batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        usr_utter, usr_mask, usr_pos = batch[\"usr_utter\"][\"ids\"][:,turnid,:], batch[\"usr_utter\"][\"mask\"][:,turnid,:], batch[\"usr_utter\"][\"ids_pos\"][:,turnid,:]\n",
    "        sys_utter, sys_mask, sys_pos = batch[\"sys_utter\"][\"ids\"][:,turnid,:], batch[\"sys_utter\"][\"mask\"][:,turnid,:], batch[\"sys_utter\"][\"ids_pos\"][:,turnid,:]\n",
    "        \n",
    "        usr_utter = self.emb(usr_utter, position_ids=usr_pos, attention_mask=usr_mask) # bse\n",
    "        sys_utter = self.emb(sys_utter, position_ids=sys_pos, attention_mask=sys_mask) # bse\n",
    "        \n",
    "        utter = torch.cat([sys_utter, usr_utter], dim=1) # b2se\n",
    "\n",
    "        utter, utter_h = self.l0(utter)\n",
    "        \n",
    "        posx = torch.zeros(usr_utter.shape[0], 1, device=usr_utter.device) + turnid\n",
    "        \n",
    "        return utter_h[0][-1] + self.turn_pos(posx.float()) # be\n",
    "\n",
    "    def encode_slot_desc(self, batch):\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        slotid = batch[\"slotid\"]\n",
    "        \n",
    "        desc = batch[\"slot_desc\"][\"ids\"][:,serviceid,slotid,:] # bt\n",
    "        desc_pos = batch[\"slot_desc\"][\"ids_pos\"][:,serviceid,slotid,:]\n",
    "        desc_mask = batch[\"slot_desc\"][\"mask\"][:,serviceid,slotid,:]\n",
    "        sh = desc.shape\n",
    "        desc = self.emb(desc, position_ids=desc_pos, attention_mask=desc_mask) # bte\n",
    "        \n",
    "        serv_desc = batch[\"serv_desc\"][\"ids\"][:,serviceid,:] # bt\n",
    "        serv_desc_pos = batch[\"serv_desc\"][\"ids_pos\"][:,serviceid,:]\n",
    "        serv_desc_mask = batch[\"serv_desc\"][\"mask\"][:,serviceid,:]\n",
    "        sh1 = serv_desc.shape\n",
    "        serv_desc = self.emb(serv_desc, serv_desc_pos, serv_desc_mask) # bte\n",
    "\n",
    "        desc = torch.cat([desc, serv_desc], dim=1) # d2te\n",
    "        desc, desc_h = self.l2(desc)\n",
    "\n",
    "        desc_h = desc_h[0][-1]\n",
    "    \n",
    "        return desc_h # be\n",
    "    \n",
    "    def encode_memory(self, batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        slotid = batch[\"slotid\"]\n",
    "        \n",
    "        # Encode memory\n",
    "        mem = batch[\"slot_memory\"][\"ids\"][:,turnid,:] # bms\n",
    "        mem_mask = batch[\"slot_memory\"][\"mask\"][:,turnid,:] \n",
    "        mem_pos = batch[\"slot_memory\"][\"ids_pos\"][:,turnid,:] # position of memory cell, not tokens. bm\n",
    "        sh = mem.shape\n",
    "        \n",
    "        mem_pos_r = mem_pos[:,:,None].repeat(1,1,sh[-1])# bm->bms\n",
    "        mem = self.emb(mem, position_ids=mem_pos_r, attention_mask=mem_mask, flat=(0, 1)) # bmse\n",
    "        \n",
    "        mem, mem_h = self.l1(mem.flatten(0,1))\n",
    "        mem_h = (mem_h[0][-1] + mem_h[1][-1]).view(sh[0], sh[1], -1)\n",
    "        \n",
    "        return mem_h + self.mem_pos(mem_pos.unsqueeze(-1).float()) # bme\n",
    "    \n",
    "    def get_key(self, utter, slot, attn=None):\n",
    "        key = self.l3(torch.cat([utter, slot], dim=-1)) # b2e->be\n",
    "        return key # be\n",
    "    \n",
    "    def get_value(self, memory, key, layers=1):\n",
    "        # memory: bme, key: be\n",
    "        attn = self.l5(memory * key.unsqueeze(1)).squeeze(-1)\n",
    "        attn = F.softmax(attn, -1)\n",
    "        \n",
    "        output = memory * attn.unsqueeze(-1)\n",
    "        output = self.l4(output).squeeze(-1) # bm1\n",
    "        output = F.softmax(output, dim=-1)\n",
    "        \n",
    "        return output, attn # bm\n",
    "        \n",
    "    def forward(self, **batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        slotid = batch[\"slotid\"]\n",
    "        \n",
    "        # doc: GRU outputs [batch, seq, emb * dir] [layers * dir, batch, emb]\n",
    "\n",
    "        # get fixed size encodings\n",
    "        utter = self.encode_utter(batch)\n",
    "        slot_desc = self.encode_slot_desc(batch)\n",
    "        memory = self.encode_memory(batch)\n",
    "        \n",
    "        key = self.get_key(utter, slot_desc)\n",
    "        score, attn = self.get_value(memory, key)\n",
    "        \n",
    "        output = {\"score\": score, \"mem_attn\": attn} # bsm\n",
    "\n",
    "        if \"slot_memory_loc\" in batch:\n",
    "            target = batch[\"slot_memory_loc\"]\n",
    "            memsize = target[\"ids_onehot\"].shape[-1]\n",
    "            pred_score = score.view(-1, memsize) # bsm->bs,m \n",
    "            \n",
    "            # calc loss\n",
    "            target_score_oh = target[\"ids_onehot\"][:,turnid,serviceid,slotid,:].float() # bm\n",
    "            target_mask_oh = target[\"mask_onehot\"][:,turnid,serviceid,slotid,:].float()\n",
    "            output[\"loss\"] = F.binary_cross_entropy(pred_score, target_score_oh, target_mask_oh).unsqueeze(0) # don't return scalar\n",
    "            \n",
    "            # log metrics\n",
    "            target_score = target[\"ids\"][:,turnid,serviceid,slotid].float() # [batch, slots]\n",
    "            target_mask = (target[\"mask\"][:,turnid,serviceid,slotid] * target[\"mask_none\"][:,turnid,serviceid,slotid]).float()\n",
    "            self.acc(score, target_score, target_mask)\n",
    "            self.goal_acc(score, target_score, target_mask)\n",
    "            \n",
    "            output[\"target_ids\"] = target_score\n",
    "            output[\"pred_ids\"] = torch.argmax(score, dim=-1)\n",
    "            output[\"mask\"] = target[\"mask\"][:,turnid,serviceid,slotid].float()\n",
    "            output[\"mask_none\"] = target[\"mask_none\"][:,turnid,serviceid,slotid].float()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.tensorboard_writer import TensorboardWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module(m):\n",
    "    if type(m) is nn.DataParallel:\n",
    "        return m.module\n",
    "    return m\n",
    "\n",
    "def train(model, optimizer, batch_size, num_epochs, train_ds, test_ds, device):\n",
    "    model = model.train()\n",
    "    current_batch = 0\n",
    "    tensorboard = TensorboardWriter(\n",
    "        get_batch_num_total=lambda: current_batch,\n",
    "        summary_interval=10,\n",
    "        serialization_dir=\"../data/tensorboard/\"\n",
    "    )\n",
    "    \n",
    "    histogram_weights = [name for name, p in model.named_parameters() if not \".emb.\" in name]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_iter = DialogIterator(train_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "        num_batches = len(train_iter) \n",
    "        if test_ds:\n",
    "            test_iter = DialogIterator(test_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "            num_batches += len(test_iter)\n",
    "        \n",
    "        with tqdm(total=num_batches) as pbar:\n",
    "            # train\n",
    "            pbar.set_description(\"Train {}\".format(epoch))\n",
    "            model = model.train()\n",
    "            train_iter = DialogIterator(train_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "            \n",
    "            # to know when the dialog and service changes\n",
    "            prev_turnid = -1\n",
    "            \n",
    "            for i, batch in enumerate(train_iter):\n",
    "                metrics = OrderedDict()\n",
    "                batch = move_to_device(batch, device)\n",
    "                current_batch += 1\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(**batch)\n",
    "                output[\"loss\"] = output[\"loss\"].mean()\n",
    "                output[\"loss\"].backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (output[\"mask\"] * output[\"mask_none\"]).sum() > 0:\n",
    "                    num_turns = batch[\"usr_utter\"][\"ids\"].shape[1]\n",
    "                    num_slots = batch[\"slot_desc\"][\"ids\"].shape[2]\n",
    "                    goal_reset = batch[\"turnid\"] == num_turns - 1\n",
    "                    reset = prev_turnid != batch[\"turnid\"]\n",
    "                    \n",
    "                    metrics.update(module(model).get_metrics(reset, goal_reset))\n",
    "                    metrics[\"loss\"] = output[\"loss\"].item()\n",
    "\n",
    "                    # update tensorboard logs\n",
    "                    tensorboard.add_train_scalar(\"loss\", metrics[\"loss\"], timestep=current_batch)\n",
    "                    tensorboard.log_metrics(train_metrics=metrics, epoch=current_batch)\n",
    "                    tensorboard.add_train_histogram(\"target_ids\", output[\"target_ids\"])\n",
    "                    tensorboard.add_train_histogram(\"pred_ids\", output[\"pred_ids\"])\n",
    "                    tensorboard.add_train_histogram(\"mem_attn\", output[\"mem_attn\"])\n",
    "                    tensorboard.log_parameter_and_gradient_statistics(model, None)\n",
    "\n",
    "                    metrics.update(turnid=batch[\"turnid\"], servid=batch[\"serviceid\"], slotid=batch[\"slotid\"])\n",
    "                    pbar.set_postfix(metrics)\n",
    "                    \n",
    "                prev_turnid = batch[\"turnid\"]\n",
    "                pbar.update(1)\n",
    "\n",
    "            # test\n",
    "            if test_ds:\n",
    "                pbar.set_description(\"Test {}\".format(epoch))\n",
    "                with torch.no_grad():\n",
    "                    model = model.eval()\n",
    "                    prev_turnid = -1\n",
    "                    for i, batch in enumerate(test_iter):\n",
    "                        metrics = OrderedDict()\n",
    "                        batch = move_to_device(batch, device)\n",
    "                        current_batch += 1\n",
    "                        output = model(**batch)\n",
    "                        output[\"loss\"] = output[\"loss\"].mean()\n",
    "                        # at each new turn\n",
    "                        if prev_turnid != batch[\"turnid\"]:\n",
    "                            metrics.update(module(model).get_metrics(reset=True, goal_reset=True))\n",
    "                        else:\n",
    "                            curr_met = module(model).get_metrics(reset=True)\n",
    "                            metrics.update(acc=curr_met[\"acc\"])\n",
    "                        metrics[\"loss\"] = output[\"loss\"].item()\n",
    "                        metrics.update(turnid=batch[\"turnid\"], servid=batch[\"serviceid\"], slotid=batch[\"slotid\"])\n",
    "                        pbar.set_postfix(metrics)\n",
    "                        prev_turnid = batch[\"turnid\"]\n",
    "                        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"../data/model0.pkl\")\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove tensorboard logs\n",
      "set number of devices\n",
      "loading model\n",
      "Initializing bias/weights of  l0.weight_ih_l0\n",
      "Initializing bias/weights of  l0.weight_hh_l0\n",
      "Initializing bias/weights of  l0.bias_ih_l0\n",
      "Initializing bias/weights of  l0.bias_hh_l0\n",
      "Initializing bias/weights of  l0.weight_ih_l1\n",
      "Initializing bias/weights of  l0.weight_hh_l1\n",
      "Initializing bias/weights of  l0.bias_ih_l1\n",
      "Initializing bias/weights of  l0.bias_hh_l1\n",
      "Initializing bias/weights of  l2.weight_ih_l0\n",
      "Initializing bias/weights of  l2.weight_hh_l0\n",
      "Initializing bias/weights of  l2.bias_ih_l0\n",
      "Initializing bias/weights of  l2.bias_hh_l0\n",
      "Initializing bias/weights of  l2.weight_ih_l1\n",
      "Initializing bias/weights of  l2.weight_hh_l1\n",
      "Initializing bias/weights of  l2.bias_ih_l1\n",
      "Initializing bias/weights of  l2.bias_hh_l1\n",
      "started training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4d2083b8dd419bb96f626199c5f1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Remove tensorboard logs\")\n",
    "!rm -rf ../data/tensorboard/*\n",
    "\n",
    "print(\"set number of devices\") # not sure we can in jupyter once program already kicked in the first time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = \"cuda\"\n",
    "\n",
    "print(\"loading model\")\n",
    "model = CandidateSelector()\n",
    "#model = nn.DataParallel(model)\n",
    "model = move_to_device(model, device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "train_samples = [train_ds[i] for i in range(100)]\n",
    "test_samples = [test_ds[i] for i in range(10)]\n",
    "\n",
    "print(\"started training\")\n",
    "train(\n",
    "    model=model,\n",
    "    optimizer=optim,\n",
    "    train_ds=train_samples,\n",
    "    test_ds=None, #test_samples,\n",
    "    device=device,\n",
    "    num_epochs=20,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac52ec8fd5074e16a72c14cd31d0ea15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Goal Acc:  0.0\n",
      "Avg Joint Goal Acc:  0.09090909090909091\n",
      "\n",
      "\n",
      "   dialid    num_turns    turnid    servid  servname         memsize  slotname         tgt_val      tgt_loc  prd_val      prd_loc    correct    mask \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  restaurant_name  NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  date             NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  time             NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  serves_alcohol   NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  has_live_music   NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  phone_number     NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  street_address   NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  party_size       NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  price_range      NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  city             NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         0         0  Restaurants_1         19  cuisine          NONE               0  Indian            16          0       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  restaurant_name  NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  time             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  price_range      NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  city             San Jose          19  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         1         0  Restaurants_1         20  cuisine          NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  restaurant_name  NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  time             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  price_range      NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  city             San Jose          19  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         2         0  Restaurants_1         20  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  restaurant_name  NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  time             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  price_range      NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  city             San Jose          19  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         3         0  Restaurants_1         21  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  restaurant_name  NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  time             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  price_range      NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  city             San Jose          19  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         4         0  Restaurants_1         22  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  restaurant_name  NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  time             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  price_range      NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  city             San Jose          19  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         5         0  Restaurants_1         23  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  restaurant_name  NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  time             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  price_range      moderate          11  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  city             Palo Alto         24  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         6         0  Restaurants_1         25  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  restaurant_name  Bird Dog          25  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  time             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  price_range      moderate          11  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  city             Palo Alto         24  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         7         0  Restaurants_1         26  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  restaurant_name  Bird Dog          25  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  date             NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  time             11:30 am          26  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  party_size       NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  price_range      moderate          11  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  city             Palo Alto         24  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         8         0  Restaurants_1         27  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  restaurant_name  Bird Dog          25  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  date             today             27  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  time             11:30 am          26  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  party_size       2                  5  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  price_range      moderate          11  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  city             Palo Alto         24  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12         9         0  Restaurants_1         28  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  restaurant_name  Bird Dog          25  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  date             today             27  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  time             11:30 am          26  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  party_size       2                  5  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  price_range      moderate          11  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  city             Palo Alto         24  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        10         0  Restaurants_1         28  cuisine          American          17  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  restaurant_name  Bird Dog          25  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  date             today             27  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  time             11:30 am          26  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  serves_alcohol   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  has_live_music   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  phone_number     NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  street_address   NONE               0  NONE               0        100       0 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  party_size       2                  5  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  price_range      moderate          11  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  city             Palo Alto         24  NONE               0          0       1 \n",
      "\n",
      "  1_00000           12        11         0  Restaurants_1         29  cuisine          American          17  NONE               0          0       1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def infer_batch(model, test_ds, device):\n",
    "    result_table = []\n",
    "    \n",
    "    # all samples\n",
    "    avg_goal_acc = 0\n",
    "    avg_joint_acc = 0\n",
    "\n",
    "    model = model.eval()\n",
    "    \n",
    "    batch_iterator = D.DataLoader(test_ds, 1, collate_fn=dialogue_mini_batcher)\n",
    "    with tqdm(batch_iterator, total=len(batch_iterator)) as pbar:\n",
    "        for batch in pbar:\n",
    "            batch = move_to_device(batch, device)\n",
    "\n",
    "            # iterate over dialog turn/services\n",
    "            num_turns = batch[\"usr_utter\"][\"ids\"].shape[1]\n",
    "            num_services = batch[\"serv_desc\"][\"ids\"].shape[1]\n",
    "            true_batch_size = batch[\"usr_utter\"][\"ids\"].shape[0]\n",
    "\n",
    "            # across one batch\n",
    "            total_goal_acc = {k: 0 for k in range(true_batch_size)} \n",
    "            total_joint_acc = {k: 0 for k in range(true_batch_size)}\n",
    "            unpadded_num_turns = {k: 0 for k in range(true_batch_size)} \n",
    "\n",
    "            for turnid in range(num_turns):\n",
    "                # across one turn\n",
    "                goal_acc = {k: 0 for k in range(true_batch_size)} # per batch counter\n",
    "                joint_acc = {k: 1 for k in range(true_batch_size)} # per batch counterr, binary 1/0\n",
    "                unpadded_num_slots = {k: 0 for k in range(true_batch_size)}\n",
    "\n",
    "                for sid in range(num_services):\n",
    "                    inputs = dict(turnid=turnid, serviceid=sid)\n",
    "                    inputs.update(batch)\n",
    "                    with torch.no_grad():\n",
    "                        result = model(**inputs)\n",
    "\n",
    "                    # iterate step by step now.\n",
    "                    for b in range(true_batch_size):\n",
    "\n",
    "                        fields = dict(\n",
    "                            prd_mem_loc = result[\"pred_ids\"][b], # B,slot\n",
    "                            tgt_mem_loc = result[\"target_ids\"][b],\n",
    "                            mask = result[\"mask\"][b],\n",
    "                            mask_none = result[\"mask_none\"][b], # 1 -> target is not None\n",
    "                            dial_id = inputs[\"dial_id\"][\"value\"][b],\n",
    "                            serv_name = inputs[\"serv_name\"][\"value\"][b],\n",
    "                            slot_name = inputs[\"slot_name\"][\"value\"][b],\n",
    "                            num_turns = inputs[\"num_turns\"][\"ids\"][b],\n",
    "                            memory = inputs[\"slot_memory\"][\"value\"][b], # B,turn,memory\n",
    "                        )\n",
    "\n",
    "                        for slotid, (prd_loc, tgt_loc) in enumerate(zip(fields[\"prd_mem_loc\"], fields[\"tgt_mem_loc\"])):\n",
    "                            try:\n",
    "                                memory = fields[\"memory\"][turnid]\n",
    "                                # clip the locations.. they somehow predict in padding regions!! Make it NONE\n",
    "                                prd_loc = int(prd_loc.item()) if prd_loc < len(memory) else -1\n",
    "                                tgt_loc = int(tgt_loc.item()) if tgt_loc < len(memory) else -1\n",
    "\n",
    "                                prd_val = memory[prd_loc] if prd_loc >= 0 else \"<UNK>\"\n",
    "                                tgt_val = memory[tgt_loc] if tgt_loc >= 0 else \"<UNK>\"\n",
    "                                mask = fields[\"mask\"][slotid].item()\n",
    "                                mask_none = fields[\"mask_none\"][slotid].item()\n",
    "                                dialid = fields[\"dial_id\"]\n",
    "                                servname = fields[\"serv_name\"][sid]\n",
    "                                slotname = fields[\"slot_name\"][sid][slotid]\n",
    "                                num_turns = fields[\"num_turns\"].item() / 2 # usr-sys turn pairs\n",
    "                            except: # padding issues.\n",
    "                                continue\n",
    "                            \n",
    "                            # update acc counter. Multiply mask_none to ignore acc on NONE slots\n",
    "                            if mask * mask_none == 1: \n",
    "                                goal_acc[b] += int(prd_loc == tgt_loc)\n",
    "                                joint_acc[b] *= int(prd_loc == tgt_loc)\n",
    "                                unpadded_num_slots[b] += 1\n",
    "\n",
    "                            item = OrderedDict(\n",
    "                                dialid = fields[\"dial_id\"],\n",
    "                                num_turns = num_turns,\n",
    "                                turnid = turnid,\n",
    "                                servid = sid,\n",
    "                                servname = fields[\"serv_name\"][sid],\n",
    "                                memsize = len(memory),\n",
    "                                slotname = slotname,\n",
    "                                tgt_val = tgt_val,\n",
    "                                tgt_loc = tgt_loc,\n",
    "                                prd_val = prd_val,\n",
    "                                prd_loc = prd_loc,\n",
    "                                correct = 100*int(tgt_loc == prd_loc),\n",
    "                                mask = (mask * mask_none),\n",
    "                            )\n",
    "\n",
    "                            result_table.append(item)\n",
    "\n",
    "                # update acc across the batch\n",
    "                for k in range(true_batch_size):\n",
    "                    total_goal_acc[k] += goal_acc[k] / max(unpadded_num_slots[k], 1)\n",
    "                    total_joint_acc[k] += joint_acc[k]\n",
    "                    unpadded_num_turns[k] += int(unpadded_num_slots[k] > 0)\n",
    "\n",
    "            # update avg\n",
    "            for k in range(true_batch_size):\n",
    "                avg_goal_acc += total_goal_acc[k] / unpadded_num_turns[k]\n",
    "                avg_joint_acc += total_joint_acc[k] / unpadded_num_turns[k]\n",
    "        \n",
    "    print(\"Avg Goal Acc: \", avg_goal_acc / len(test_ds))\n",
    "    print(\"Avg Joint Goal Acc: \", avg_joint_acc / len(test_ds))\n",
    "    print()\n",
    "    \n",
    "    print(tabulate(\n",
    "        [list(item.values()) for item in result_table],\n",
    "        list(result_table[0].keys()),\n",
    "        \"fancy_grid\",\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    \n",
    "litmus_test_samples = [train_ds[0]]\n",
    "infer_batch(model, litmus_test_samples, device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "226px",
    "width": "226px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1510px",
    "right": "97px",
    "top": "135px",
    "width": "403px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

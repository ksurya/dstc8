{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as D\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import lru_cache\n",
    "from collections import OrderedDict\n",
    "from types import SimpleNamespace\n",
    "from collections.abc import Iterable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from ipdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        self.bert = bert\n",
    "    \n",
    "    def __call__(self, text, include_sep=True):\n",
    "        tokens = self.bert.tokenize(text)\n",
    "        if include_sep:\n",
    "            tokens.insert(0, \"[CLS]\")\n",
    "            tokens.append(\"[SEP]\")\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "class TokenIndexer:\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        self.bert = bert\n",
    "        \n",
    "    def inv(self, *args, **kw):\n",
    "        # tokens MUST be list, tensor doesn't work.\n",
    "        return self.bert.convert_ids_to_tokens(*args, **kw)\n",
    "        \n",
    "    def __call__(self, *args, **kw):\n",
    "        return self.bert.convert_tokens_to_ids(*args, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def label_binarize(labels, classes):\n",
    "    # labels: np.array or tensor [batch, 1]\n",
    "    # classes: [..] list of classes\n",
    "    # weirdly,`sklearn.preprocessing.label_binarize` returns [1] or [0]\n",
    "    # instead of onehot ONLY when executing in this script!\n",
    "    vectors = [np.zeros(len(classes)) for _ in labels]\n",
    "    for i, label in enumerate(labels):\n",
    "        for j, c in enumerate(classes):\n",
    "            if c == label:\n",
    "                vectors[i][j] = 1\n",
    "    return np.array(vectors)\n",
    "    \n",
    "\n",
    "def label_inv_binarize(vectors, classes):\n",
    "    # labels: np.array or tensor [batch, classes]\n",
    "    # classes: [..] list of classes\n",
    "    # follows sklearn LabelBinarizer.inverse_transform()\n",
    "    # given all zeros, predicts label at index 0, instead of returning none!\n",
    "    # sklearn doesn't have functional API of inverse transform\n",
    "    labels = []\n",
    "    for each in vectors:\n",
    "        index = np.argmax(each)\n",
    "        labels.append(classes[index])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def padded_array(array, value=0):\n",
    "    # TODO: this does not do type checking; and wow it can be slow on strings.\n",
    "    # expects array to have fixed _number_ of dimensions\n",
    "    \n",
    "    # resolve the shape of padded array\n",
    "    shape_index = {}\n",
    "    queue = [(array, 0)]\n",
    "    while queue:\n",
    "        subarr, dim = queue.pop(0)\n",
    "        shape_index[dim] = max(shape_index.get(dim, -1), len(subarr))\n",
    "        for x in subarr:\n",
    "            if isinstance(x, Iterable) and not isinstance(x, str):\n",
    "                queue.append((x, dim+1))\n",
    "    shape = [shape_index[k] for k in range(max(shape_index) + 1)]\n",
    "    \n",
    "    # fill the values \n",
    "    padded = np.ones(shape) * value\n",
    "    queue = [(array, [])]\n",
    "    while queue:\n",
    "        subarr, index = queue.pop(0)\n",
    "        for j, x in enumerate(subarr):\n",
    "            if isinstance(x, Iterable):\n",
    "                queue.append((x, index + [j]))\n",
    "            else:\n",
    "                padded[tuple(index + [j])] = x\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "class Schemas(object):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        with open(filepath) as f:\n",
    "            self.index = {}\n",
    "            for schema in json.load(f):\n",
    "                service_name = schema[\"service_name\"]\n",
    "                self.index[service_name] = schema\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get(self, service):\n",
    "        result = dict(\n",
    "            # service\n",
    "            name=service,\n",
    "            desc=self.index[service][\"description\"],\n",
    "            \n",
    "            # slots\n",
    "            slot_name=[],\n",
    "            slot_desc=[],\n",
    "            slot_iscat=[], \n",
    "            slot_vals=[], # collected only for cat slots.. not sure if that makes sense\n",
    "\n",
    "            # intents\n",
    "            intent_name=[],\n",
    "            intent_desc=[],\n",
    "            intent_istrans=[],\n",
    "            intent_reqslots=[],\n",
    "            intent_optslots=[],\n",
    "            intent_optvals=[],\n",
    "        )\n",
    "\n",
    "        for slot in self.index[service][\"slots\"]:\n",
    "            result[\"slot_name\"].append(slot[\"name\"])\n",
    "            result[\"slot_desc\"].append(slot[\"description\"])\n",
    "            result[\"slot_iscat\"].append(slot[\"is_categorical\"])\n",
    "            result[\"slot_vals\"].append(slot[\"possible_values\"])\n",
    "        \n",
    "        for intent in self.index[service][\"intents\"]:\n",
    "            result[\"intent_name\"].append(intent[\"name\"])\n",
    "            result[\"intent_desc\"].append(intent[\"description\"])\n",
    "            result[\"intent_istrans\"].append(intent[\"is_transactional\"])\n",
    "            result[\"intent_reqslots\"].append(intent[\"required_slots\"])\n",
    "            result[\"intent_optslots\"].append(list(intent[\"optional_slots\"].keys()))\n",
    "            result[\"intent_optvals\"].append(list(intent[\"optional_slots\"].values()))\n",
    "\n",
    "        return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueDataset(D.Dataset):\n",
    "    def __init__(self, filename, schemas, tokenizer, token_indexer):\n",
    "        with open(filename) as f:\n",
    "            self.ds = json.load(f)\n",
    "        self.schemas = schemas\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexer = token_indexer\n",
    "        self.dialogues = []\n",
    "        for dial in self.ds:\n",
    "            fields = self.dial_to_fields(dial)\n",
    "            self.dialogues.append(fields)\n",
    "        self.schemas = None\n",
    "        self.tokenizer = None\n",
    "        self.token_indexer = None\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dialogues[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dialogues)\n",
    "    \n",
    "    def fd_serv_name(self, dial, fields):\n",
    "        resp = dict(value=[])\n",
    "        for service in dial[\"services\"]:\n",
    "            resp[\"value\"].append(service)\n",
    "        return resp\n",
    "        \n",
    "    def fd_serv_desc(self, dial, fields):\n",
    "        resp = dict(value=[], tokens=[], ids=[], ids_pos=[], mask=[])\n",
    "        for service in dial[\"services\"]:\n",
    "            desc = self.schemas.get(service)[\"desc\"]\n",
    "            tokens = self.tokenizer(desc)\n",
    "            ids = self.token_indexer(tokens)\n",
    "            resp[\"value\"].append(desc)\n",
    "            resp[\"tokens\"].append(tokens)\n",
    "            resp[\"ids\"].append(ids)\n",
    "            resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "            resp[\"mask\"].append([1] * len(ids))\n",
    "        return resp\n",
    "    \n",
    "    def fd_slot_name(self, dial, fields):\n",
    "        resp = {\"value\": []}\n",
    "        for serv in dial[\"services\"]:\n",
    "            schema = self.schemas.get(serv)\n",
    "            resp[\"value\"].append(schema[\"slot_name\"])\n",
    "        return resp\n",
    "    \n",
    "    def fd_slot_desc(self, dial, fields):\n",
    "        resp = dict(value=[], tokens=[], ids=[], ids_pos=[], mask=[])\n",
    "        for serv in dial[\"services\"]:\n",
    "            s_desc = self.schemas.get(serv)[\"slot_desc\"]\n",
    "            s_tokens = [self.tokenizer(d) for d in s_desc]\n",
    "            s_ids = [self.token_indexer(d) for d in s_tokens]\n",
    "            s_mask = [[1] * len(d) for d in s_tokens]\n",
    "            resp[\"value\"].append(s_desc)\n",
    "            resp[\"tokens\"].append(s_tokens)\n",
    "            resp[\"ids\"].append(s_ids)\n",
    "            resp[\"ids_pos\"].append([list(range(1, len(i) + 1)) for i in s_ids])\n",
    "            resp[\"mask\"].append(s_mask)\n",
    "        return resp\n",
    "\n",
    "    def fd_slot_memory(self, dial, fields):\n",
    "        # TODO: iscat feature..\n",
    "        # memory is a sequence of slot tagger values across all frames in a dial.. that grows per turn\n",
    "        # maintain snapshot at each turn\n",
    "        resp = dict(\n",
    "            value=[], # unfeaturized memory\n",
    "            value_desc = [],\n",
    "            value_slot = [], # value -> slots that use it..\n",
    "            tokens=[], # tokenized memory [turn, mem-size, tokens]\n",
    "            tokens_desc = [],\n",
    "            ids=[], # indexed memory [turn mem-size, tokens]\n",
    "            ids_desc = [], # append desc if slots have same desc!\n",
    "            ids_pos=[],\n",
    "            ids_memsize=[], # mem sizes [turn, 1]\n",
    "            mask=[], # mask on memory [turn, mem-size, tokens]\n",
    "            mask_desc = [],\n",
    "        )\n",
    "        \n",
    "        # memory is sequential, initialized by vals from schema, only has values\n",
    "        memory = [\"NONE\", \"dontcare\"] # keep these at index 0, 1\n",
    "        memory_slot = [[\"*\"], [\"*\"]]\n",
    "        memory_desc = [\"NONE\", \"DONTCARE\"]\n",
    "        memory_index = {}\n",
    "        for serv in dial[\"services\"]:\n",
    "            schema = self.schemas.get(serv)\n",
    "            servdesc = schema[\"desc\"]\n",
    "            for slotname, slotdesc, values in zip(schema[\"slot_name\"], schema[\"slot_desc\"], schema[\"slot_vals\"]):\n",
    "                for val in values:\n",
    "                    if val not in memory_index:\n",
    "                        memory.append(val)\n",
    "                        memory_slot.append([slotname])\n",
    "                        memory_desc.append(slotdesc + \"[SEP]\" + servdesc)\n",
    "                        memory_index[val] = len(memory)\n",
    "                    else:\n",
    "                        idx = memory_index[val] - 1\n",
    "                        if slotname not in memory_slot[idx]:\n",
    "                            memory_desc[idx] = memory_desc[idx] + \"[SEP]\" + slotdesc + \"[SEP]\" + servdesc\n",
    "                            memory_slot[idx].append(slotname)\n",
    "        \n",
    "        # at each user turn create a memory snapshot..\n",
    "        for turn in dial[\"turns\"]:\n",
    "            memory = deepcopy(memory)\n",
    "            memory_desc = deepcopy(memory_desc)\n",
    "            memory_slot = deepcopy(memory_slot)\n",
    "            \n",
    "            # pick slot tagger's ground truth ; categorical slot vals are already initialized!\n",
    "            utter = turn[\"utterance\"]\n",
    "            for frame in turn[\"frames\"]:\n",
    "                schema = self.schemas.get(frame[\"service\"])\n",
    "                servdesc = schema[\"desc\"]\n",
    "                for tag in frame[\"slots\"]:\n",
    "                    slotname = tag[\"slot\"]\n",
    "                    slotdesc = schema[\"slot_desc\"][schema[\"slot_name\"].index(slotname)] # shit! O(N*2)\n",
    "                    st, en = tag[\"start\"], tag[\"exclusive_end\"]\n",
    "                    value = utter[st:en]\n",
    "                    if value not in memory_index:\n",
    "                        memory.append(value)\n",
    "                        memory_slot.append([slotname])\n",
    "                        memory_desc.append(slotdesc)\n",
    "                        memory_index[value] = len(memory)\n",
    "                    else:\n",
    "                        idx = memory_index[value] - 1\n",
    "                        if slotname not in memory_slot[idx]:\n",
    "                            memory_slot[idx].append(slotname)\n",
    "                            memory_desc[idx] = memory_desc[idx] + \"[SEP]\" + slotdesc + \"[SEP]\" + servdesc\n",
    "                        \n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                resp[\"value\"].append(memory)\n",
    "                resp[\"value_desc\"].append(memory_desc)\n",
    "                resp[\"value_slot\"].append(memory_slot)\n",
    "                resp[\"ids_memsize\"].append(len(memory))\n",
    "\n",
    "        # tokenize and index the memory values\n",
    "        # value: [turn, values], ids/tokens: [turn, values, tokens]\n",
    "        for mem_desc_snapshot, mem_snapshot in zip(resp[\"value_desc\"], resp[\"value\"]):\n",
    "            mem_tokens = []\n",
    "            mem_tokens_desc = []\n",
    "            mem_ids = []\n",
    "            mem_ids_desc = []\n",
    "            mem_pos = list(range(1, len(mem_snapshot) + 1))\n",
    "            mem_mask = []\n",
    "            mem_mask_desc = []\n",
    "            for desc, val in zip(mem_desc_snapshot, mem_snapshot):\n",
    "                # featurize memory\n",
    "                tokens = self.tokenizer(val)\n",
    "                mem_tokens.append(tokens)\n",
    "                mem_ids.append(self.token_indexer(tokens))\n",
    "                mem_mask.append([1] * len(tokens))\n",
    "                \n",
    "                # featurize memory desc\n",
    "                tokens_desc = self.tokenizer(desc)\n",
    "                mem_tokens_desc.append(tokens_desc)\n",
    "                mem_ids_desc.append(self.token_indexer(tokens_desc))\n",
    "                mem_mask_desc.append([1] * len(tokens_desc))\n",
    "                \n",
    "            resp[\"tokens\"].append(mem_tokens)\n",
    "            resp[\"tokens_desc\"].append(mem_tokens_desc)\n",
    "            resp[\"ids\"].append(mem_ids)\n",
    "            resp[\"ids_desc\"].append(mem_ids_desc)\n",
    "            resp[\"ids_pos\"].append(mem_pos)\n",
    "            resp[\"mask\"].append(mem_mask)\n",
    "            resp[\"mask_desc\"].append(mem_mask_desc)\n",
    "        \n",
    "        return resp\n",
    "    \n",
    "    def fd_slot_memory_loc(self, dial, fields):\n",
    "        resp = dict(\n",
    "            value=[],  # string value\n",
    "            ids=[], # memory loc\n",
    "            ids_onehot=[], # onehot of memory loc\n",
    "            mask=[],\n",
    "            mask_onehot=[],\n",
    "            mask_none=[], # 1 -> non NONE values\n",
    "            mask_none_onehot=[],\n",
    "        )\n",
    "        \n",
    "        # query dialog memory snapshots per turn. NOTE: fd_slot_memory should exec first.\n",
    "        memory = fields[\"slot_memory\"][\"value\"]\n",
    "        \n",
    "        # init snapshot: service, slot -> memory loc, val\n",
    "        memory_loc = []\n",
    "        memory_val = []\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                loc = OrderedDict()\n",
    "                val = OrderedDict()\n",
    "                for serv in dial[\"services\"]:\n",
    "                    loc[serv] = OrderedDict()\n",
    "                    val[serv] = OrderedDict()\n",
    "                    for slot in self.schemas.get(serv)[\"slot_name\"]:\n",
    "                        loc[serv][slot] = None\n",
    "                        val[serv][slot] = None\n",
    "                memory_loc.append(loc)\n",
    "                memory_val.append(val)\n",
    "        \n",
    "        # fill the memory locations \n",
    "        snapshot_id = 0\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                turn_memory = memory[snapshot_id]\n",
    "                turn_memory_loc = memory_loc[snapshot_id]\n",
    "                turn_memory_val = memory_val[snapshot_id]\n",
    "                for frame in turn[\"frames\"]:\n",
    "                    service = frame[\"service\"]\n",
    "                    for slot, values in frame[\"state\"][\"slot_values\"].items():\n",
    "                        val = re.sub(\"\\u2013\", \"-\", values[0]) # dial 59_00125 turn 14\n",
    "                        turn_memory_loc[service][slot] = turn_memory.index(val)\n",
    "                        turn_memory_val[service][slot] = val\n",
    "                    # add locations to UNKNOWN slots\n",
    "                    for slot, val in turn_memory_loc[service].items():\n",
    "                        if val is None:\n",
    "                            turn_memory_loc[service][slot] = turn_memory.index(\"NONE\")\n",
    "                            turn_memory_val[service][slot] = \"NONE\"\n",
    "                snapshot_id += 1\n",
    "        \n",
    "        # featurize\n",
    "        snapshot_id = 0\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                turn_memory = memory[snapshot_id]\n",
    "                turn_memory_loc = memory_loc[snapshot_id]\n",
    "                turn_memory_val = memory_val[snapshot_id]\n",
    "                none_loc = memory[snapshot_id].index(\"NONE\")\n",
    "                turn_fields = dict(\n",
    "                    value=[], ids=[], ids_onehot=[], mask=[], mask_onehot=[],\n",
    "                    mask_none=[], mask_none_onehot=[],\n",
    "                )\n",
    "\n",
    "                for serv in turn_memory_loc:\n",
    "                    mem_size = len(turn_memory)\n",
    "                    vals = list(turn_memory_val[serv].values())\n",
    "                    ids = list(turn_memory_loc[serv].values())\n",
    "                    ids_onehots = label_binarize(ids, list(range(mem_size)))\n",
    "                    mask = [1] * len(ids)\n",
    "                    mask_onehots = [[1] * mem_size for _ in ids]\n",
    "\n",
    "                    mask_none = [int(v!=\"NONE\") for v in vals]\n",
    "                    mask_none_onehot = [[1] * mem_size for _ in ids]\n",
    "                    for v, loc, onehot in zip(vals, ids, mask_none_onehot):\n",
    "                        if v == \"NONE\":\n",
    "                            onehot[loc] = 0\n",
    "                                \n",
    "                    turn_fields[\"value\"].append(vals)\n",
    "                    turn_fields[\"ids\"].append(ids)\n",
    "                    turn_fields[\"ids_onehot\"].append(ids_onehots)\n",
    "                    turn_fields[\"mask\"].append(mask)\n",
    "                    turn_fields[\"mask_onehot\"].append(mask_onehots)\n",
    "                    turn_fields[\"mask_none\"].append(mask_none)\n",
    "                    turn_fields[\"mask_none_onehot\"].append(mask_none_onehot)\n",
    "\n",
    "                # update turn\n",
    "                for k, v in turn_fields.items():\n",
    "                    resp[k].append(v)\n",
    "                \n",
    "                snapshot_id += 1\n",
    "            \n",
    "        return resp\n",
    "    \n",
    "    def fd_num_turns(self, dial, fields):\n",
    "        return {\"ids\": len(dial[\"turns\"])}\n",
    "    \n",
    "    def fd_num_frames(self, dial, fields):\n",
    "        return {\"ids\": [len(t[\"frames\"]) for t in dial[\"turns\"]]}\n",
    "    \n",
    "    def fd_usr_utter(self, dial, fields):\n",
    "        resp = dict(value=[], ids=[], ids_pos=[], mask=[], tokens=[])\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                utter = turn[\"utterance\"]\n",
    "                tokens = self.tokenizer(utter)\n",
    "                ids = self.token_indexer(tokens)\n",
    "                resp[\"value\"].append(utter)\n",
    "                resp[\"ids\"].append(ids)\n",
    "                resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "                resp[\"tokens\"].append(tokens)\n",
    "                resp[\"mask\"].append([1] * len(tokens))\n",
    "        return resp\n",
    "    \n",
    "    def fd_sys_utter(self, dial, fields):\n",
    "        resp = dict(value=[], ids=[], ids_pos=[], mask=[], tokens=[])\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"SYSTEM\":\n",
    "                utter = turn[\"utterance\"]\n",
    "                tokens = self.tokenizer(utter)\n",
    "                ids = self.token_indexer(tokens)\n",
    "                resp[\"value\"].append(utter)\n",
    "                resp[\"ids\"].append(ids)\n",
    "                resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "                resp[\"tokens\"].append(tokens)\n",
    "                resp[\"mask\"].append([1] * len(tokens))\n",
    "        return resp\n",
    "    \n",
    "    def fd_dial_id(self, dial, fields):\n",
    "        return {\"value\": dial[\"dialogue_id\"]}\n",
    "    \n",
    "    def dial_to_fields(self, dial):\n",
    "        fields = {}\n",
    "        ordered_funcs = [\n",
    "            \"fd_dial_id\",\n",
    "            \"fd_num_turns\", \"fd_num_frames\",\n",
    "            \"fd_serv_name\", \"fd_serv_desc\", \n",
    "            \"fd_slot_name\", \"fd_slot_desc\",\n",
    "            \"fd_slot_memory\", \"fd_slot_memory_loc\",\n",
    "            \"fd_usr_utter\", \"fd_sys_utter\"]\n",
    "        for func in ordered_funcs:\n",
    "            name = func.split(\"fd_\", maxsplit=1)[-1]\n",
    "            value = getattr(self, func)(dial, fields)\n",
    "            if value is not None:\n",
    "                fields[name] = value\n",
    "        return fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "bert_ = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = Tokenizer(bert_)\n",
    "token_indexer = TokenIndexer(bert_)\n",
    "\n",
    "train_schemas = Schemas(\"../data/train/schema.json\")\n",
    "test_schemas = Schemas(\"../data/dev/schema.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DialogueDataset(\"../data/train/dialogues_001.json\", train_schemas, tokenizer, token_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e45eaab6a942abb28234392ddd1ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=127), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "train_dial_sets = []\n",
    "train_dial_files = sorted(glob.glob(\"../data/train/dialogues*.json\"))\n",
    "num_workers = min(20, len(train_dial_files))\n",
    "\n",
    "def worker(filename):\n",
    "    return DialogueDataset(filename, train_schemas, tokenizer, token_indexer)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    for ds in tqdm(executor.map(worker, train_dial_files), total=len(train_dial_files)):\n",
    "        train_dial_sets.append(ds)\n",
    "\n",
    "train_ds = D.ConcatDataset(train_dial_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405c6ed13f544def86c8a5ac894bfbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "test_dial_sets = []\n",
    "test_dial_files = sorted(glob.glob(\"../data/dev/dialogues*.json\"))\n",
    "num_workers = min(20, len(train_dial_files))\n",
    "\n",
    "def worker(filename):\n",
    "    return DialogueDataset(filename, test_schemas, tokenizer, token_indexer)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    for ds in tqdm(executor.map(worker, test_dial_files), total=len(test_dial_files)):\n",
    "        test_dial_sets.append(ds)\n",
    "\n",
    "test_ds = D.ConcatDataset(test_dial_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def move_to_device(obj, device):\n",
    "    if type(obj) is list:\n",
    "        return [move_to_device(o, device) for o in obj]\n",
    "    elif type(obj) is dict:\n",
    "        return {k: move_to_device(v, device) for k, v in obj.items()}\n",
    "    elif type(obj) is torch.Tensor or isinstance(obj, nn.Module):\n",
    "        return obj.to(device)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dialogue_mini_batcher(dialogues):\n",
    "    default_padding = 0\n",
    "    batch = {}\n",
    "    for dial in dialogues:\n",
    "        # populate the batch\n",
    "        for field, data in dial.items():\n",
    "            if field not in batch:\n",
    "                batch[field] = {}\n",
    "            for attr, val in data.items():\n",
    "                if attr == \"padding\":\n",
    "                    batch[field][attr] = val\n",
    "                else:\n",
    "                    batch[field][attr] = batch[field].get(attr, [])\n",
    "                    batch[field][attr].append(val)\n",
    "\n",
    "    # padding on field attributes\n",
    "    for field_name, data in batch.items():\n",
    "        for attr in data:\n",
    "            if attr.startswith((\"ids\", \"mask\")):\n",
    "                data[attr] = padded_array(data[attr], default_padding)\n",
    "                data[attr] = torch.tensor(data[attr], device=\"cpu\") # whatif its in device0 in epoch0, then at epoch1, sent to device1\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "class DialogIterator(object):\n",
    "    \"\"\"A simple wrapper on DataLoader\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, *args, **kw):\n",
    "        self.length = None\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.iterator = D.DataLoader(dataset, batch_size, *args, **kw)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.length is None:\n",
    "            self.length = 0\n",
    "            for dial in self.dataset:\n",
    "                self.length += (dial[\"num_turns\"][\"ids\"] * len(dial[\"serv_name\"][\"value\"]))\n",
    "            self.length = int(self.length / self.batch_size)\n",
    "        return self.length\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.iterator:\n",
    "            num_turns = batch[\"usr_utter\"][\"ids\"].shape[1]\n",
    "            num_services = batch[\"serv_desc\"][\"ids\"].shape[1]\n",
    "            for turnid in range(num_turns):\n",
    "                for sid in range(num_services):\n",
    "                    inputs = dict(turnid=turnid, serviceid=sid)\n",
    "                    inputs.update(batch)\n",
    "                    yield inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_turns ids --> torch.Size([1])\n",
      "num_frames ids --> torch.Size([1, 24])\n",
      "serv_desc ids --> torch.Size([1, 1, 10])\n",
      "serv_desc ids_pos --> torch.Size([1, 1, 10])\n",
      "serv_desc mask --> torch.Size([1, 1, 10])\n",
      "slot_desc ids --> torch.Size([1, 1, 11, 12])\n",
      "slot_desc ids_pos --> torch.Size([1, 1, 11, 12])\n",
      "slot_desc mask --> torch.Size([1, 1, 11, 12])\n",
      "slot_memory ids --> torch.Size([1, 12, 29, 10])\n",
      "slot_memory ids_desc --> torch.Size([1, 12, 29, 40])\n",
      "slot_memory ids_pos --> torch.Size([1, 12, 29])\n",
      "slot_memory ids_memsize --> torch.Size([1, 12])\n",
      "slot_memory mask --> torch.Size([1, 12, 29, 10])\n",
      "slot_memory mask_desc --> torch.Size([1, 12, 29, 40])\n",
      "slot_memory_loc ids --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc ids_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "slot_memory_loc mask --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc mask_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "slot_memory_loc mask_none --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc mask_none_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "usr_utter ids --> torch.Size([1, 12, 25])\n",
      "usr_utter ids_pos --> torch.Size([1, 12, 25])\n",
      "usr_utter mask --> torch.Size([1, 12, 25])\n",
      "sys_utter ids --> torch.Size([1, 12, 31])\n",
      "sys_utter ids_pos --> torch.Size([1, 12, 31])\n",
      "sys_utter mask --> torch.Size([1, 12, 31])\n"
     ]
    }
   ],
   "source": [
    "def get_sample(ds, size=1):\n",
    "    return next(iter(DialogIterator(ds, size, collate_fn=dialogue_mini_batcher)))\n",
    "\n",
    "def print_shapes(ds):\n",
    "    it = get_sample(ds, size=1)\n",
    "    for field, val in it.items():\n",
    "        if type(val) is dict:\n",
    "            for attr in val:\n",
    "                if attr.startswith(\"ids\") or attr.startswith(\"mask\"):\n",
    "                    print(field, attr, \"-->\", val[attr].shape)\n",
    "                    \n",
    "\n",
    "# TODO: why mem ids, and mem loc size is diff by 1?\n",
    "print_shapes(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertModel, BertConfig\n",
    "from allennlp.training.metrics import BooleanAccuracy, CategoricalAccuracy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDownstream(nn.Module):\n",
    "    # https://huggingface.co/pytorch-transformers/model_doc/bert.html\n",
    "    # https://github.com/hanxiao/bert-as-service/blob/master/docs/section/faq.rst#id6\n",
    "    \n",
    "    def __init__(self, btype, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.emb = BertModel.from_pretrained(btype, output_hidden_states=True)\n",
    "        for name, param in self.emb.named_parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return 768\n",
    "    \n",
    "    def forward(self, input_ids, position_ids=None, attention_mask=None, flat=None):\n",
    "        sh = list(input_ids.shape)\n",
    "        \n",
    "        if flat:\n",
    "            st, en = flat\n",
    "        elif len(sh) == 3:\n",
    "            st, en = 0, 1\n",
    "        elif len(sh) in (0,1,2):\n",
    "            st, en = 0, 0\n",
    "        else:\n",
    "            st, en = 1, -2\n",
    "        \n",
    "        input_ids = torch.flatten(input_ids, st, en).long()\n",
    "        if position_ids is not None:\n",
    "            position_ids = torch.flatten(position_ids, st, en).long()\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = torch.flatten(attention_mask, st, en).long()\n",
    "        \n",
    "        outputs = self.emb(input_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs[2][4]\n",
    "        pooled = pooled.view(sh + [-1])\n",
    "        \n",
    "        return pooled #*->*e\n",
    "\n",
    "\n",
    "class CandidateSelector(nn.Module):\n",
    "    \"\"\"\n",
    "    memory -- represents temporal hash table of text values, that monotonically grows\n",
    "    memory_desc -- represents sequential description to every value in hash table\n",
    "    slot, utter -- represent query/key descriptions\n",
    "    \n",
    "    The idea is that we model a hash function \n",
    "        F: slot, utter, time -> memory_location\n",
    "    \n",
    "    This is a mix of ideas from\n",
    "        - Memory Networks by Jason Weston, FAIR\n",
    "        - E2E Memory Networks by Sukhbaatar, NYU/FAIR\n",
    "        - Pointer Networks by Oriol Vinayls, Google Brain\n",
    "        - Alignment and Translation by Bahdanau, MILA\n",
    "    \n",
    "        - Weston and Sukhbaatar demonstrate memory models on Facebook bAbI tasks. that capture some temporal challenges.\n",
    "            while Vinayls tweaks the idea of Bahdanau's attention, to classification/regress targets represented in latent space.\n",
    "            (NOTE: their motivation is subtly different, but this explanation still stands valid)\n",
    "    \n",
    "    Unique contribution:\n",
    "        - Explore the problem where memory grows and has temporal information.\n",
    "        - Model a hash function that understands temporal (just like Vinayls) but but \n",
    "            new challenges are:\n",
    "            - applied to dialog state (no one else did before), where the hash function has additional challenges of dealing with \n",
    "                guessing user behavior dist. and language subtlities (eg: coreference and ellipsis resolutions.)\n",
    "            - the hash function is learning from real world data, unlike previous works where toy data are used. \n",
    "                the hash key is can change just because user explicitly/implicitly says something..\n",
    "            - the model is setup in a way it supports growth, and scale across domains. Sukhbaatar's approach is fixed (verify again!)\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = BertDownstream(\"bert-base-uncased\")\n",
    "        emb_dim = self.emb.output_dim\n",
    "        \n",
    "        self.l0 = nn.GRU(emb_dim, emb_dim, batch_first=True, num_layers=1) # encode utter\n",
    "        self.l1 = nn.GRU(emb_dim, emb_dim, batch_first=True, num_layers=1) # encode memory\n",
    "        self.l2 = nn.GRU(emb_dim, emb_dim, batch_first=True, num_layers=1) # encode query slot\n",
    "       \n",
    "        # attentions\n",
    "        self.l3 = nn.Linear(2*emb_dim, emb_dim)\n",
    "        self.l4 = nn.Bilinear(emb_dim, emb_dim, 1)\n",
    "         \n",
    "        # metrics\n",
    "        self.acc = CategoricalAccuracy()\n",
    "        self.goal_acc = CategoricalAccuracy()\n",
    "        \n",
    "        self.register_buffer(\"utter_state\", None)\n",
    "\n",
    "        # init weights: classifier's performance changes heavily on these\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.startswith((\"l0.\", \"11.\", \"l2.\")):\n",
    "                print(\"Initializing bias/weights of \", name)\n",
    "                if \"weight\" in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    param.data.fill_(0.)\n",
    "\n",
    "    def get_metrics(self, reset=False, goal_reset=False):\n",
    "        return dict(\n",
    "            acc=self.acc.get_metric(reset), # avg per service\n",
    "            goal_acc=self.goal_acc.get_metric(goal_reset), # avg per turn\n",
    "        )\n",
    "    \n",
    "    def encode_utter(self, batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        usr_utter, usr_mask, usr_pos = batch[\"usr_utter\"][\"ids\"][:,turnid,:], batch[\"usr_utter\"][\"mask\"][:,turnid,:], batch[\"usr_utter\"][\"ids_pos\"][:,turnid,:]\n",
    "        sys_utter, sys_mask, sys_pos = batch[\"sys_utter\"][\"ids\"][:,turnid,:], batch[\"sys_utter\"][\"mask\"][:,turnid,:], batch[\"sys_utter\"][\"ids_pos\"][:,turnid,:]\n",
    "        \n",
    "        usr_utter = self.emb(usr_utter, position_ids=usr_pos, attention_mask=usr_mask)\n",
    "        sys_utter = self.emb(sys_utter, position_ids=sys_pos, attention_mask=sys_mask)\n",
    "        \n",
    "        utter = torch.cat([sys_utter, usr_utter], dim=1) # b2se\n",
    "\n",
    "        utter_h = self.utter_state.detach() if turnid != 0 else None\n",
    "        utter, utter_h = self.l0(utter, utter_h)\n",
    "        self.utter_state = utter_h\n",
    "        \n",
    "        return utter_h[-1] # be\n",
    "\n",
    "    def encode_memory(self, batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        # Encode memory\n",
    "        memory = batch[\"slot_memory\"][\"ids\"][:,turnid,:]\n",
    "        memory_mask = batch[\"slot_memory\"][\"mask\"][:,turnid,:]\n",
    "        memory_pos = batch[\"slot_memory\"][\"ids_pos\"][:,turnid,:]\n",
    "        sh = memory.shape\n",
    "        \n",
    "        memory_pos = memory_pos[:,:,None].repeat(1,1,sh[-1])# bm->bms\n",
    "        memory = self.emb(memory, position_ids=memory_pos, attention_mask=memory_mask) # bmse\n",
    "        \n",
    "        # Encode memory desc\n",
    "        memory_desc = batch[\"slot_memory\"][\"ids_desc\"][:,turnid,:]\n",
    "        memory_desc_mask = batch[\"slot_memory\"][\"mask_desc\"][:,turnid,:]\n",
    "        sh2 = memory_desc.shape\n",
    "        \n",
    "        memory_pos = batch[\"slot_memory\"][\"ids_pos\"][:,turnid,:]\n",
    "        memory_desc_pos = memory_pos[:,:,None].repeat(1,1,sh2[-1]) # bm->bms\n",
    "        memory_desc = self.emb(memory_desc, position_ids=memory_desc_pos, attention_mask=memory_desc_mask) # bmse\n",
    "        \n",
    "        # across text\n",
    "        memory = torch.cat([memory, memory_desc], dim=2) # bm2se\n",
    "        memory = torch.flatten(memory, 0, 1) # bm,2s,e\n",
    "        memory, memory_h = self.l1(memory)\n",
    "        \n",
    "        memory_h = memory_h[-1].view(sh[0], sh[1], -1) # pool two layers in bidirectional.\n",
    "        return memory_h # bme\n",
    "    \n",
    "    def encode_slot_desc(self, batch):\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        desc = batch[\"slot_desc\"][\"ids\"][:,serviceid,:] # [batch, slots, tokens]\n",
    "        desc_pos = batch[\"slot_desc\"][\"ids_pos\"][:,serviceid,:]\n",
    "        desc_mask = batch[\"slot_desc\"][\"mask\"][:,serviceid,:]\n",
    "        sh = desc.shape\n",
    "        \n",
    "        desc = self.emb(desc, position_ids=desc_pos, attention_mask=desc_mask) # bste\n",
    "        desc = torch.flatten(desc, 0, 1) # bs,t,e\n",
    "        desc, desc_h = self.l2(desc)\n",
    "    \n",
    "        desc_h = desc_h[-1].view(sh[0], sh[1], -1)\n",
    "    \n",
    "        return desc_h # bse\n",
    "        \n",
    "    def compute_score1(self, memory, slot, utter):\n",
    "        # memory: bme\n",
    "        # slot: bse\n",
    "        # utter: be\n",
    "        s = slot.shape[1]\n",
    "        m = memory.shape[1]\n",
    "        \n",
    "        utter = utter[:,None,:].repeat(1,s,1) #be->bse\n",
    "\n",
    "        key = self.l3(torch.cat([utter, slot], dim=-1)) # bs2e->bse\n",
    "        key = torch.tanh(key)\n",
    "        key = key[:,:,None,:].repeat(1,1,m,1) # bsme\n",
    "        \n",
    "        memory = memory[:,None,:,:].repeat(1,s,1,1) # bsme\n",
    "        \n",
    "        energy = self.l4(key, memory) #bsme->bsm1\n",
    "        energy = F.softmax(energy.squeeze(-1), dim=-1)\n",
    "        return energy\n",
    "        \n",
    "    def forward(self, **batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        # doc: GRU outputs [batch, seq, emb * dir] [layers * dir, batch, emb]\n",
    "\n",
    "        # get fixed size encodings\n",
    "        utter = self.encode_utter(batch) # be\n",
    "        memory = self.encode_memory(batch) # bme\n",
    "        slot_desc = self.encode_slot_desc(batch) # bse\n",
    "        \n",
    "        # map: slot desc -> memory\n",
    "        score = self.compute_score1(memory, slot_desc, utter) # bsm\n",
    "        output = {\"score\": score}\n",
    "\n",
    "        if \"slot_memory_loc\" in batch:\n",
    "            target = batch[\"slot_memory_loc\"]\n",
    "            memsize = target[\"ids_onehot\"].shape[-1]\n",
    "            pred_score = score.view(-1, memsize) # bsm->bs,m \n",
    "            \n",
    "            # onehot targets\n",
    "            target_score_oh = target[\"ids_onehot\"][:,turnid,serviceid,:].contiguous().view(-1, memsize).float() # bsm->bs,m\n",
    "            target_mask_oh = (target[\"mask_onehot\"][:,turnid,serviceid,:] * target[\"mask_none_onehot\"][:,turnid,serviceid,:]).contiguous().view(-1, memsize).float()\n",
    "            \n",
    "            # target\n",
    "            target_score = target[\"ids\"][:,turnid,serviceid,:].float() # [batch, slots]\n",
    "            target_mask = (target[\"mask\"][:,turnid,serviceid,:] * target[\"mask_none\"][:,turnid,serviceid,:]).float()\n",
    "            \n",
    "            # loss\n",
    "            output[\"loss\"] = F.binary_cross_entropy(pred_score, target_score_oh, target_mask_oh).unsqueeze(0) # don't return scalar\n",
    "            \n",
    "            # log metrics\n",
    "            self.acc(score, target_score, target_mask)\n",
    "            self.goal_acc(score, target_score, target_mask)\n",
    "            \n",
    "            output[\"target_ids\"] = target_score\n",
    "            output[\"pred_ids\"] = torch.argmax(score, dim=-1)\n",
    "            output[\"mask\"] = target[\"mask\"][:,turnid,serviceid,:].float()\n",
    "            output[\"mask_none\"] = target[\"mask_none\"][:,turnid,serviceid,:].float()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.tensorboard_writer import TensorboardWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module(m):\n",
    "    if type(m) is nn.DataParallel:\n",
    "        return m.module\n",
    "    return m\n",
    "\n",
    "def train(model, optimizer, batch_size, num_epochs, train_ds, test_ds, device):\n",
    "    model = model.train()\n",
    "    current_batch = 1 # tensorboard doesn't like 0\n",
    "    tensorboard = TensorboardWriter(\n",
    "        get_batch_num_total=lambda: current_batch,\n",
    "        summary_interval=10,\n",
    "        serialization_dir=\"../data/tensorboard/\"\n",
    "    )\n",
    "    \n",
    "    histogram_weights = [name for name, p in model.named_parameters() if not \".emb.\" in name]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_iter = DialogIterator(train_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "        num_batches = len(train_iter) \n",
    "        if test_ds:\n",
    "            test_iter = DialogIterator(test_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "            num_batches += len(test_iter)\n",
    "        \n",
    "        with tqdm(total=num_batches) as pbar:\n",
    "            # train\n",
    "            pbar.set_description(\"Train {}\".format(epoch))\n",
    "            model = model.train()\n",
    "            train_iter = DialogIterator(train_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "            metrics = OrderedDict()\n",
    "            \n",
    "            # to know when the dialog and service changes\n",
    "            turnid = -1\n",
    "            \n",
    "            for i, batch in enumerate(train_iter):\n",
    "                current_batch += 1\n",
    "                batch = move_to_device(batch, device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(**batch)\n",
    "                output[\"loss\"] = output[\"loss\"].mean()\n",
    "                output[\"loss\"].backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # at each new turn\n",
    "                if turnid != batch[\"turnid\"]:\n",
    "                    metrics.update(module(model).get_metrics(reset=True, goal_reset=True))\n",
    "                else:\n",
    "                    curr_met = module(model).get_metrics(reset=True)\n",
    "                    metrics.update(acc=curr_met[\"acc\"])\n",
    "                    \n",
    "                metrics[\"loss\"] = output[\"loss\"].item()\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(metrics)\n",
    "                \n",
    "                metrics[\"turnid\"] = batch[\"turnid\"]\n",
    "                metrics[\"servid\"] = batch[\"serviceid\"]\n",
    "\n",
    "                # update tensorboard logs\n",
    "                tensorboard.add_train_scalar(\"loss\", metrics[\"loss\"], timestep=current_batch)\n",
    "                tensorboard.log_metrics(train_metrics=metrics, epoch=current_batch)\n",
    "                tensorboard.log_parameter_and_gradient_statistics(model, None)\n",
    "                \n",
    "                # histograms, I guess take longer..\n",
    "                if turnid == 0:\n",
    "                    st_time = time.time()\n",
    "                    tensorboard.log_histograms(model, histogram_weights)\n",
    "                    tensorboard.add_train_histogram(\"target_ids\", output[\"target_ids\"])\n",
    "                    tensorboard.add_train_histogram(\"pred_ids\", output[\"pred_ids\"])\n",
    "                    metrics[\"time\"] = time.time() - st_time\n",
    "                \n",
    "                # at the end of the loop, update prev turnid\n",
    "                turnid = batch[\"turnid\"]\n",
    "\n",
    "            # test\n",
    "            if test_ds:\n",
    "                pbar.set_description(\"Test {}\".format(epoch))\n",
    "                metrics = OrderedDict(epoch=epoch)\n",
    "                turnid = -1\n",
    "                with torch.no_grad():\n",
    "                    model = model.eval()\n",
    "                    for i, batch in enumerate(test_iter):\n",
    "                        current_batch += 1\n",
    "                        batch = move_to_device(batch, device)\n",
    "                        output = model(**batch)\n",
    "                        output[\"loss\"] = output[\"loss\"].mean()\n",
    "\n",
    "                        # at each new turn\n",
    "                        if turnid != batch[\"turnid\"]:\n",
    "                            metrics.update(module(model).get_metrics(reset=True, goal_reset=True))\n",
    "                        else:\n",
    "                            curr_met = module(model).get_metrics(reset=True)\n",
    "                            metrics.update(acc=curr_met[\"acc\"])\n",
    "\n",
    "                        metrics[\"loss\"] = output[\"loss\"].item()\n",
    "                        pbar.update(1)\n",
    "                        pbar.set_postfix(metrics)\n",
    "                        turnid = batch[\"turnid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"../data/model0.pkl\")\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove tensorboard logs\n",
      "set number of devices\n",
      "loading model\n",
      "Initializing bias/weights of  l0.weight_ih_l0\n",
      "Initializing bias/weights of  l0.weight_hh_l0\n",
      "Initializing bias/weights of  l0.bias_ih_l0\n",
      "Initializing bias/weights of  l0.bias_hh_l0\n",
      "Initializing bias/weights of  l2.weight_ih_l0\n",
      "Initializing bias/weights of  l2.weight_hh_l0\n",
      "Initializing bias/weights of  l2.bias_ih_l0\n",
      "Initializing bias/weights of  l2.bias_hh_l0\n",
      "started training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddc5699725d4567a36b76393a0c41e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Remove tensorboard logs\")\n",
    "!rm -rf ../data/tensorboard/*\n",
    "\n",
    "print(\"set number of devices\") # not sure we can in jupyter once program already kicked in the first time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = \"cuda\"\n",
    "\n",
    "print(\"loading model\")\n",
    "model = CandidateSelector()\n",
    "#model = nn.DataParallel(model)\n",
    "model = move_to_device(model, device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "train_samples = [train_ds[i] for i in range(1000)]\n",
    "test_samples = [test_ds[i] for i in range(10)]\n",
    "\n",
    "print(\"started training\")\n",
    "train(\n",
    "    model=model,\n",
    "    optimizer=optim,\n",
    "    train_ds=train_samples,\n",
    "    test_ds=test_samples,\n",
    "    device=device,\n",
    "    num_epochs=20,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Goal Acc:  0.12333333333333334\n",
      "Avg Joint Goal Acc:  0.0\n",
      "\n",
      "╒══════════╤═════════════╤══════════╤══════════╤═══════════════╤═══════════╤════════════════════════╤═════════════════════════════╤═══════════╤═══════════╤═══════════╤═══════════╤════════╕\n",
      "│   dialid │   num_turns │   turnid │   servid │ servname      │   memsize │ slotname               │ tgt_val                     │   tgt_loc │ prd_val   │   prd_loc │   correct │   mask │\n",
      "╞══════════╪═════════════╪══════════╪══════════╪═══════════════╪═══════════╪════════════════════════╪═════════════════════════════╪═══════════╪═══════════╪═══════════╪═══════════╪════════╡\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ restaurant_name        │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ date                   │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ time                   │ half past 11 in the morning │        14 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ has_seating_outdoors   │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ has_vegetarian_options │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ phone_number           │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ rating                 │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ address                │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ number_of_seats        │ 2                           │         5 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ price_range            │ NONE                        │         0 │ moderate  │        11 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ location               │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        0 │        0 │ Restaurants_2 │        15 │ category               │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ restaurant_name        │ Sino                        │        16 │ Sino      │        16 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ date                   │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ time                   │ half past 11 in the morning │        14 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ has_seating_outdoors   │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ has_vegetarian_options │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ phone_number           │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ rating                 │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ address                │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ number_of_seats        │ 2                           │         5 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ price_range            │ NONE                        │         0 │ moderate  │        11 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ location               │ San Jose                    │        15 │ San Jose  │        15 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        1 │        0 │ Restaurants_2 │        17 │ category               │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ restaurant_name        │ Sino                        │        16 │ Sino      │        16 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ date                   │ today                       │        18 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ time                   │ 11:30 am                    │        17 │ 2         │         5 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ has_seating_outdoors   │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ has_vegetarian_options │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ phone_number           │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ rating                 │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ address                │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ number_of_seats        │ 2                           │         5 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ price_range            │ NONE                        │         0 │ moderate  │        11 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ location               │ San Jose                    │        15 │ San Jose  │        15 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        2 │        0 │ Restaurants_2 │        19 │ category               │ NONE                        │         0 │ 11:30 am  │        17 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ restaurant_name        │ Sino                        │        16 │ Sino      │        16 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ date                   │ today                       │        18 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ time                   │ 11:30 am                    │        17 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ has_seating_outdoors   │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ has_vegetarian_options │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ phone_number           │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ rating                 │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ address                │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ number_of_seats        │ 2                           │         5 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ price_range            │ NONE                        │         0 │ moderate  │        11 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ location               │ San Jose                    │        15 │ San Jose  │        15 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        3 │        0 │ Restaurants_2 │        20 │ category               │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ restaurant_name        │ Sino                        │        16 │ Sino      │        16 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ date                   │ today                       │        18 │ Sino      │        16 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ time                   │ 11:30 am                    │        17 │ 11:30 am  │        17 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ has_seating_outdoors   │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ has_vegetarian_options │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ phone_number           │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ rating                 │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ address                │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ number_of_seats        │ 2                           │         5 │ NONE      │         0 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ price_range            │ NONE                        │         0 │ moderate  │        11 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ location               │ San Jose                    │        15 │ San Jose  │        15 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        4 │        0 │ Restaurants_2 │        21 │ category               │ NONE                        │         0 │ 11:30 am  │        17 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ restaurant_name        │ Sino                        │        16 │ Sino      │        16 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ date                   │ today                       │        18 │ Sino      │        16 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ time                   │ 11:30 am                    │        17 │ 2         │         5 │         0 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ has_seating_outdoors   │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ has_vegetarian_options │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ phone_number           │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ rating                 │ NONE                        │         0 │ 2         │         5 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ address                │ NONE                        │         0 │ NONE      │         0 │       100 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ number_of_seats        │ 2                           │         5 │ 2         │         5 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ price_range            │ NONE                        │         0 │ moderate  │        11 │         0 │      0 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ location               │ San Jose                    │        15 │ San Jose  │        15 │       100 │      1 │\n",
      "├──────────┼─────────────┼──────────┼──────────┼───────────────┼───────────┼────────────────────────┼─────────────────────────────┼───────────┼───────────┼───────────┼───────────┼────────┤\n",
      "│  1_00000 │           6 │        5 │        0 │ Restaurants_2 │        21 │ category               │ NONE                        │         0 │ 11:30 am  │        17 │         0 │      0 │\n",
      "╘══════════╧═════════════╧══════════╧══════════╧═══════════════╧═══════════╧════════════════════════╧═════════════════════════════╧═══════════╧═══════════╧═══════════╧═══════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "def infer_batch(model, test_ds, batch_size, device):\n",
    "    result_table = []\n",
    "\n",
    "    goal_acc = []\n",
    "    joint_acc = []\n",
    "\n",
    "    total_turn_acc = None\n",
    "    total_joint_acc = None\n",
    "    num_turns = 0\n",
    "    num_slots = 0\n",
    "\n",
    "    model = model.eval()\n",
    "    \n",
    "    for batch in DialogIterator(test_ds, batch_size, collate_fn=dialogue_mini_batcher):\n",
    "        batch = move_to_device(batch, device)\n",
    "        with torch.no_grad():\n",
    "            result = model(**batch)\n",
    "        \n",
    "        turnid = batch[\"turnid\"]\n",
    "        servid = batch[\"serviceid\"]\n",
    "        num_batches = batch[\"usr_utter\"][\"ids\"].shape[0]\n",
    "        \n",
    "        if turnid == 0:\n",
    "            # update previous turn's.\n",
    "            if total_turn_acc is not None:\n",
    "                goal_acc.append(total_turn_acc / num_turns)\n",
    "                joint_acc.append(total_joint_acc / num_turns)\n",
    "            \n",
    "            # reset counter\n",
    "            total_turn_acc = 0\n",
    "            total_joint_acc = 1 # its binary 1 or 0\n",
    "            num_turns += 1\n",
    "\n",
    "        batch_fields = dict(\n",
    "            prd_mem_loc = result[\"pred_ids\"], # B,slot\n",
    "            tgt_mem_loc = result[\"target_ids\"],\n",
    "            mask = result[\"mask\"],\n",
    "            mask_none = result[\"mask_none\"], # 1 -> target is not None\n",
    "            dial_id = batch[\"dial_id\"][\"value\"],\n",
    "            serv_name = batch[\"serv_name\"][\"value\"],\n",
    "            slot_name = batch[\"slot_name\"][\"value\"],\n",
    "            num_turns = batch[\"num_turns\"][\"ids\"],\n",
    "            memory = batch[\"slot_memory\"][\"value\"], # B,turn,memory\n",
    "        )\n",
    "\n",
    "        for b in range(num_batches):\n",
    "            num_slots = 0\n",
    "\n",
    "            fields = {k: v[b] for k, v in batch_fields.items()}\n",
    "            memory = fields[\"memory\"][turnid]\n",
    "            \n",
    "            for slotid, (prd_loc, tgt_loc) in enumerate(zip(fields[\"prd_mem_loc\"], fields[\"tgt_mem_loc\"])):\n",
    "                # clip the locations.. they somehow predict in padding regions!! Make it NONE\n",
    "                prd_loc = int(prd_loc.item()) if prd_loc < len(memory) else 0\n",
    "                tgt_loc = int(tgt_loc.item()) if tgt_loc < len(memory) else 0\n",
    "                \n",
    "                prd_val = memory[prd_loc]\n",
    "                tgt_val = memory[tgt_loc]\n",
    "                mask = fields[\"mask\"][slotid].item()\n",
    "                mask_none = fields[\"mask_none\"][slotid].item()\n",
    "                dialid = fields[\"dial_id\"]\n",
    "                servname = fields[\"serv_name\"][servid]\n",
    "                slotname = fields[\"slot_name\"][servid][slotid]\n",
    "                num_turns = fields[\"num_turns\"].item() / 2 # usr-sys turn pairs\n",
    "                \n",
    "                # update acc counter\n",
    "                if mask * mask_none == 1:\n",
    "                    total_turn_acc += int(prd_loc == tgt_loc)\n",
    "                    total_joint_acc *= int(prd_loc == tgt_loc)\n",
    "                    num_slots += 1\n",
    "\n",
    "                item = OrderedDict(\n",
    "                    dialid = fields[\"dial_id\"],\n",
    "                    num_turns = num_turns,\n",
    "                    turnid = turnid,\n",
    "                    servid = servid,\n",
    "                    servname = fields[\"serv_name\"][servid],\n",
    "                    memsize = len(memory),\n",
    "                    slotname = slotname,\n",
    "                    tgt_val = tgt_val,\n",
    "                    tgt_loc = tgt_loc,\n",
    "                    prd_val = prd_val,\n",
    "                    prd_loc = prd_loc,\n",
    "                    correct = 100*int(tgt_loc == prd_loc),\n",
    "                    mask = (mask * mask_none),\n",
    "                )\n",
    "\n",
    "                result_table.append(item)\n",
    "            \n",
    "            # avg acc across slots per turn\n",
    "            total_turn_acc /= num_slots\n",
    "    \n",
    "    # the last batch\n",
    "    goal_acc.append(total_turn_acc / num_turns)\n",
    "    joint_acc.append(total_joint_acc / num_turns)\n",
    "        \n",
    "    print(\"Avg Goal Acc: \", sum(goal_acc) / len(goal_acc))\n",
    "    print(\"Avg Joint Goal Acc: \", sum(joint_acc) / len(joint_acc))\n",
    "    print()\n",
    "    \n",
    "    print(tabulate(\n",
    "        [list(item.values()) for item in result_table],\n",
    "        list(result_table[0].keys()),\n",
    "        \"fancy_grid\",\n",
    "    ))\n",
    "    \n",
    "    \n",
    "        \n",
    "infer_batch(model, [test_ds[0]], batch_size=2, device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "226px",
    "width": "226px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1510px",
    "right": "97px",
    "top": "135px",
    "width": "403px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

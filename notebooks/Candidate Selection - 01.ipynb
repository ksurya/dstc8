{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as D\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import lru_cache\n",
    "from collections import OrderedDict\n",
    "from types import SimpleNamespace\n",
    "from collections.abc import Iterable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from ipdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        self.bert = bert\n",
    "    \n",
    "    def __call__(self, text, include_sep=True):\n",
    "        tokens = self.bert.tokenize(text)\n",
    "        if include_sep:\n",
    "            tokens.insert(0, \"[CLS]\")\n",
    "            tokens.append(\"[SEP]\")\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "class TokenIndexer:\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        self.bert = bert\n",
    "        \n",
    "    def inv(self, *args, **kw):\n",
    "        # tokens MUST be list, tensor doesn't work.\n",
    "        return self.bert.convert_ids_to_tokens(*args, **kw)\n",
    "        \n",
    "    def __call__(self, *args, **kw):\n",
    "        return self.bert.convert_tokens_to_ids(*args, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def label_binarize(labels, classes):\n",
    "    # labels: np.array or tensor [batch, 1]\n",
    "    # classes: [..] list of classes\n",
    "    # weirdly,`sklearn.preprocessing.label_binarize` returns [1] or [0]\n",
    "    # instead of onehot ONLY when executing in this script!\n",
    "    vectors = [np.zeros(len(classes)) for _ in labels]\n",
    "    for i, label in enumerate(labels):\n",
    "        for j, c in enumerate(classes):\n",
    "            if c == label:\n",
    "                vectors[i][j] = 1\n",
    "    return np.array(vectors)\n",
    "    \n",
    "\n",
    "def label_inv_binarize(vectors, classes):\n",
    "    # labels: np.array or tensor [batch, classes]\n",
    "    # classes: [..] list of classes\n",
    "    # follows sklearn LabelBinarizer.inverse_transform()\n",
    "    # given all zeros, predicts label at index 0, instead of returning none!\n",
    "    # sklearn doesn't have functional API of inverse transform\n",
    "    labels = []\n",
    "    for each in vectors:\n",
    "        index = np.argmax(each)\n",
    "        labels.append(classes[index])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def padded_array(array, value=0):\n",
    "    # TODO: this does not do type checking; and wow it can be slow on strings.\n",
    "    # expects array to have fixed _number_ of dimensions\n",
    "    \n",
    "    # resolve the shape of padded array\n",
    "    shape_index = {}\n",
    "    queue = [(array, 0)]\n",
    "    while queue:\n",
    "        subarr, dim = queue.pop(0)\n",
    "        shape_index[dim] = max(shape_index.get(dim, -1), len(subarr))\n",
    "        for x in subarr:\n",
    "            if isinstance(x, Iterable) and not isinstance(x, str):\n",
    "                queue.append((x, dim+1))\n",
    "    shape = [shape_index[k] for k in range(max(shape_index) + 1)]\n",
    "    \n",
    "    # fill the values \n",
    "    padded = np.ones(shape) * value\n",
    "    queue = [(array, [])]\n",
    "    while queue:\n",
    "        subarr, index = queue.pop(0)\n",
    "        for j, x in enumerate(subarr):\n",
    "            if isinstance(x, Iterable):\n",
    "                queue.append((x, index + [j]))\n",
    "            else:\n",
    "                padded[tuple(index + [j])] = x\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "class Schemas(object):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        with open(filepath) as f:\n",
    "            self.index = {}\n",
    "            for schema in json.load(f):\n",
    "                service_name = schema[\"service_name\"]\n",
    "                self.index[service_name] = schema\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get(self, service):\n",
    "        result = dict(\n",
    "            # service\n",
    "            name=service,\n",
    "            desc=self.index[service][\"description\"],\n",
    "            \n",
    "            # slots\n",
    "            slot_name=[],\n",
    "            slot_desc=[],\n",
    "            slot_iscat=[], \n",
    "            slot_vals=[], # collected only for cat slots.. not sure if that makes sense\n",
    "\n",
    "            # intents\n",
    "            intent_name=[],\n",
    "            intent_desc=[],\n",
    "            intent_istrans=[],\n",
    "            intent_reqslots=[],\n",
    "            intent_optslots=[],\n",
    "            intent_optvals=[],\n",
    "        )\n",
    "\n",
    "        for slot in self.index[service][\"slots\"]:\n",
    "            result[\"slot_name\"].append(slot[\"name\"])\n",
    "            result[\"slot_desc\"].append(slot[\"description\"])\n",
    "            result[\"slot_iscat\"].append(slot[\"is_categorical\"])\n",
    "            result[\"slot_vals\"].append(slot[\"possible_values\"])\n",
    "        \n",
    "        for intent in self.index[service][\"intents\"]:\n",
    "            result[\"intent_name\"].append(intent[\"name\"])\n",
    "            result[\"intent_desc\"].append(intent[\"description\"])\n",
    "            result[\"intent_istrans\"].append(intent[\"is_transactional\"])\n",
    "            result[\"intent_reqslots\"].append(intent[\"required_slots\"])\n",
    "            result[\"intent_optslots\"].append(list(intent[\"optional_slots\"].keys()))\n",
    "            result[\"intent_optvals\"].append(list(intent[\"optional_slots\"].values()))\n",
    "\n",
    "        return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueDataset(D.Dataset):\n",
    "    def __init__(self, filename, schemas, tokenizer, token_indexer):\n",
    "        with open(filename) as f:\n",
    "            self.ds = json.load(f)\n",
    "        self.schemas = schemas\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexer = token_indexer\n",
    "        self.dialogues = []\n",
    "        for dial in self.ds:\n",
    "            fields = self.dial_to_fields(dial)\n",
    "            self.dialogues.append(fields)\n",
    "        self.schemas = None\n",
    "        self.tokenizer = None\n",
    "        self.token_indexer = None\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dialogues[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dialogues)\n",
    "    \n",
    "    def fd_serv_name(self, dial, fields):\n",
    "        resp = dict(value=[])\n",
    "        for service in dial[\"services\"]:\n",
    "            resp[\"value\"].append(service)\n",
    "        return resp\n",
    "        \n",
    "    def fd_serv_desc(self, dial, fields):\n",
    "        resp = dict(value=[], tokens=[], ids=[], ids_pos=[], mask=[])\n",
    "        for service in dial[\"services\"]:\n",
    "            desc = self.schemas.get(service)[\"desc\"]\n",
    "            tokens = self.tokenizer(desc)\n",
    "            ids = self.token_indexer(tokens)\n",
    "            resp[\"value\"].append(desc)\n",
    "            resp[\"tokens\"].append(tokens)\n",
    "            resp[\"ids\"].append(ids)\n",
    "            resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "            resp[\"mask\"].append([1] * len(ids))\n",
    "        return resp\n",
    "    \n",
    "    def fd_slot_name(self, dial, fields):\n",
    "        resp = {\"value\": []}\n",
    "        for serv in dial[\"services\"]:\n",
    "            schema = self.schemas.get(serv)\n",
    "            resp[\"value\"].append(schema[\"slot_name\"])\n",
    "        return resp\n",
    "    \n",
    "    def fd_slot_desc(self, dial, fields):\n",
    "        resp = dict(value=[], tokens=[], ids=[], ids_pos=[], mask=[])\n",
    "        for serv in dial[\"services\"]:\n",
    "            s_desc = self.schemas.get(serv)[\"slot_desc\"]\n",
    "            s_tokens = [self.tokenizer(d) for d in s_desc]\n",
    "            s_ids = [self.token_indexer(d) for d in s_tokens]\n",
    "            s_mask = [[1] * len(d) for d in s_tokens]\n",
    "            resp[\"value\"].append(s_desc)\n",
    "            resp[\"tokens\"].append(s_tokens)\n",
    "            resp[\"ids\"].append(s_ids)\n",
    "            resp[\"ids_pos\"].append([list(range(1, len(i) + 1)) for i in s_ids])\n",
    "            resp[\"mask\"].append(s_mask)\n",
    "        return resp\n",
    "\n",
    "    def fd_slot_memory(self, dial, fields):\n",
    "        # TODO: iscat feature..\n",
    "        # memory is a sequence of slot tagger values across all frames in a dial.. that grows per turn\n",
    "        # maintain snapshot at each turn\n",
    "        resp = dict(\n",
    "            value=[], # unfeaturized memory\n",
    "            value_desc = [],\n",
    "            value_slot = [], # value -> slots that use it..\n",
    "            tokens=[], # tokenized memory [turn, mem-size, tokens]\n",
    "            tokens_desc = [],\n",
    "            ids=[], # indexed memory [turn mem-size, tokens]\n",
    "            ids_desc = [], # append desc if slots have same desc!\n",
    "            ids_pos=[],\n",
    "            ids_memsize=[], # mem sizes [turn, 1]\n",
    "            mask=[], # mask on memory [turn, mem-size, tokens]\n",
    "            mask_desc = [],\n",
    "        )\n",
    "        \n",
    "        # memory is sequential, initialized by vals from schema, only has values\n",
    "        memory = [\"NONE\", \"dontcare\"] # keep these at index 0, 1\n",
    "        memory_slot = [[\"*\"], [\"*\"]]\n",
    "        memory_desc = [\"NONE\", \"DONTCARE\"]\n",
    "        memory_index = {}\n",
    "        for serv in dial[\"services\"]:\n",
    "            schema = self.schemas.get(serv)\n",
    "            servdesc = schema[\"desc\"]\n",
    "            for slotname, slotdesc, values in zip(schema[\"slot_name\"], schema[\"slot_desc\"], schema[\"slot_vals\"]):\n",
    "                for val in values:\n",
    "                    if val not in memory_index:\n",
    "                        memory.append(val)\n",
    "                        memory_slot.append([slotname])\n",
    "                        memory_desc.append(slotdesc + \"[SEP]\" + servdesc)\n",
    "                        memory_index[val] = len(memory)\n",
    "                    else:\n",
    "                        idx = memory_index[val] - 1\n",
    "                        if slotname not in memory_slot[idx]:\n",
    "                            memory_desc[idx] = memory_desc[idx] + \"[SEP]\" + slotdesc + \"[SEP]\" + servdesc\n",
    "                            memory_slot[idx].append(slotname)\n",
    "        \n",
    "        # at each user turn create a memory snapshot..\n",
    "        for turn in dial[\"turns\"]:\n",
    "            memory = deepcopy(memory)\n",
    "            memory_desc = deepcopy(memory_desc)\n",
    "            memory_slot = deepcopy(memory_slot)\n",
    "            \n",
    "            # pick slot tagger's ground truth ; categorical slot vals are already initialized!\n",
    "            utter = turn[\"utterance\"]\n",
    "            for frame in turn[\"frames\"]:\n",
    "                schema = self.schemas.get(frame[\"service\"])\n",
    "                servdesc = schema[\"desc\"]\n",
    "                for tag in frame[\"slots\"]:\n",
    "                    slotname = tag[\"slot\"]\n",
    "                    slotdesc = schema[\"slot_desc\"][schema[\"slot_name\"].index(slotname)] # shit! O(N*2)\n",
    "                    st, en = tag[\"start\"], tag[\"exclusive_end\"]\n",
    "                    value = utter[st:en]\n",
    "                    if value not in memory_index:\n",
    "                        memory.append(value)\n",
    "                        memory_slot.append([slotname])\n",
    "                        memory_desc.append(slotdesc)\n",
    "                        memory_index[value] = len(memory)\n",
    "                    else:\n",
    "                        idx = memory_index[value] - 1\n",
    "                        if slotname not in memory_slot[idx]:\n",
    "                            memory_slot[idx].append(slotname)\n",
    "                            memory_desc[idx] = memory_desc[idx] + \"[SEP]\" + slotdesc + \"[SEP]\" + servdesc\n",
    "                        \n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                resp[\"value\"].append(memory)\n",
    "                resp[\"value_desc\"].append(memory_desc)\n",
    "                resp[\"value_slot\"].append(memory_slot)\n",
    "                resp[\"ids_memsize\"].append(len(memory))\n",
    "\n",
    "        # tokenize and index the memory values\n",
    "        # value: [turn, values], ids/tokens: [turn, values, tokens]\n",
    "        for mem_desc_snapshot, mem_snapshot in zip(resp[\"value_desc\"], resp[\"value\"]):\n",
    "            mem_tokens = []\n",
    "            mem_tokens_desc = []\n",
    "            mem_ids = []\n",
    "            mem_ids_desc = []\n",
    "            mem_pos = list(range(1, len(mem_snapshot) + 1))\n",
    "            mem_mask = []\n",
    "            mem_mask_desc = []\n",
    "            for desc, val in zip(mem_desc_snapshot, mem_snapshot):\n",
    "                # featurize memory\n",
    "                tokens = self.tokenizer(val)\n",
    "                mem_tokens.append(tokens)\n",
    "                mem_ids.append(self.token_indexer(tokens))\n",
    "                mem_mask.append([1] * len(tokens))\n",
    "                \n",
    "                # featurize memory desc\n",
    "                tokens_desc = self.tokenizer(desc)\n",
    "                mem_tokens_desc.append(tokens_desc)\n",
    "                mem_ids_desc.append(self.token_indexer(tokens_desc))\n",
    "                mem_mask_desc.append([1] * len(tokens_desc))\n",
    "                \n",
    "            resp[\"tokens\"].append(mem_tokens)\n",
    "            resp[\"tokens_desc\"].append(mem_tokens_desc)\n",
    "            resp[\"ids\"].append(mem_ids)\n",
    "            resp[\"ids_desc\"].append(mem_ids_desc)\n",
    "            resp[\"ids_pos\"].append(mem_pos)\n",
    "            resp[\"mask\"].append(mem_mask)\n",
    "            resp[\"mask_desc\"].append(mem_mask_desc)\n",
    "        \n",
    "        return resp\n",
    "    \n",
    "    def fd_slot_memory_loc(self, dial, fields):\n",
    "        resp = dict(\n",
    "            value=[],  # string value\n",
    "            ids=[], # memory loc\n",
    "            ids_onehot=[], # onehot of memory loc\n",
    "            mask=[],\n",
    "            mask_onehot=[],\n",
    "            mask_none=[], # 1 -> non NONE values\n",
    "            mask_none_onehot=[],\n",
    "        )\n",
    "        \n",
    "        # query dialog memory snapshots per turn. NOTE: fd_slot_memory should exec first.\n",
    "        memory = fields[\"slot_memory\"][\"value\"]\n",
    "        \n",
    "        # init snapshot: service, slot -> memory loc, val\n",
    "        memory_loc = []\n",
    "        memory_val = []\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                loc = OrderedDict()\n",
    "                val = OrderedDict()\n",
    "                for serv in dial[\"services\"]:\n",
    "                    loc[serv] = OrderedDict()\n",
    "                    val[serv] = OrderedDict()\n",
    "                    for slot in self.schemas.get(serv)[\"slot_name\"]:\n",
    "                        loc[serv][slot] = None\n",
    "                        val[serv][slot] = None\n",
    "                memory_loc.append(loc)\n",
    "                memory_val.append(val)\n",
    "        \n",
    "        # fill the memory locations \n",
    "        snapshot_id = 0\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                turn_memory = memory[snapshot_id]\n",
    "                turn_memory_loc = memory_loc[snapshot_id]\n",
    "                turn_memory_val = memory_val[snapshot_id]\n",
    "                for frame in turn[\"frames\"]:\n",
    "                    service = frame[\"service\"]\n",
    "                    for slot, values in frame[\"state\"][\"slot_values\"].items():\n",
    "                        val = re.sub(\"\\u2013\", \"-\", values[0]) # dial 59_00125 turn 14\n",
    "                        turn_memory_loc[service][slot] = turn_memory.index(val)\n",
    "                        turn_memory_val[service][slot] = val\n",
    "                    # add locations to UNKNOWN slots\n",
    "                    for slot, val in turn_memory_loc[service].items():\n",
    "                        if val is None:\n",
    "                            turn_memory_loc[service][slot] = turn_memory.index(\"NONE\")\n",
    "                            turn_memory_val[service][slot] = \"NONE\"\n",
    "                snapshot_id += 1\n",
    "        \n",
    "        # featurize\n",
    "        snapshot_id = 0\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                turn_memory = memory[snapshot_id]\n",
    "                turn_memory_loc = memory_loc[snapshot_id]\n",
    "                turn_memory_val = memory_val[snapshot_id]\n",
    "                none_loc = memory[snapshot_id].index(\"NONE\")\n",
    "                turn_fields = dict(\n",
    "                    value=[], ids=[], ids_onehot=[], mask=[], mask_onehot=[],\n",
    "                    mask_none=[], mask_none_onehot=[],\n",
    "                )\n",
    "\n",
    "                for serv in turn_memory_loc:\n",
    "                    mem_size = len(turn_memory)\n",
    "                    vals = list(turn_memory_val[serv].values())\n",
    "                    ids = list(turn_memory_loc[serv].values())\n",
    "                    ids_onehots = label_binarize(ids, list(range(mem_size)))\n",
    "                    mask = [1] * len(ids)\n",
    "                    mask_onehots = [[1] * mem_size for _ in ids]\n",
    "\n",
    "                    mask_none = [int(v!=\"NONE\") for v in vals]\n",
    "                    mask_none_onehot = [[1] * mem_size for _ in ids]\n",
    "                    for v, loc, onehot in zip(vals, ids, mask_none_onehot):\n",
    "                        if v == \"NONE\":\n",
    "                            onehot[loc] = 0\n",
    "                                \n",
    "                    turn_fields[\"value\"].append(vals)\n",
    "                    turn_fields[\"ids\"].append(ids)\n",
    "                    turn_fields[\"ids_onehot\"].append(ids_onehots)\n",
    "                    turn_fields[\"mask\"].append(mask)\n",
    "                    turn_fields[\"mask_onehot\"].append(mask_onehots)\n",
    "                    turn_fields[\"mask_none\"].append(mask_none)\n",
    "                    turn_fields[\"mask_none_onehot\"].append(mask_none_onehot)\n",
    "\n",
    "                # update turn\n",
    "                for k, v in turn_fields.items():\n",
    "                    resp[k].append(v)\n",
    "                \n",
    "                snapshot_id += 1\n",
    "            \n",
    "        return resp\n",
    "    \n",
    "    def fd_num_turns(self, dial, fields):\n",
    "        return {\"ids\": len(dial[\"turns\"])}\n",
    "    \n",
    "    def fd_num_frames(self, dial, fields):\n",
    "        return {\"ids\": [len(t[\"frames\"]) for t in dial[\"turns\"]]}\n",
    "    \n",
    "    def fd_usr_utter(self, dial, fields):\n",
    "        resp = dict(value=[], ids=[], ids_pos=[], mask=[], tokens=[])\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"USER\":\n",
    "                utter = turn[\"utterance\"]\n",
    "                tokens = self.tokenizer(utter)\n",
    "                ids = self.token_indexer(tokens)\n",
    "                resp[\"value\"].append(utter)\n",
    "                resp[\"ids\"].append(ids)\n",
    "                resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "                resp[\"tokens\"].append(tokens)\n",
    "                resp[\"mask\"].append([1] * len(tokens))\n",
    "        return resp\n",
    "    \n",
    "    def fd_sys_utter(self, dial, fields):\n",
    "        resp = dict(value=[], ids=[], ids_pos=[], mask=[], tokens=[])\n",
    "        for turn in dial[\"turns\"]:\n",
    "            if turn[\"speaker\"] == \"SYSTEM\":\n",
    "                utter = turn[\"utterance\"]\n",
    "                tokens = self.tokenizer(utter)\n",
    "                ids = self.token_indexer(tokens)\n",
    "                resp[\"value\"].append(utter)\n",
    "                resp[\"ids\"].append(ids)\n",
    "                resp[\"ids_pos\"].append(list(range(1, len(ids) + 1)))\n",
    "                resp[\"tokens\"].append(tokens)\n",
    "                resp[\"mask\"].append([1] * len(tokens))\n",
    "        return resp\n",
    "    \n",
    "    def fd_dial_id(self, dial, fields):\n",
    "        return {\"value\": dial[\"dialogue_id\"]}\n",
    "    \n",
    "    def dial_to_fields(self, dial):\n",
    "        fields = {}\n",
    "        ordered_funcs = [\n",
    "            \"fd_dial_id\",\n",
    "            \"fd_num_turns\", \"fd_num_frames\",\n",
    "            \"fd_serv_name\", \"fd_serv_desc\", \n",
    "            \"fd_slot_name\", \"fd_slot_desc\",\n",
    "            \"fd_slot_memory\", \"fd_slot_memory_loc\",\n",
    "            \"fd_usr_utter\", \"fd_sys_utter\"]\n",
    "        for func in ordered_funcs:\n",
    "            name = func.split(\"fd_\", maxsplit=1)[-1]\n",
    "            value = getattr(self, func)(dial, fields)\n",
    "            if value is not None:\n",
    "                fields[name] = value\n",
    "        return fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "bert_ = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = Tokenizer(bert_)\n",
    "token_indexer = TokenIndexer(bert_)\n",
    "\n",
    "train_schemas = Schemas(\"../data/train/schema.json\")\n",
    "test_schemas = Schemas(\"../data/dev/schema.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DialogueDataset(\"../data/train/dialogues_001.json\", train_schemas, tokenizer, token_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e45eaab6a942abb28234392ddd1ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=127), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "train_dial_sets = []\n",
    "train_dial_files = sorted(glob.glob(\"../data/train/dialogues*.json\"))\n",
    "num_workers = min(20, len(train_dial_files))\n",
    "\n",
    "def worker(filename):\n",
    "    return DialogueDataset(filename, train_schemas, tokenizer, token_indexer)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    for ds in tqdm(executor.map(worker, train_dial_files), total=len(train_dial_files)):\n",
    "        train_dial_sets.append(ds)\n",
    "\n",
    "train_ds = D.ConcatDataset(train_dial_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405c6ed13f544def86c8a5ac894bfbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "test_dial_sets = []\n",
    "test_dial_files = sorted(glob.glob(\"../data/dev/dialogues*.json\"))\n",
    "num_workers = min(20, len(train_dial_files))\n",
    "\n",
    "def worker(filename):\n",
    "    return DialogueDataset(filename, test_schemas, tokenizer, token_indexer)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    for ds in tqdm(executor.map(worker, test_dial_files), total=len(test_dial_files)):\n",
    "        test_dial_sets.append(ds)\n",
    "\n",
    "test_ds = D.ConcatDataset(test_dial_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def move_to_device(obj, device):\n",
    "    if type(obj) is list:\n",
    "        return [move_to_device(o, device) for o in obj]\n",
    "    elif type(obj) is dict:\n",
    "        return {k: move_to_device(v, device) for k, v in obj.items()}\n",
    "    elif type(obj) is torch.Tensor or isinstance(obj, nn.Module):\n",
    "        return obj.to(device)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dialogue_mini_batcher(dialogues):\n",
    "    default_padding = 0\n",
    "    batch = {}\n",
    "    for dial in dialogues:\n",
    "        # populate the batch\n",
    "        for field, data in dial.items():\n",
    "            if field not in batch:\n",
    "                batch[field] = {}\n",
    "            for attr, val in data.items():\n",
    "                if attr == \"padding\":\n",
    "                    batch[field][attr] = val\n",
    "                else:\n",
    "                    batch[field][attr] = batch[field].get(attr, [])\n",
    "                    batch[field][attr].append(val)\n",
    "\n",
    "    # padding on field attributes\n",
    "    for field_name, data in batch.items():\n",
    "        for attr in data:\n",
    "            if attr.startswith((\"ids\", \"mask\")):\n",
    "                data[attr] = padded_array(data[attr], default_padding)\n",
    "                data[attr] = torch.tensor(data[attr], device=\"cpu\") # whatif its in device0 in epoch0, then at epoch1, sent to device1\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "class DialogIterator(object):\n",
    "    \"\"\"A simple wrapper on DataLoader\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, *args, **kw):\n",
    "        self.length = None\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.iterator = D.DataLoader(dataset, batch_size, *args, **kw)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.length is None:\n",
    "            self.length = 0\n",
    "            for dial in self.dataset:\n",
    "                self.length += (dial[\"num_turns\"][\"ids\"] * len(dial[\"serv_name\"][\"value\"]))\n",
    "            self.length = int(self.length / self.batch_size)\n",
    "        return self.length\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.iterator:\n",
    "            num_turns = batch[\"usr_utter\"][\"ids\"].shape[1]\n",
    "            num_services = batch[\"serv_desc\"][\"ids\"].shape[1]\n",
    "            for turnid in range(num_turns):\n",
    "                for sid in range(num_services):\n",
    "                    inputs = dict(turnid=turnid, serviceid=sid)\n",
    "                    inputs.update(batch)\n",
    "                    yield inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_turns ids --> torch.Size([1])\n",
      "num_frames ids --> torch.Size([1, 24])\n",
      "serv_desc ids --> torch.Size([1, 1, 10])\n",
      "serv_desc ids_pos --> torch.Size([1, 1, 10])\n",
      "serv_desc mask --> torch.Size([1, 1, 10])\n",
      "slot_desc ids --> torch.Size([1, 1, 11, 12])\n",
      "slot_desc ids_pos --> torch.Size([1, 1, 11, 12])\n",
      "slot_desc mask --> torch.Size([1, 1, 11, 12])\n",
      "slot_memory ids --> torch.Size([1, 12, 29, 10])\n",
      "slot_memory ids_desc --> torch.Size([1, 12, 29, 40])\n",
      "slot_memory ids_pos --> torch.Size([1, 12, 29])\n",
      "slot_memory ids_memsize --> torch.Size([1, 12])\n",
      "slot_memory mask --> torch.Size([1, 12, 29, 10])\n",
      "slot_memory mask_desc --> torch.Size([1, 12, 29, 40])\n",
      "slot_memory_loc ids --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc ids_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "slot_memory_loc mask --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc mask_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "slot_memory_loc mask_none --> torch.Size([1, 12, 1, 11])\n",
      "slot_memory_loc mask_none_onehot --> torch.Size([1, 12, 1, 11, 29])\n",
      "usr_utter ids --> torch.Size([1, 12, 25])\n",
      "usr_utter ids_pos --> torch.Size([1, 12, 25])\n",
      "usr_utter mask --> torch.Size([1, 12, 25])\n",
      "sys_utter ids --> torch.Size([1, 12, 31])\n",
      "sys_utter ids_pos --> torch.Size([1, 12, 31])\n",
      "sys_utter mask --> torch.Size([1, 12, 31])\n"
     ]
    }
   ],
   "source": [
    "def get_sample(ds, size=1):\n",
    "    return next(iter(DialogIterator(ds, size, collate_fn=dialogue_mini_batcher)))\n",
    "\n",
    "def print_shapes(ds):\n",
    "    it = get_sample(ds, size=1)\n",
    "    for field, val in it.items():\n",
    "        if type(val) is dict:\n",
    "            for attr in val:\n",
    "                if attr.startswith(\"ids\") or attr.startswith(\"mask\"):\n",
    "                    print(field, attr, \"-->\", val[attr].shape)\n",
    "                    \n",
    "\n",
    "# TODO: why mem ids, and mem loc size is diff by 1?\n",
    "print_shapes(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertModel, BertConfig\n",
    "from allennlp.training.metrics import BooleanAccuracy, CategoricalAccuracy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDownstream(nn.Module):\n",
    "    # https://huggingface.co/pytorch-transformers/model_doc/bert.html\n",
    "    # https://github.com/hanxiao/bert-as-service/blob/master/docs/section/faq.rst#id6\n",
    "    \n",
    "    def __init__(self, btype, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.emb = BertModel.from_pretrained(btype, output_hidden_states=True)\n",
    "        for name, param in self.emb.named_parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return 768\n",
    "    \n",
    "    def forward(self, input_ids, position_ids=None, attention_mask=None, flat=None):\n",
    "        sh = list(input_ids.shape)\n",
    "        \n",
    "        if flat:\n",
    "            st, en = flat\n",
    "        elif len(sh) == 3:\n",
    "            st, en = 0, 1\n",
    "        elif len(sh) in (0,1,2):\n",
    "            st, en = 0, 0\n",
    "        else:\n",
    "            st, en = 1, -2\n",
    "        \n",
    "        input_ids = torch.flatten(input_ids, st, en).long()\n",
    "        if position_ids is not None:\n",
    "            position_ids = torch.flatten(position_ids, st, en).long()\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = torch.flatten(attention_mask, st, en).long()\n",
    "        \n",
    "        outputs = self.emb(input_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs[2][4]\n",
    "        pooled = pooled.view(sh + [-1])\n",
    "        \n",
    "        return pooled #*->*e\n",
    "\n",
    "\n",
    "class CandidateSelector(nn.Module):\n",
    "    \"\"\"\n",
    "    memory -- represents temporal hash table of text values, that monotonically grows\n",
    "    memory_desc -- represents sequential description to every value in hash table\n",
    "    slot, utter -- represent query/key descriptions\n",
    "    \n",
    "    The idea is that we model a hash function \n",
    "        F: slot, utter, time -> memory_location\n",
    "    \n",
    "    This is a mix of ideas from\n",
    "        - Memory Networks by Jason Weston, FAIR\n",
    "        - E2E Memory Networks by Sukhbaatar, NYU/FAIR\n",
    "        - Pointer Networks by Oriol Vinayls, Google Brain\n",
    "        - Alignment and Translation by Bahdanau, MILA\n",
    "    \n",
    "        - Weston and Sukhbaatar demonstrate memory models on Facebook bAbI tasks. that capture some temporal challenges.\n",
    "            while Vinayls tweaks the idea of Bahdanau's attention, to classification/regress targets represented in latent space.\n",
    "            (NOTE: their motivation is subtly different, but this explanation still stands valid)\n",
    "    \n",
    "    Unique contribution:\n",
    "        - Explore the problem where memory grows and has temporal information.\n",
    "        - Model a hash function that understands temporal (just like Vinayls) but but \n",
    "            new challenges are:\n",
    "            - applied to dialog state (no one else did before), where the hash function has additional challenges of dealing with \n",
    "                guessing user behavior dist. and language subtlities (eg: coreference and ellipsis resolutions.)\n",
    "            - the hash function is learning from real world data, unlike previous works where toy data are used. \n",
    "                the hash key is can change just because user explicitly/implicitly says something..\n",
    "            - the model is setup in a way it supports growth, and scale across domains. Sukhbaatar's approach is fixed (verify again!)\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = BertDownstream(\"bert-base-uncased\")\n",
    "        emb_dim = self.emb.output_dim\n",
    "        \n",
    "        self.l0 = nn.GRU(emb_dim, emb_dim, batch_first=True, num_layers=1) # encode utter\n",
    "        self.l1 = nn.GRU(emb_dim, emb_dim, batch_first=True, num_layers=1) # encode memory\n",
    "        self.l2 = nn.GRU(emb_dim, emb_dim, batch_first=True, num_layers=1) # encode query slot\n",
    "       \n",
    "        # attentions\n",
    "        self.l3 = nn.Linear(2*emb_dim, emb_dim)\n",
    "        self.l4 = nn.Bilinear(emb_dim, emb_dim, 1)\n",
    "         \n",
    "        # metrics\n",
    "        self.acc = CategoricalAccuracy()\n",
    "        self.goal_acc = CategoricalAccuracy()\n",
    "        \n",
    "        self.register_buffer(\"utter_state\", None)\n",
    "\n",
    "        # init weights: classifier's performance changes heavily on these\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.startswith((\"l0.\", \"11.\", \"l2.\")):\n",
    "                print(\"Initializing bias/weights of \", name)\n",
    "                if \"weight\" in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    param.data.fill_(0.)\n",
    "\n",
    "    def get_metrics(self, reset=False, goal_reset=False):\n",
    "        return dict(\n",
    "            acc=self.acc.get_metric(reset), # avg per service\n",
    "            goal_acc=self.goal_acc.get_metric(goal_reset), # avg per turn\n",
    "        )\n",
    "    \n",
    "    def encode_utter(self, batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        usr_utter, usr_mask, usr_pos = batch[\"usr_utter\"][\"ids\"][:,turnid,:], batch[\"usr_utter\"][\"mask\"][:,turnid,:], batch[\"usr_utter\"][\"ids_pos\"][:,turnid,:]\n",
    "        sys_utter, sys_mask, sys_pos = batch[\"sys_utter\"][\"ids\"][:,turnid,:], batch[\"sys_utter\"][\"mask\"][:,turnid,:], batch[\"sys_utter\"][\"ids_pos\"][:,turnid,:]\n",
    "        \n",
    "        usr_utter = self.emb(usr_utter, position_ids=usr_pos, attention_mask=usr_mask)\n",
    "        sys_utter = self.emb(sys_utter, position_ids=sys_pos, attention_mask=sys_mask)\n",
    "        \n",
    "        utter = torch.cat([sys_utter, usr_utter], dim=1) # b2se\n",
    "\n",
    "        utter_h = self.utter_state.detach() if turnid != 0 else None\n",
    "        utter, utter_h = self.l0(utter, utter_h)\n",
    "        self.utter_state = utter_h\n",
    "        \n",
    "        return utter_h[-1] # be\n",
    "\n",
    "    def encode_memory(self, batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        # Encode memory\n",
    "        memory = batch[\"slot_memory\"][\"ids\"][:,turnid,:]\n",
    "        memory_mask = batch[\"slot_memory\"][\"mask\"][:,turnid,:]\n",
    "        memory_pos = batch[\"slot_memory\"][\"ids_pos\"][:,turnid,:]\n",
    "        sh = memory.shape\n",
    "        \n",
    "        memory_pos = memory_pos[:,:,None].repeat(1,1,sh[-1])# bm->bms\n",
    "        memory = self.emb(memory, position_ids=memory_pos, attention_mask=memory_mask) # bmse\n",
    "        \n",
    "        # Encode memory desc\n",
    "        memory_desc = batch[\"slot_memory\"][\"ids_desc\"][:,turnid,:]\n",
    "        memory_desc_mask = batch[\"slot_memory\"][\"mask_desc\"][:,turnid,:]\n",
    "        sh2 = memory_desc.shape\n",
    "        \n",
    "        memory_pos = batch[\"slot_memory\"][\"ids_pos\"][:,turnid,:]\n",
    "        memory_desc_pos = memory_pos[:,:,None].repeat(1,1,sh2[-1]) # bm->bms\n",
    "        memory_desc = self.emb(memory_desc, position_ids=memory_desc_pos, attention_mask=memory_desc_mask) # bmse\n",
    "        \n",
    "        # across text\n",
    "        memory = torch.cat([memory, memory_desc], dim=2) # bm2se\n",
    "        memory = torch.flatten(memory, 0, 1) # bm,2s,e\n",
    "        memory, memory_h = self.l1(memory)\n",
    "        \n",
    "        memory_h = memory_h[-1].view(sh[0], sh[1], -1) # pool two layers in bidirectional.\n",
    "        return memory_h # bme\n",
    "    \n",
    "    def encode_slot_desc(self, batch):\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        desc = batch[\"slot_desc\"][\"ids\"][:,serviceid,:] # [batch, slots, tokens]\n",
    "        desc_pos = batch[\"slot_desc\"][\"ids_pos\"][:,serviceid,:]\n",
    "        desc_mask = batch[\"slot_desc\"][\"mask\"][:,serviceid,:]\n",
    "        sh = desc.shape\n",
    "        \n",
    "        desc = self.emb(desc, position_ids=desc_pos, attention_mask=desc_mask) # bste\n",
    "        desc = torch.flatten(desc, 0, 1) # bs,t,e\n",
    "        desc, desc_h = self.l2(desc)\n",
    "    \n",
    "        desc_h = desc_h[-1].view(sh[0], sh[1], -1)\n",
    "    \n",
    "        return desc_h # bse\n",
    "        \n",
    "    def compute_score1(self, memory, slot, utter):\n",
    "        # memory: bme\n",
    "        # slot: bse\n",
    "        # utter: be\n",
    "        s = slot.shape[1]\n",
    "        m = memory.shape[1]\n",
    "        \n",
    "        utter = utter[:,None,:].repeat(1,s,1) #be->bse\n",
    "\n",
    "        key = self.l3(torch.cat([utter, slot], dim=-1)) # bs2e->bse\n",
    "        key = torch.tanh(key)\n",
    "        key = key[:,:,None,:].repeat(1,1,m,1) # bsme\n",
    "        \n",
    "        memory = memory[:,None,:,:].repeat(1,s,1,1) # bsme\n",
    "        \n",
    "        energy = self.l4(key, memory) #bsme->bsm1\n",
    "        energy = F.softmax(energy.squeeze(-1), dim=-1)\n",
    "        return energy\n",
    "        \n",
    "    def forward(self, **batch):\n",
    "        turnid = batch[\"turnid\"]\n",
    "        serviceid = batch[\"serviceid\"]\n",
    "        \n",
    "        # doc: GRU outputs [batch, seq, emb * dir] [layers * dir, batch, emb]\n",
    "\n",
    "        # get fixed size encodings\n",
    "        utter = self.encode_utter(batch) # be\n",
    "        memory = self.encode_memory(batch) # bme\n",
    "        slot_desc = self.encode_slot_desc(batch) # bse\n",
    "        \n",
    "        # map: slot desc -> memory\n",
    "        score = self.compute_score1(memory, slot_desc, utter) # bsm\n",
    "        output = {\"score\": score}\n",
    "\n",
    "        if \"slot_memory_loc\" in batch:\n",
    "            target = batch[\"slot_memory_loc\"]\n",
    "            memsize = target[\"ids_onehot\"].shape[-1]\n",
    "            pred_score = score.view(-1, memsize) # bsm->bs,m \n",
    "            \n",
    "            # onehot targets\n",
    "            target_score_oh = target[\"ids_onehot\"][:,turnid,serviceid,:].contiguous().view(-1, memsize).float() # bsm->bs,m\n",
    "            target_mask_oh = (target[\"mask_onehot\"][:,turnid,serviceid,:] * target[\"mask_none_onehot\"][:,turnid,serviceid,:]).contiguous().view(-1, memsize).float()\n",
    "            \n",
    "            # target\n",
    "            target_score = target[\"ids\"][:,turnid,serviceid,:].float() # [batch, slots]\n",
    "            target_mask = (target[\"mask\"][:,turnid,serviceid,:] * target[\"mask_none\"][:,turnid,serviceid,:]).float()\n",
    "            \n",
    "            # loss\n",
    "            output[\"loss\"] = F.binary_cross_entropy(pred_score, target_score_oh, target_mask_oh).unsqueeze(0) # don't return scalar\n",
    "            \n",
    "            # log metrics\n",
    "            self.acc(score, target_score, target_mask)\n",
    "            self.goal_acc(score, target_score, target_mask)\n",
    "            \n",
    "            output[\"target_ids\"] = target_score\n",
    "            output[\"pred_ids\"] = torch.argmax(score, dim=-1)\n",
    "            output[\"mask\"] = target[\"mask\"][:,turnid,serviceid,:].float()\n",
    "            output[\"mask_none\"] = target[\"mask_none\"][:,turnid,serviceid,:].float()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.tensorboard_writer import TensorboardWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module(m):\n",
    "    if type(m) is nn.DataParallel:\n",
    "        return m.module\n",
    "    return m\n",
    "\n",
    "def train(model, optimizer, batch_size, num_epochs, train_ds, test_ds, device):\n",
    "    model = model.train()\n",
    "    current_batch = 1 # tensorboard doesn't like 0\n",
    "    tensorboard = TensorboardWriter(\n",
    "        get_batch_num_total=lambda: current_batch,\n",
    "        summary_interval=10,\n",
    "        serialization_dir=\"../data/tensorboard/\"\n",
    "    )\n",
    "    \n",
    "    histogram_weights = [name for name, p in model.named_parameters() if not \".emb.\" in name]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_iter = DialogIterator(train_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "        num_batches = len(train_iter) \n",
    "        if test_ds:\n",
    "            test_iter = DialogIterator(test_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "            num_batches += len(test_iter)\n",
    "        \n",
    "        with tqdm(total=num_batches) as pbar:\n",
    "            # train\n",
    "            pbar.set_description(\"Train {}\".format(epoch))\n",
    "            model = model.train()\n",
    "            train_iter = DialogIterator(train_ds, batch_size, collate_fn=dialogue_mini_batcher)\n",
    "            metrics = OrderedDict()\n",
    "            \n",
    "            # to know when the dialog and service changes\n",
    "            turnid = -1\n",
    "            \n",
    "            for i, batch in enumerate(train_iter):\n",
    "                current_batch += 1\n",
    "                batch = move_to_device(batch, device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(**batch)\n",
    "                output[\"loss\"] = output[\"loss\"].mean()\n",
    "                output[\"loss\"].backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # at each new turn\n",
    "                if turnid != batch[\"turnid\"]:\n",
    "                    metrics.update(module(model).get_metrics(reset=True, goal_reset=True))\n",
    "                else:\n",
    "                    curr_met = module(model).get_metrics(reset=True)\n",
    "                    metrics.update(acc=curr_met[\"acc\"])\n",
    "                    \n",
    "                metrics[\"loss\"] = output[\"loss\"].item()\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(metrics)\n",
    "                \n",
    "                metrics[\"turnid\"] = batch[\"turnid\"]\n",
    "                metrics[\"servid\"] = batch[\"serviceid\"]\n",
    "\n",
    "                # update tensorboard logs\n",
    "                tensorboard.add_train_scalar(\"loss\", metrics[\"loss\"], timestep=current_batch)\n",
    "                tensorboard.log_metrics(train_metrics=metrics, epoch=current_batch)\n",
    "                tensorboard.log_parameter_and_gradient_statistics(model, None)\n",
    "                \n",
    "                # histograms, I guess take longer..\n",
    "                if turnid == 0:\n",
    "                    st_time = time.time()\n",
    "                    tensorboard.log_histograms(model, histogram_weights)\n",
    "                    tensorboard.add_train_histogram(\"target_ids\", output[\"target_ids\"])\n",
    "                    tensorboard.add_train_histogram(\"pred_ids\", output[\"pred_ids\"])\n",
    "                    metrics[\"time\"] = time.time() - st_time\n",
    "                \n",
    "                # at the end of the loop, update prev turnid\n",
    "                turnid = batch[\"turnid\"]\n",
    "\n",
    "            # test\n",
    "            if test_ds:\n",
    "                pbar.set_description(\"Test {}\".format(epoch))\n",
    "                metrics = OrderedDict(epoch=epoch)\n",
    "                turnid = -1\n",
    "                with torch.no_grad():\n",
    "                    model = model.eval()\n",
    "                    for i, batch in enumerate(test_iter):\n",
    "                        current_batch += 1\n",
    "                        batch = move_to_device(batch, device)\n",
    "                        output = model(**batch)\n",
    "                        output[\"loss\"] = output[\"loss\"].mean()\n",
    "\n",
    "                        # at each new turn\n",
    "                        if turnid != batch[\"turnid\"]:\n",
    "                            metrics.update(module(model).get_metrics(reset=True, goal_reset=True))\n",
    "                        else:\n",
    "                            curr_met = module(model).get_metrics(reset=True)\n",
    "                            metrics.update(acc=curr_met[\"acc\"])\n",
    "\n",
    "                        metrics[\"loss\"] = output[\"loss\"].item()\n",
    "                        pbar.update(1)\n",
    "                        pbar.set_postfix(metrics)\n",
    "                        turnid = batch[\"turnid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"../data/model0.pkl\")\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove tensorboard logs\n",
      "set number of devices\n",
      "loading model\n",
      "Initializing bias/weights of  l0.weight_ih_l0\n",
      "Initializing bias/weights of  l0.weight_hh_l0\n",
      "Initializing bias/weights of  l0.bias_ih_l0\n",
      "Initializing bias/weights of  l0.bias_hh_l0\n",
      "Initializing bias/weights of  l2.weight_ih_l0\n",
      "Initializing bias/weights of  l2.weight_hh_l0\n",
      "Initializing bias/weights of  l2.bias_ih_l0\n",
      "Initializing bias/weights of  l2.bias_hh_l0\n",
      "started training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddc5699725d4567a36b76393a0c41e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Remove tensorboard logs\")\n",
    "!rm -rf ../data/tensorboard/*\n",
    "\n",
    "print(\"set number of devices\") # not sure we can in jupyter once program already kicked in the first time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = \"cuda\"\n",
    "\n",
    "print(\"loading model\")\n",
    "model = CandidateSelector()\n",
    "#model = nn.DataParallel(model)\n",
    "model = move_to_device(model, device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "train_samples = [train_ds[i] for i in range(1000)]\n",
    "test_samples = [test_ds[i] for i in range(10)]\n",
    "\n",
    "print(\"started training\")\n",
    "train(\n",
    "    model=model,\n",
    "    optimizer=optim,\n",
    "    train_ds=train_samples,\n",
    "    test_ds=test_samples,\n",
    "    device=device,\n",
    "    num_epochs=20,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Goal Acc:  0.12333333333333334\n",
      "Avg Joint Goal Acc:  0.0\n",
      "\n",
      "\n",
      "   dialid    num_turns    turnid    servid  servname         memsize  slotname                tgt_val                        tgt_loc  prd_val      prd_loc    correct    mask \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  restaurant_name         NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  date                    NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  time                    half past 11 in the morning         14  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  has_seating_outdoors    NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  has_vegetarian_options  NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  phone_number            NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  rating                  NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  address                 NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  number_of_seats         2                                    5  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  price_range             NONE                                 0  moderate          11          0       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  location                NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         0         0  Restaurants_2         15  category                NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  restaurant_name         Sino                                16  Sino              16        100       1 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  date                    NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  time                    half past 11 in the morning         14  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  has_seating_outdoors    NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  has_vegetarian_options  NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  phone_number            NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  rating                  NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  address                 NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  number_of_seats         2                                    5  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  price_range             NONE                                 0  moderate          11          0       0 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  location                San Jose                            15  San Jose          15        100       1 \n",
      "\n",
      "  1_00000            6         1         0  Restaurants_2         17  category                NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  restaurant_name         Sino                                16  Sino              16        100       1 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  date                    today                               18  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  time                    11:30 am                            17  2                  5          0       1 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  has_seating_outdoors    NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  has_vegetarian_options  NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  phone_number            NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  rating                  NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  address                 NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  number_of_seats         2                                    5  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  price_range             NONE                                 0  moderate          11          0       0 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  location                San Jose                            15  San Jose          15        100       1 \n",
      "\n",
      "  1_00000            6         2         0  Restaurants_2         19  category                NONE                                 0  11:30 am          17          0       0 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  restaurant_name         Sino                                16  Sino              16        100       1 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  date                    today                               18  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  time                    11:30 am                            17  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  has_seating_outdoors    NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  has_vegetarian_options  NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  phone_number            NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  rating                  NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  address                 NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  number_of_seats         2                                    5  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  price_range             NONE                                 0  moderate          11          0       0 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  location                San Jose                            15  San Jose          15        100       1 \n",
      "\n",
      "  1_00000            6         3         0  Restaurants_2         20  category                NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  restaurant_name         Sino                                16  Sino              16        100       1 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  date                    today                               18  Sino              16          0       1 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  time                    11:30 am                            17  11:30 am          17        100       1 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  has_seating_outdoors    NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  has_vegetarian_options  NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  phone_number            NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  rating                  NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  address                 NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  number_of_seats         2                                    5  NONE               0          0       1 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  price_range             NONE                                 0  moderate          11          0       0 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  location                San Jose                            15  San Jose          15        100       1 \n",
      "\n",
      "  1_00000            6         4         0  Restaurants_2         21  category                NONE                                 0  11:30 am          17          0       0 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  restaurant_name         Sino                                16  Sino              16        100       1 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  date                    today                               18  Sino              16          0       1 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  time                    11:30 am                            17  2                  5          0       1 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  has_seating_outdoors    NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  has_vegetarian_options  NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  phone_number            NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  rating                  NONE                                 0  2                  5          0       0 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  address                 NONE                                 0  NONE               0        100       0 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  number_of_seats         2                                    5  2                  5        100       1 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  price_range             NONE                                 0  moderate          11          0       0 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  location                San Jose                            15  San Jose          15        100       1 \n",
      "\n",
      "  1_00000            6         5         0  Restaurants_2         21  category                NONE                                 0  11:30 am          17          0       0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def infer_batch(model, test_ds, batch_size, device):\n",
    "    result_table = []\n",
    "\n",
    "    goal_acc = []\n",
    "    joint_acc = []\n",
    "\n",
    "    total_turn_acc = None\n",
    "    total_joint_acc = None\n",
    "    num_turns = 0\n",
    "    num_slots = 0\n",
    "\n",
    "    model = model.eval()\n",
    "    \n",
    "    for batch in DialogIterator(test_ds, batch_size, collate_fn=dialogue_mini_batcher):\n",
    "        batch = move_to_device(batch, device)\n",
    "        with torch.no_grad():\n",
    "            result = model(**batch)\n",
    "        \n",
    "        turnid = batch[\"turnid\"]\n",
    "        servid = batch[\"serviceid\"]\n",
    "        num_batches = batch[\"usr_utter\"][\"ids\"].shape[0]\n",
    "        \n",
    "        if turnid == 0:\n",
    "            # update previous turn's.\n",
    "            if total_turn_acc is not None:\n",
    "                goal_acc.append(total_turn_acc / num_turns)\n",
    "                joint_acc.append(total_joint_acc / num_turns)\n",
    "            \n",
    "            # reset counter\n",
    "            total_turn_acc = 0\n",
    "            total_joint_acc = 1 # its binary 1 or 0\n",
    "            num_turns += 1\n",
    "\n",
    "        batch_fields = dict(\n",
    "            prd_mem_loc = result[\"pred_ids\"], # B,slot\n",
    "            tgt_mem_loc = result[\"target_ids\"],\n",
    "            mask = result[\"mask\"],\n",
    "            mask_none = result[\"mask_none\"], # 1 -> target is not None\n",
    "            dial_id = batch[\"dial_id\"][\"value\"],\n",
    "            serv_name = batch[\"serv_name\"][\"value\"],\n",
    "            slot_name = batch[\"slot_name\"][\"value\"],\n",
    "            num_turns = batch[\"num_turns\"][\"ids\"],\n",
    "            memory = batch[\"slot_memory\"][\"value\"], # B,turn,memory\n",
    "        )\n",
    "\n",
    "        for b in range(num_batches):\n",
    "            num_slots = 0\n",
    "\n",
    "            fields = {k: v[b] for k, v in batch_fields.items()}\n",
    "            memory = fields[\"memory\"][turnid]\n",
    "            \n",
    "            for slotid, (prd_loc, tgt_loc) in enumerate(zip(fields[\"prd_mem_loc\"], fields[\"tgt_mem_loc\"])):\n",
    "                # clip the locations.. they somehow predict in padding regions!! Make it NONE\n",
    "                prd_loc = int(prd_loc.item()) if prd_loc < len(memory) else 0\n",
    "                tgt_loc = int(tgt_loc.item()) if tgt_loc < len(memory) else 0\n",
    "                \n",
    "                prd_val = memory[prd_loc]\n",
    "                tgt_val = memory[tgt_loc]\n",
    "                mask = fields[\"mask\"][slotid].item()\n",
    "                mask_none = fields[\"mask_none\"][slotid].item()\n",
    "                dialid = fields[\"dial_id\"]\n",
    "                servname = fields[\"serv_name\"][servid]\n",
    "                slotname = fields[\"slot_name\"][servid][slotid]\n",
    "                num_turns = fields[\"num_turns\"].item() / 2 # usr-sys turn pairs\n",
    "                \n",
    "                # update acc counter\n",
    "                if mask * mask_none == 1:\n",
    "                    total_turn_acc += int(prd_loc == tgt_loc)\n",
    "                    total_joint_acc *= int(prd_loc == tgt_loc)\n",
    "                    num_slots += 1\n",
    "\n",
    "                item = OrderedDict(\n",
    "                    dialid = fields[\"dial_id\"],\n",
    "                    num_turns = num_turns,\n",
    "                    turnid = turnid,\n",
    "                    servid = servid,\n",
    "                    servname = fields[\"serv_name\"][servid],\n",
    "                    memsize = len(memory),\n",
    "                    slotname = slotname,\n",
    "                    tgt_val = tgt_val,\n",
    "                    tgt_loc = tgt_loc,\n",
    "                    prd_val = prd_val,\n",
    "                    prd_loc = prd_loc,\n",
    "                    correct = 100*int(tgt_loc == prd_loc),\n",
    "                    mask = (mask * mask_none),\n",
    "                )\n",
    "\n",
    "                result_table.append(item)\n",
    "            \n",
    "            # avg acc across slots per turn\n",
    "            total_turn_acc /= num_slots\n",
    "    \n",
    "    # the last batch\n",
    "    goal_acc.append(total_turn_acc / num_turns)\n",
    "    joint_acc.append(total_joint_acc / num_turns)\n",
    "        \n",
    "    print(\"Avg Goal Acc: \", sum(goal_acc) / len(goal_acc))\n",
    "    print(\"Avg Joint Goal Acc: \", sum(joint_acc) / len(joint_acc))\n",
    "    print()\n",
    "    \n",
    "    print(tabulate(\n",
    "        [list(item.values()) for item in result_table],\n",
    "        list(result_table[0].keys()),\n",
    "        \"fancy_grid\",\n",
    "    ))\n",
    "    \n",
    "    \n",
    "        \n",
    "infer_batch(model, [test_ds[0]], batch_size=2, device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "226px",
    "width": "226px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495px",
    "left": "1510px",
    "right": "97px",
    "top": "135px",
    "width": "403px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
